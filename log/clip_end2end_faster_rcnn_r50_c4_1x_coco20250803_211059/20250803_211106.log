2025-08-03 21:11:06,547 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 4090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.8.r11.8/compiler.31833905_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.10.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0+cu111
OpenCV: 4.12.0
MMCV: 1.3.17
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.18.0+eb18253
------------------------------------------------------------

2025-08-03 21:11:07,516 - mmdet - INFO - Distributed training: True
2025-08-03 21:11:08,463 - mmdet - INFO - Config:
checkpoint_config = dict(interval=2)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = 'regionclip_pretrained-cc_rn50_mmdet.pth'
resume_from = None
workflow = [('train', 1)]
norm_cfg = dict(type='BN', requires_grad=False)
model = dict(
    type='FasterRCNN',
    backbone=dict(type='CLIPResNet', layers=[3, 4, 6, 3], style='pytorch'),
    rpn_head=dict(
        type='RPNHead',
        in_channels=1024,
        feat_channels=1024,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[2, 4, 8, 16, 32],
            ratios=[0.5, 1.0, 2.0],
            strides=[16]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        shared_head=dict(type='CLIPResLayer', layers=[3, 4, 6, 3]),
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=1024,
            featmap_strides=[16]),
        bbox_head=dict(
            type='BBoxHeadCLIP',
            with_avg_pool=True,
            roi_feat_size=7,
            in_channels=2048,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            with_cls=False,
            reg_class_agnostic=True,
            zeroshot_path=
            './clip_embeddings/coco_clip_a+cname_rn50_manyprompt.npy',
            num_classes=80,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=12000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=6000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.0001,
            nms=dict(type='soft_nms', iou_threshold=0.5, method='gaussian'),
            max_per_img=100)))
dataset_type = 'CocoDataset'
data_root = '/root/autodl-tmp/datasets/coco/'
img_norm_cfg = dict(
    mean=[122.7709383, 116.7460125, 104.09373615],
    std=[68.5005327, 66.6321579, 70.32316305],
    to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=[(1333, 400), (1333, 800)], keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[122.7709383, 116.7460125, 104.09373615],
        std=[68.5005327, 66.6321579, 70.32316305],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[122.7709383, 116.7460125, 104.09373615],
                std=[68.5005327, 66.6321579, 70.32316305],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_train2017.1@5.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='Resize',
                img_scale=[(1333, 400), (1333, 800)],
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[122.7709383, 116.7460125, 104.09373615],
                std=[68.5005327, 66.6321579, 70.32316305],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=2, metric='bbox')
optimizer = dict(
    type='SGD',
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0001,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=0.1, decay_mult=1.0),
            roi_head=dict(lr_mult=0.1, decay_mult=1.0))))
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[3, 4])
runner = dict(type='EpochBasedRunner', max_epochs=4)
seed = 1
work_dir = '/root/autodl-tmp/log/clip_end2end_faster_rcnn_r50_c4_1x_coco20250803_211059'
gpu_ids = range(0, 1)

2025-08-03 21:11:08,788 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2025-08-03 21:11:08,834 - mmdet - INFO - initialize BBoxHeadCLIP with init_cfg [{'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.conv2.weight - torch.Size([32, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.conv3.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.bn3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

rpn_head.rpn_conv.weight - torch.Size([1024, 1024, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([1024]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([15, 1024, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([15]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([60, 1024, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([60]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.shared_head.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.shared_head.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.attnpool.positional_embedding - torch.Size([50, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.k_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.k_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.q_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.q_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.v_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.v_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.c_proj.weight - torch.Size([1024, 2048]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

roi_head.bbox_head.attnpool.c_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FasterRCNN  
2025-08-03 21:11:14,199 - mmdet - INFO - load checkpoint from local path: regionclip_pretrained-cc_rn50_mmdet.pth
2025-08-03 21:11:14,320 - mmdet - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: rpn_head.rpn_conv.weight, rpn_head.rpn_conv.bias, rpn_head.rpn_cls.weight, rpn_head.rpn_cls.bias, rpn_head.rpn_reg.weight, rpn_head.rpn_reg.bias, roi_head.bbox_head.zs_weights, roi_head.bbox_head.fc_reg.weight, roi_head.bbox_head.fc_reg.bias

2025-08-03 21:11:14,321 - mmdet - INFO - Start running, host: root@autodl-container-4bf6429de3-797681b8, work_dir: /root/autodl-tmp/log/clip_end2end_faster_rcnn_r50_c4_1x_coco20250803_211059
2025-08-03 21:11:14,321 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-08-03 21:11:14,322 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs
2025-08-03 21:11:14,322 - mmdet - INFO - Checkpoints will be saved to /root/autodl-tmp/log/clip_end2end_faster_rcnn_r50_c4_1x_coco20250803_211059 by HardDiskBackend.
2025-08-03 21:11:44,146 - mmdet - INFO - Epoch [1][50/2935]	lr: 4.945e-04, eta: 1:56:12, time: 0.596, data_time: 0.262, memory: 12209, loss_rpn_cls: 0.7523, loss_rpn_bbox: 0.2715, loss_cls: 201.1363, acc: 18.5723, loss_bbox: 0.1660, loss: 202.3261, grad_norm: 2328.6533
2025-08-03 21:12:01,014 - mmdet - INFO - Epoch [1][100/2935]	lr: 9.940e-04, eta: 1:30:34, time: 0.337, data_time: 0.005, memory: 12227, loss_rpn_cls: 0.4099, loss_rpn_bbox: 0.2248, loss_cls: 0.5681, acc: 92.3496, loss_bbox: 0.2495, loss: 1.4522, grad_norm: 16.7915
2025-08-03 21:12:17,985 - mmdet - INFO - Epoch [1][150/2935]	lr: 1.494e-03, eta: 1:21:58, time: 0.339, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2834, loss_rpn_bbox: 0.2017, loss_cls: 0.3268, acc: 92.9853, loss_bbox: 0.2373, loss: 1.0493, grad_norm: 12.1657
2025-08-03 21:12:34,696 - mmdet - INFO - Epoch [1][200/2935]	lr: 1.993e-03, eta: 1:17:17, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2759, loss_rpn_bbox: 0.2350, loss_cls: 0.3164, acc: 92.6882, loss_bbox: 0.2462, loss: 1.0735, grad_norm: 10.9921
2025-08-03 21:12:51,114 - mmdet - INFO - Epoch [1][250/2935]	lr: 2.493e-03, eta: 1:14:08, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2334, loss_rpn_bbox: 0.1923, loss_cls: 0.3010, acc: 92.7232, loss_bbox: 0.2463, loss: 0.9729, grad_norm: 9.8366
2025-08-03 21:13:07,780 - mmdet - INFO - Epoch [1][300/2935]	lr: 2.992e-03, eta: 1:12:06, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2144, loss_rpn_bbox: 0.2024, loss_cls: 0.3345, acc: 92.0838, loss_bbox: 0.2699, loss: 1.0213, grad_norm: 11.1959
2025-08-03 21:13:24,472 - mmdet - INFO - Epoch [1][350/2935]	lr: 3.492e-03, eta: 1:10:35, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2312, loss_rpn_bbox: 0.1817, loss_cls: 0.3372, acc: 92.1348, loss_bbox: 0.2768, loss: 1.0269, grad_norm: 9.8247
2025-08-03 21:13:40,822 - mmdet - INFO - Epoch [1][400/2935]	lr: 3.991e-03, eta: 1:09:13, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2245, loss_rpn_bbox: 0.1677, loss_cls: 0.3250, acc: 91.8533, loss_bbox: 0.2699, loss: 0.9871, grad_norm: 10.2416
2025-08-03 21:13:57,455 - mmdet - INFO - Epoch [1][450/2935]	lr: 4.491e-03, eta: 1:08:12, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1991, loss_rpn_bbox: 0.1519, loss_cls: 0.3178, acc: 92.4442, loss_bbox: 0.2601, loss: 0.9288, grad_norm: 9.3293
2025-08-03 21:14:14,502 - mmdet - INFO - Epoch [1][500/2935]	lr: 4.990e-03, eta: 1:07:30, time: 0.341, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2166, loss_rpn_bbox: 0.2038, loss_cls: 0.3145, acc: 92.3246, loss_bbox: 0.2629, loss: 0.9978, grad_norm: 9.1597
2025-08-03 21:14:30,627 - mmdet - INFO - Epoch [1][550/2935]	lr: 5.000e-03, eta: 1:06:33, time: 0.322, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2177, loss_rpn_bbox: 0.1618, loss_cls: 0.3504, acc: 91.3980, loss_bbox: 0.2770, loss: 1.0069, grad_norm: 10.0546
2025-08-03 21:14:47,196 - mmdet - INFO - Epoch [1][600/2935]	lr: 5.000e-03, eta: 1:05:52, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.2140, loss_rpn_bbox: 0.1688, loss_cls: 0.3353, acc: 90.7383, loss_bbox: 0.3276, loss: 1.0458, grad_norm: 8.2987
2025-08-03 21:15:03,716 - mmdet - INFO - Epoch [1][650/2935]	lr: 5.000e-03, eta: 1:05:13, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1810, loss_rpn_bbox: 0.1403, loss_cls: 0.3392, acc: 90.9100, loss_bbox: 0.3223, loss: 0.9827, grad_norm: 8.3636
2025-08-03 21:15:20,140 - mmdet - INFO - Epoch [1][700/2935]	lr: 5.000e-03, eta: 1:04:36, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1925, loss_rpn_bbox: 0.1416, loss_cls: 0.3885, acc: 89.9811, loss_bbox: 0.3662, loss: 1.0889, grad_norm: 8.7753
2025-08-03 21:15:37,027 - mmdet - INFO - Epoch [1][750/2935]	lr: 5.000e-03, eta: 1:04:09, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1848, loss_rpn_bbox: 0.1243, loss_cls: 0.3121, acc: 91.5089, loss_bbox: 0.3148, loss: 0.9360, grad_norm: 7.7217
2025-08-03 21:15:53,842 - mmdet - INFO - Epoch [1][800/2935]	lr: 5.000e-03, eta: 1:03:42, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1965, loss_rpn_bbox: 0.1426, loss_cls: 0.3045, acc: 91.2392, loss_bbox: 0.3088, loss: 0.9525, grad_norm: 7.9006
2025-08-03 21:16:10,552 - mmdet - INFO - Epoch [1][850/2935]	lr: 5.000e-03, eta: 1:03:15, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1720, loss_rpn_bbox: 0.1474, loss_cls: 0.3271, acc: 91.2154, loss_bbox: 0.3392, loss: 0.9857, grad_norm: 7.7874
2025-08-03 21:16:27,450 - mmdet - INFO - Epoch [1][900/2935]	lr: 5.000e-03, eta: 1:02:51, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1774, loss_rpn_bbox: 0.1270, loss_cls: 0.2829, acc: 91.7467, loss_bbox: 0.3190, loss: 0.9063, grad_norm: 7.3796
2025-08-03 21:16:43,978 - mmdet - INFO - Epoch [1][950/2935]	lr: 5.000e-03, eta: 1:02:24, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1781, loss_rpn_bbox: 0.1255, loss_cls: 0.3270, acc: 90.8428, loss_bbox: 0.3533, loss: 0.9839, grad_norm: 7.6384
2025-08-03 21:17:00,606 - mmdet - INFO - Exp name: clip_end2end_faster_rcnn_r50_c4_1x_coco.py
2025-08-03 21:17:00,606 - mmdet - INFO - Epoch [1][1000/2935]	lr: 5.000e-03, eta: 1:01:59, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1689, loss_rpn_bbox: 0.1278, loss_cls: 0.2774, acc: 92.0042, loss_bbox: 0.3213, loss: 0.8954, grad_norm: 6.8497
2025-08-03 21:17:16,884 - mmdet - INFO - Epoch [1][1050/2935]	lr: 5.000e-03, eta: 1:01:31, time: 0.326, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1724, loss_rpn_bbox: 0.1204, loss_cls: 0.3523, acc: 90.3170, loss_bbox: 0.3573, loss: 1.0024, grad_norm: 8.7938
2025-08-03 21:17:32,950 - mmdet - INFO - Epoch [1][1100/2935]	lr: 5.000e-03, eta: 1:01:02, time: 0.321, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1779, loss_rpn_bbox: 0.1534, loss_cls: 0.3319, acc: 90.6420, loss_bbox: 0.3555, loss: 1.0188, grad_norm: 8.1068
2025-08-03 21:17:48,704 - mmdet - INFO - Epoch [1][1150/2935]	lr: 5.000e-03, eta: 1:00:31, time: 0.315, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1669, loss_rpn_bbox: 0.1559, loss_cls: 0.3447, acc: 89.9892, loss_bbox: 0.3839, loss: 1.0514, grad_norm: 8.6981
2025-08-03 21:18:04,997 - mmdet - INFO - Epoch [1][1200/2935]	lr: 5.000e-03, eta: 1:00:07, time: 0.326, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1589, loss_rpn_bbox: 0.1150, loss_cls: 0.3263, acc: 90.7761, loss_bbox: 0.3500, loss: 0.9502, grad_norm: 7.8614
2025-08-03 21:18:21,555 - mmdet - INFO - Epoch [1][1250/2935]	lr: 5.000e-03, eta: 0:59:45, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1842, loss_rpn_bbox: 0.1395, loss_cls: 0.3689, acc: 89.2148, loss_bbox: 0.4102, loss: 1.1029, grad_norm: 8.6763
2025-08-03 21:18:37,885 - mmdet - INFO - Epoch [1][1300/2935]	lr: 5.000e-03, eta: 0:59:22, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1619, loss_rpn_bbox: 0.1275, loss_cls: 0.3235, acc: 90.7611, loss_bbox: 0.3526, loss: 0.9655, grad_norm: 7.6461
2025-08-03 21:18:54,107 - mmdet - INFO - Epoch [1][1350/2935]	lr: 5.000e-03, eta: 0:58:58, time: 0.324, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1854, loss_rpn_bbox: 0.1584, loss_cls: 0.3747, acc: 89.6800, loss_bbox: 0.3743, loss: 1.0929, grad_norm: 8.8468
2025-08-03 21:19:10,465 - mmdet - INFO - Epoch [1][1400/2935]	lr: 5.000e-03, eta: 0:58:36, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1592, loss_rpn_bbox: 0.1258, loss_cls: 0.3182, acc: 90.5833, loss_bbox: 0.3698, loss: 0.9730, grad_norm: 7.5376
2025-08-03 21:19:26,906 - mmdet - INFO - Epoch [1][1450/2935]	lr: 5.000e-03, eta: 0:58:15, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1579, loss_rpn_bbox: 0.1445, loss_cls: 0.3385, acc: 90.8023, loss_bbox: 0.3594, loss: 1.0002, grad_norm: 7.6631
2025-08-03 21:19:43,461 - mmdet - INFO - Epoch [1][1500/2935]	lr: 5.000e-03, eta: 0:57:55, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1590, loss_rpn_bbox: 0.1129, loss_cls: 0.3310, acc: 90.7902, loss_bbox: 0.3829, loss: 0.9858, grad_norm: 7.3913
2025-08-03 21:20:00,174 - mmdet - INFO - Epoch [1][1550/2935]	lr: 5.000e-03, eta: 0:57:36, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1461, loss_rpn_bbox: 0.1350, loss_cls: 0.3138, acc: 90.9260, loss_bbox: 0.3615, loss: 0.9564, grad_norm: 8.2070
2025-08-03 21:20:16,744 - mmdet - INFO - Epoch [1][1600/2935]	lr: 5.000e-03, eta: 0:57:17, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1383, loss_rpn_bbox: 0.0898, loss_cls: 0.3442, acc: 89.8007, loss_bbox: 0.3820, loss: 0.9544, grad_norm: 8.6320
2025-08-03 21:20:33,485 - mmdet - INFO - Epoch [1][1650/2935]	lr: 5.000e-03, eta: 0:56:59, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1482, loss_rpn_bbox: 0.1254, loss_cls: 0.3141, acc: 90.4601, loss_bbox: 0.3781, loss: 0.9658, grad_norm: 8.1350
2025-08-03 21:20:50,217 - mmdet - INFO - Epoch [1][1700/2935]	lr: 5.000e-03, eta: 0:56:41, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1720, loss_rpn_bbox: 0.1340, loss_cls: 0.3293, acc: 89.7234, loss_bbox: 0.4131, loss: 1.0484, grad_norm: 8.4224
2025-08-03 21:21:06,557 - mmdet - INFO - Epoch [1][1750/2935]	lr: 5.000e-03, eta: 0:56:20, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1714, loss_rpn_bbox: 0.1410, loss_cls: 0.3000, acc: 91.2040, loss_bbox: 0.3561, loss: 0.9685, grad_norm: 8.7143
2025-08-03 21:21:22,270 - mmdet - INFO - Epoch [1][1800/2935]	lr: 5.000e-03, eta: 0:55:57, time: 0.314, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1490, loss_rpn_bbox: 0.1167, loss_cls: 0.3399, acc: 90.3056, loss_bbox: 0.3701, loss: 0.9757, grad_norm: 8.3583
2025-08-03 21:21:38,865 - mmdet - INFO - Epoch [1][1850/2935]	lr: 5.000e-03, eta: 0:55:38, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1531, loss_rpn_bbox: 0.1027, loss_cls: 0.3482, acc: 90.1340, loss_bbox: 0.3963, loss: 1.0003, grad_norm: 8.2075
2025-08-03 21:21:55,484 - mmdet - INFO - Epoch [1][1900/2935]	lr: 5.000e-03, eta: 0:55:20, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1396, loss_rpn_bbox: 0.1384, loss_cls: 0.3008, acc: 91.2036, loss_bbox: 0.3642, loss: 0.9430, grad_norm: 7.7960
2025-08-03 21:22:12,023 - mmdet - INFO - Epoch [1][1950/2935]	lr: 5.000e-03, eta: 0:55:01, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1379, loss_rpn_bbox: 0.1388, loss_cls: 0.3018, acc: 90.9981, loss_bbox: 0.3661, loss: 0.9446, grad_norm: 7.5084
2025-08-03 21:22:28,481 - mmdet - INFO - Exp name: clip_end2end_faster_rcnn_r50_c4_1x_coco.py
2025-08-03 21:22:28,482 - mmdet - INFO - Epoch [1][2000/2935]	lr: 5.000e-03, eta: 0:54:43, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1767, loss_rpn_bbox: 0.1454, loss_cls: 0.3322, acc: 90.1443, loss_bbox: 0.3775, loss: 1.0318, grad_norm: 9.0263
2025-08-03 21:22:44,976 - mmdet - INFO - Epoch [1][2050/2935]	lr: 5.000e-03, eta: 0:54:24, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1436, loss_rpn_bbox: 0.1140, loss_cls: 0.2954, acc: 91.3860, loss_bbox: 0.3485, loss: 0.9016, grad_norm: 7.0436
2025-08-03 21:23:01,769 - mmdet - INFO - Epoch [1][2100/2935]	lr: 5.000e-03, eta: 0:54:07, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1609, loss_rpn_bbox: 0.1199, loss_cls: 0.2832, acc: 91.0027, loss_bbox: 0.3709, loss: 0.9349, grad_norm: 7.5452
2025-08-03 21:23:18,117 - mmdet - INFO - Epoch [1][2150/2935]	lr: 5.000e-03, eta: 0:53:48, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1586, loss_rpn_bbox: 0.1455, loss_cls: 0.3106, acc: 91.2111, loss_bbox: 0.3662, loss: 0.9808, grad_norm: 7.6220
2025-08-03 21:23:34,607 - mmdet - INFO - Epoch [1][2200/2935]	lr: 5.000e-03, eta: 0:53:30, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1529, loss_rpn_bbox: 0.1026, loss_cls: 0.2831, acc: 91.5318, loss_bbox: 0.3223, loss: 0.8610, grad_norm: 7.6210
2025-08-03 21:23:51,350 - mmdet - INFO - Epoch [1][2250/2935]	lr: 5.000e-03, eta: 0:53:12, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1448, loss_rpn_bbox: 0.1136, loss_cls: 0.2909, acc: 91.1573, loss_bbox: 0.3652, loss: 0.9145, grad_norm: 7.5575
2025-08-03 21:24:08,071 - mmdet - INFO - Epoch [1][2300/2935]	lr: 5.000e-03, eta: 0:52:55, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1480, loss_rpn_bbox: 0.1224, loss_cls: 0.3084, acc: 90.5398, loss_bbox: 0.3681, loss: 0.9468, grad_norm: 8.2846
2025-08-03 21:24:24,783 - mmdet - INFO - Epoch [1][2350/2935]	lr: 5.000e-03, eta: 0:52:38, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1479, loss_rpn_bbox: 0.1269, loss_cls: 0.2888, acc: 91.6000, loss_bbox: 0.3300, loss: 0.8935, grad_norm: 7.4329
2025-08-03 21:24:41,102 - mmdet - INFO - Epoch [1][2400/2935]	lr: 5.000e-03, eta: 0:52:19, time: 0.326, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1511, loss_rpn_bbox: 0.1017, loss_cls: 0.3063, acc: 91.1967, loss_bbox: 0.3490, loss: 0.9082, grad_norm: 7.8873
2025-08-03 21:24:57,630 - mmdet - INFO - Epoch [1][2450/2935]	lr: 5.000e-03, eta: 0:52:01, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1394, loss_rpn_bbox: 0.1360, loss_cls: 0.2939, acc: 91.4698, loss_bbox: 0.3463, loss: 0.9155, grad_norm: 7.6688
2025-08-03 21:25:14,435 - mmdet - INFO - Epoch [1][2500/2935]	lr: 5.000e-03, eta: 0:51:45, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1364, loss_rpn_bbox: 0.1176, loss_cls: 0.3010, acc: 90.6544, loss_bbox: 0.3751, loss: 0.9301, grad_norm: 7.8592
2025-08-03 21:25:31,015 - mmdet - INFO - Epoch [1][2550/2935]	lr: 5.000e-03, eta: 0:51:27, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1355, loss_rpn_bbox: 0.0910, loss_cls: 0.3328, acc: 90.0439, loss_bbox: 0.3863, loss: 0.9455, grad_norm: 8.6249
2025-08-03 21:25:47,525 - mmdet - INFO - Epoch [1][2600/2935]	lr: 5.000e-03, eta: 0:51:09, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1708, loss_rpn_bbox: 0.1381, loss_cls: 0.3700, acc: 88.7506, loss_bbox: 0.4093, loss: 1.0882, grad_norm: 10.0561
2025-08-03 21:26:04,386 - mmdet - INFO - Epoch [1][2650/2935]	lr: 5.000e-03, eta: 0:50:53, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1369, loss_rpn_bbox: 0.0883, loss_cls: 0.3253, acc: 89.7817, loss_bbox: 0.4273, loss: 0.9778, grad_norm: 7.7303
2025-08-03 21:26:21,051 - mmdet - INFO - Epoch [1][2700/2935]	lr: 5.000e-03, eta: 0:50:35, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1380, loss_rpn_bbox: 0.1258, loss_cls: 0.3038, acc: 90.8838, loss_bbox: 0.3568, loss: 0.9244, grad_norm: 8.4385
2025-08-03 21:26:37,504 - mmdet - INFO - Epoch [1][2750/2935]	lr: 5.000e-03, eta: 0:50:17, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1305, loss_rpn_bbox: 0.1119, loss_cls: 0.2936, acc: 90.7817, loss_bbox: 0.3621, loss: 0.8981, grad_norm: 8.3052
2025-08-03 21:26:53,334 - mmdet - INFO - Epoch [1][2800/2935]	lr: 5.000e-03, eta: 0:49:58, time: 0.317, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1481, loss_rpn_bbox: 0.1518, loss_cls: 0.3135, acc: 91.0314, loss_bbox: 0.3450, loss: 0.9584, grad_norm: 7.7608
2025-08-03 21:27:09,754 - mmdet - INFO - Epoch [1][2850/2935]	lr: 5.000e-03, eta: 0:49:40, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1354, loss_rpn_bbox: 0.1141, loss_cls: 0.3096, acc: 90.5545, loss_bbox: 0.3666, loss: 0.9258, grad_norm: 8.4420
2025-08-03 21:27:26,434 - mmdet - INFO - Epoch [1][2900/2935]	lr: 5.000e-03, eta: 0:49:23, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1391, loss_rpn_bbox: 0.1237, loss_cls: 0.3284, acc: 90.4031, loss_bbox: 0.3616, loss: 0.9529, grad_norm: 9.3423
2025-08-03 21:28:08,941 - mmdet - INFO - Epoch [2][50/2935]	lr: 5.000e-03, eta: 0:48:58, time: 0.597, data_time: 0.274, memory: 12372, loss_rpn_cls: 0.1309, loss_rpn_bbox: 0.1235, loss_cls: 0.2614, acc: 91.9989, loss_bbox: 0.3225, loss: 0.8382, grad_norm: 6.8235
2025-08-03 21:28:25,572 - mmdet - INFO - Epoch [2][100/2935]	lr: 5.000e-03, eta: 0:48:41, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1288, loss_rpn_bbox: 0.1227, loss_cls: 0.3043, acc: 90.4869, loss_bbox: 0.3603, loss: 0.9161, grad_norm: 8.4016
2025-08-03 21:28:42,159 - mmdet - INFO - Epoch [2][150/2935]	lr: 5.000e-03, eta: 0:48:24, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1311, loss_rpn_bbox: 0.1174, loss_cls: 0.2979, acc: 90.4398, loss_bbox: 0.3887, loss: 0.9351, grad_norm: 7.8203
2025-08-03 21:28:58,711 - mmdet - INFO - Epoch [2][200/2935]	lr: 5.000e-03, eta: 0:48:06, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1485, loss_rpn_bbox: 0.1162, loss_cls: 0.3255, acc: 90.0545, loss_bbox: 0.3919, loss: 0.9822, grad_norm: 8.7481
2025-08-03 21:29:15,074 - mmdet - INFO - Epoch [2][250/2935]	lr: 5.000e-03, eta: 0:47:48, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1217, loss_rpn_bbox: 0.0998, loss_cls: 0.2740, acc: 91.2952, loss_bbox: 0.3396, loss: 0.8350, grad_norm: 7.9193
2025-08-03 21:29:31,404 - mmdet - INFO - Epoch [2][300/2935]	lr: 5.000e-03, eta: 0:47:30, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1418, loss_rpn_bbox: 0.1124, loss_cls: 0.3334, acc: 89.7374, loss_bbox: 0.3905, loss: 0.9781, grad_norm: 9.1145
2025-08-03 21:29:47,878 - mmdet - INFO - Epoch [2][350/2935]	lr: 5.000e-03, eta: 0:47:13, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1265, loss_rpn_bbox: 0.1003, loss_cls: 0.2790, acc: 91.3451, loss_bbox: 0.3542, loss: 0.8600, grad_norm: 7.5120
2025-08-03 21:30:04,760 - mmdet - INFO - Epoch [2][400/2935]	lr: 5.000e-03, eta: 0:46:57, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1422, loss_rpn_bbox: 0.1307, loss_cls: 0.2955, acc: 91.0860, loss_bbox: 0.3402, loss: 0.9086, grad_norm: 8.6545
2025-08-03 21:30:21,131 - mmdet - INFO - Epoch [2][450/2935]	lr: 5.000e-03, eta: 0:46:39, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1597, loss_rpn_bbox: 0.1400, loss_cls: 0.3040, acc: 90.4516, loss_bbox: 0.3670, loss: 0.9707, grad_norm: 8.6830
2025-08-03 21:30:37,379 - mmdet - INFO - Epoch [2][500/2935]	lr: 5.000e-03, eta: 0:46:21, time: 0.325, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1602, loss_rpn_bbox: 0.1384, loss_cls: 0.2926, acc: 91.2019, loss_bbox: 0.3288, loss: 0.9200, grad_norm: 8.2227
2025-08-03 21:30:53,573 - mmdet - INFO - Epoch [2][550/2935]	lr: 5.000e-03, eta: 0:46:03, time: 0.324, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1584, loss_rpn_bbox: 0.1401, loss_cls: 0.2878, acc: 90.9993, loss_bbox: 0.3399, loss: 0.9261, grad_norm: 8.1914
2025-08-03 21:31:10,060 - mmdet - INFO - Epoch [2][600/2935]	lr: 5.000e-03, eta: 0:45:45, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1415, loss_rpn_bbox: 0.1134, loss_cls: 0.2690, acc: 91.4952, loss_bbox: 0.3496, loss: 0.8735, grad_norm: 7.5396
2025-08-03 21:31:26,841 - mmdet - INFO - Epoch [2][650/2935]	lr: 5.000e-03, eta: 0:45:29, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1256, loss_rpn_bbox: 0.1271, loss_cls: 0.2675, acc: 91.6858, loss_bbox: 0.3334, loss: 0.8537, grad_norm: 7.7252
2025-08-03 21:31:43,676 - mmdet - INFO - Epoch [2][700/2935]	lr: 5.000e-03, eta: 0:45:12, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1386, loss_rpn_bbox: 0.1468, loss_cls: 0.2945, acc: 90.6566, loss_bbox: 0.3465, loss: 0.9263, grad_norm: 8.6191
2025-08-03 21:32:00,134 - mmdet - INFO - Epoch [2][750/2935]	lr: 5.000e-03, eta: 0:44:55, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1318, loss_rpn_bbox: 0.1100, loss_cls: 0.2869, acc: 91.0444, loss_bbox: 0.3483, loss: 0.8770, grad_norm: 8.0679
2025-08-03 21:32:16,885 - mmdet - INFO - Epoch [2][800/2935]	lr: 5.000e-03, eta: 0:44:38, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1482, loss_rpn_bbox: 0.1193, loss_cls: 0.2829, acc: 91.3757, loss_bbox: 0.3639, loss: 0.9143, grad_norm: 8.6208
2025-08-03 21:32:33,294 - mmdet - INFO - Epoch [2][850/2935]	lr: 5.000e-03, eta: 0:44:21, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1118, loss_rpn_bbox: 0.0957, loss_cls: 0.2723, acc: 91.8546, loss_bbox: 0.3280, loss: 0.8078, grad_norm: 8.0493
2025-08-03 21:32:49,974 - mmdet - INFO - Epoch [2][900/2935]	lr: 5.000e-03, eta: 0:44:04, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1318, loss_rpn_bbox: 0.0966, loss_cls: 0.2913, acc: 90.8493, loss_bbox: 0.3526, loss: 0.8723, grad_norm: 8.7578
2025-08-03 21:33:06,311 - mmdet - INFO - Epoch [2][950/2935]	lr: 5.000e-03, eta: 0:43:47, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1411, loss_rpn_bbox: 0.1270, loss_cls: 0.3190, acc: 89.8603, loss_bbox: 0.3929, loss: 0.9800, grad_norm: 8.8375
2025-08-03 21:33:22,618 - mmdet - INFO - Epoch [2][1000/2935]	lr: 5.000e-03, eta: 0:43:29, time: 0.326, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1406, loss_rpn_bbox: 0.1471, loss_cls: 0.2952, acc: 90.9131, loss_bbox: 0.3515, loss: 0.9343, grad_norm: 8.2894
2025-08-03 21:33:39,405 - mmdet - INFO - Epoch [2][1050/2935]	lr: 5.000e-03, eta: 0:43:12, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1427, loss_rpn_bbox: 0.1139, loss_cls: 0.3049, acc: 90.3447, loss_bbox: 0.3608, loss: 0.9223, grad_norm: 8.9347
2025-08-03 21:33:55,836 - mmdet - INFO - Epoch [2][1100/2935]	lr: 5.000e-03, eta: 0:42:55, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1336, loss_rpn_bbox: 0.0958, loss_cls: 0.3047, acc: 90.8087, loss_bbox: 0.3540, loss: 0.8881, grad_norm: 8.9354
2025-08-03 21:34:12,505 - mmdet - INFO - Epoch [2][1150/2935]	lr: 5.000e-03, eta: 0:42:38, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1357, loss_rpn_bbox: 0.1128, loss_cls: 0.3246, acc: 89.9646, loss_bbox: 0.3724, loss: 0.9454, grad_norm: 8.5430
2025-08-03 21:34:28,971 - mmdet - INFO - Epoch [2][1200/2935]	lr: 5.000e-03, eta: 0:42:21, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1274, loss_rpn_bbox: 0.1029, loss_cls: 0.2985, acc: 91.0245, loss_bbox: 0.3542, loss: 0.8830, grad_norm: 8.1019
2025-08-03 21:34:45,532 - mmdet - INFO - Epoch [2][1250/2935]	lr: 5.000e-03, eta: 0:42:04, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1381, loss_rpn_bbox: 0.1150, loss_cls: 0.3371, acc: 89.4561, loss_bbox: 0.4035, loss: 0.9938, grad_norm: 8.8578
2025-08-03 21:35:01,963 - mmdet - INFO - Epoch [2][1300/2935]	lr: 5.000e-03, eta: 0:41:47, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1659, loss_rpn_bbox: 0.1514, loss_cls: 0.2995, acc: 90.7727, loss_bbox: 0.3458, loss: 0.9626, grad_norm: 8.8718
2025-08-03 21:35:18,669 - mmdet - INFO - Epoch [2][1350/2935]	lr: 5.000e-03, eta: 0:41:30, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1411, loss_rpn_bbox: 0.1092, loss_cls: 0.2909, acc: 91.0300, loss_bbox: 0.3197, loss: 0.8609, grad_norm: 7.9411
2025-08-03 21:35:35,136 - mmdet - INFO - Epoch [2][1400/2935]	lr: 5.000e-03, eta: 0:41:13, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1392, loss_rpn_bbox: 0.1436, loss_cls: 0.3147, acc: 90.1600, loss_bbox: 0.3796, loss: 0.9771, grad_norm: 8.4630
2025-08-03 21:35:51,777 - mmdet - INFO - Epoch [2][1450/2935]	lr: 5.000e-03, eta: 0:40:56, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1288, loss_rpn_bbox: 0.1109, loss_cls: 0.2554, acc: 92.0788, loss_bbox: 0.3154, loss: 0.8105, grad_norm: 7.2847
2025-08-03 21:36:08,665 - mmdet - INFO - Epoch [2][1500/2935]	lr: 5.000e-03, eta: 0:40:40, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1293, loss_rpn_bbox: 0.1072, loss_cls: 0.2801, acc: 91.1804, loss_bbox: 0.3569, loss: 0.8734, grad_norm: 7.7134
2025-08-03 21:36:25,378 - mmdet - INFO - Epoch [2][1550/2935]	lr: 5.000e-03, eta: 0:40:23, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1248, loss_rpn_bbox: 0.1128, loss_cls: 0.2697, acc: 91.6163, loss_bbox: 0.3214, loss: 0.8288, grad_norm: 7.9492
2025-08-03 21:36:42,063 - mmdet - INFO - Epoch [2][1600/2935]	lr: 5.000e-03, eta: 0:40:07, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1258, loss_rpn_bbox: 0.1034, loss_cls: 0.3055, acc: 90.7541, loss_bbox: 0.3692, loss: 0.9039, grad_norm: 8.9469
2025-08-03 21:36:58,471 - mmdet - INFO - Epoch [2][1650/2935]	lr: 5.000e-03, eta: 0:39:49, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1436, loss_rpn_bbox: 0.1166, loss_cls: 0.3285, acc: 89.7368, loss_bbox: 0.3644, loss: 0.9531, grad_norm: 9.8216
2025-08-03 21:37:15,377 - mmdet - INFO - Epoch [2][1700/2935]	lr: 5.000e-03, eta: 0:39:33, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1317, loss_rpn_bbox: 0.1172, loss_cls: 0.2983, acc: 90.3793, loss_bbox: 0.3645, loss: 0.9117, grad_norm: 8.8083
2025-08-03 21:37:31,956 - mmdet - INFO - Epoch [2][1750/2935]	lr: 5.000e-03, eta: 0:39:16, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1289, loss_rpn_bbox: 0.1064, loss_cls: 0.2923, acc: 90.9041, loss_bbox: 0.3471, loss: 0.8746, grad_norm: 8.7683
2025-08-03 21:37:48,378 - mmdet - INFO - Epoch [2][1800/2935]	lr: 5.000e-03, eta: 0:38:59, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1244, loss_rpn_bbox: 0.1041, loss_cls: 0.3070, acc: 90.5559, loss_bbox: 0.3554, loss: 0.8909, grad_norm: 8.3595
2025-08-03 21:38:05,015 - mmdet - INFO - Epoch [2][1850/2935]	lr: 5.000e-03, eta: 0:38:42, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1281, loss_rpn_bbox: 0.1244, loss_cls: 0.2898, acc: 90.8463, loss_bbox: 0.3573, loss: 0.8996, grad_norm: 8.2755
2025-08-03 21:38:21,579 - mmdet - INFO - Epoch [2][1900/2935]	lr: 5.000e-03, eta: 0:38:25, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1171, loss_rpn_bbox: 0.0969, loss_cls: 0.2746, acc: 91.4574, loss_bbox: 0.3502, loss: 0.8388, grad_norm: 8.1031
2025-08-03 21:38:38,211 - mmdet - INFO - Epoch [2][1950/2935]	lr: 5.000e-03, eta: 0:38:09, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1130, loss_rpn_bbox: 0.0983, loss_cls: 0.2444, acc: 92.1162, loss_bbox: 0.3102, loss: 0.7659, grad_norm: 7.6251
2025-08-03 21:38:54,754 - mmdet - INFO - Epoch [2][2000/2935]	lr: 5.000e-03, eta: 0:37:52, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1196, loss_rpn_bbox: 0.1017, loss_cls: 0.2455, acc: 92.3364, loss_bbox: 0.3128, loss: 0.7796, grad_norm: 8.1187
2025-08-03 21:39:11,816 - mmdet - INFO - Epoch [2][2050/2935]	lr: 5.000e-03, eta: 0:37:35, time: 0.341, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1457, loss_rpn_bbox: 0.1094, loss_cls: 0.3280, acc: 90.1615, loss_bbox: 0.3792, loss: 0.9623, grad_norm: 9.4380
2025-08-03 21:39:28,508 - mmdet - INFO - Epoch [2][2100/2935]	lr: 5.000e-03, eta: 0:37:19, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1378, loss_rpn_bbox: 0.1201, loss_cls: 0.3054, acc: 90.5733, loss_bbox: 0.3518, loss: 0.9151, grad_norm: 8.1204
2025-08-03 21:39:45,129 - mmdet - INFO - Epoch [2][2150/2935]	lr: 5.000e-03, eta: 0:37:02, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1297, loss_rpn_bbox: 0.1151, loss_cls: 0.2924, acc: 90.8266, loss_bbox: 0.3525, loss: 0.8897, grad_norm: 8.0391
2025-08-03 21:40:01,820 - mmdet - INFO - Epoch [2][2200/2935]	lr: 5.000e-03, eta: 0:36:45, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1222, loss_rpn_bbox: 0.0976, loss_cls: 0.2610, acc: 91.7036, loss_bbox: 0.3103, loss: 0.7912, grad_norm: 7.8739
2025-08-03 21:40:18,453 - mmdet - INFO - Epoch [2][2250/2935]	lr: 5.000e-03, eta: 0:36:28, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1232, loss_rpn_bbox: 0.1128, loss_cls: 0.2924, acc: 90.9877, loss_bbox: 0.3629, loss: 0.8913, grad_norm: 8.6197
2025-08-03 21:40:35,146 - mmdet - INFO - Epoch [2][2300/2935]	lr: 5.000e-03, eta: 0:36:12, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1225, loss_rpn_bbox: 0.0960, loss_cls: 0.2637, acc: 91.8469, loss_bbox: 0.3109, loss: 0.7931, grad_norm: 8.1047
2025-08-03 21:40:51,395 - mmdet - INFO - Epoch [2][2350/2935]	lr: 5.000e-03, eta: 0:35:54, time: 0.325, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1328, loss_rpn_bbox: 0.1302, loss_cls: 0.2815, acc: 91.5886, loss_bbox: 0.3223, loss: 0.8668, grad_norm: 9.0107
2025-08-03 21:41:07,642 - mmdet - INFO - Epoch [2][2400/2935]	lr: 5.000e-03, eta: 0:35:37, time: 0.325, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1267, loss_rpn_bbox: 0.1214, loss_cls: 0.2677, acc: 91.6939, loss_bbox: 0.3147, loss: 0.8304, grad_norm: 8.2901
2025-08-03 21:41:24,137 - mmdet - INFO - Epoch [2][2450/2935]	lr: 5.000e-03, eta: 0:35:20, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1313, loss_rpn_bbox: 0.1041, loss_cls: 0.2792, acc: 91.4032, loss_bbox: 0.3368, loss: 0.8514, grad_norm: 8.5718
2025-08-03 21:41:40,960 - mmdet - INFO - Epoch [2][2500/2935]	lr: 5.000e-03, eta: 0:35:04, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1318, loss_rpn_bbox: 0.1072, loss_cls: 0.2974, acc: 90.9797, loss_bbox: 0.3320, loss: 0.8684, grad_norm: 8.5774
2025-08-03 21:41:57,723 - mmdet - INFO - Epoch [2][2550/2935]	lr: 5.000e-03, eta: 0:34:47, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1532, loss_rpn_bbox: 0.1333, loss_cls: 0.3205, acc: 90.2922, loss_bbox: 0.3553, loss: 0.9623, grad_norm: 9.0595
2025-08-03 21:42:14,380 - mmdet - INFO - Epoch [2][2600/2935]	lr: 5.000e-03, eta: 0:34:30, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1340, loss_rpn_bbox: 0.1227, loss_cls: 0.2762, acc: 91.4838, loss_bbox: 0.3184, loss: 0.8514, grad_norm: 7.9830
2025-08-03 21:42:31,030 - mmdet - INFO - Epoch [2][2650/2935]	lr: 5.000e-03, eta: 0:34:14, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1231, loss_rpn_bbox: 0.1057, loss_cls: 0.2520, acc: 91.9550, loss_bbox: 0.3037, loss: 0.7844, grad_norm: 7.7035
2025-08-03 21:42:47,512 - mmdet - INFO - Epoch [2][2700/2935]	lr: 5.000e-03, eta: 0:33:57, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1142, loss_rpn_bbox: 0.0853, loss_cls: 0.2866, acc: 90.9884, loss_bbox: 0.3363, loss: 0.8224, grad_norm: 8.3589
2025-08-03 21:43:04,357 - mmdet - INFO - Epoch [2][2750/2935]	lr: 5.000e-03, eta: 0:33:40, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1448, loss_rpn_bbox: 0.1137, loss_cls: 0.3155, acc: 90.3129, loss_bbox: 0.3658, loss: 0.9397, grad_norm: 8.6521
2025-08-03 21:43:21,040 - mmdet - INFO - Epoch [2][2800/2935]	lr: 5.000e-03, eta: 0:33:24, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1319, loss_rpn_bbox: 0.0971, loss_cls: 0.3150, acc: 90.0582, loss_bbox: 0.3607, loss: 0.9047, grad_norm: 8.9460
2025-08-03 21:43:37,693 - mmdet - INFO - Epoch [2][2850/2935]	lr: 5.000e-03, eta: 0:33:07, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1148, loss_rpn_bbox: 0.1054, loss_cls: 0.2976, acc: 90.9515, loss_bbox: 0.3296, loss: 0.8474, grad_norm: 9.0732
2025-08-03 21:43:54,275 - mmdet - INFO - Epoch [2][2900/2935]	lr: 5.000e-03, eta: 0:32:50, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1267, loss_rpn_bbox: 0.1187, loss_cls: 0.2773, acc: 91.1937, loss_bbox: 0.2949, loss: 0.8175, grad_norm: 8.5771
2025-08-03 21:44:06,666 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-08-03 21:44:53,836 - mmdet - INFO - Evaluating bbox...
2025-08-03 21:45:02,600 - mmdet - INFO - Exp name: clip_end2end_faster_rcnn_r50_c4_1x_coco.py
2025-08-03 21:45:02,601 - mmdet - INFO - Epoch(val) [2][850]	bbox_mAP: 0.1090, bbox_mAP_50: 0.2430, bbox_mAP_75: 0.0870, bbox_mAP_s: 0.0390, bbox_mAP_m: 0.1430, bbox_mAP_l: 0.1810, bbox_mAP_copypaste: 0.109 0.243 0.087 0.039 0.143 0.181
2025-08-03 21:45:32,695 - mmdet - INFO - Epoch [3][50/2935]	lr: 5.000e-03, eta: 0:32:23, time: 0.602, data_time: 0.273, memory: 12372, loss_rpn_cls: 0.1247, loss_rpn_bbox: 0.0944, loss_cls: 0.2686, acc: 91.4807, loss_bbox: 0.3202, loss: 0.8079, grad_norm: 8.2311
2025-08-03 21:45:49,102 - mmdet - INFO - Epoch [3][100/2935]	lr: 5.000e-03, eta: 0:32:06, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1225, loss_rpn_bbox: 0.1256, loss_cls: 0.3067, acc: 89.8840, loss_bbox: 0.3779, loss: 0.9327, grad_norm: 9.2209
2025-08-03 21:46:05,653 - mmdet - INFO - Epoch [3][150/2935]	lr: 5.000e-03, eta: 0:31:50, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1392, loss_rpn_bbox: 0.0996, loss_cls: 0.3023, acc: 89.9875, loss_bbox: 0.3685, loss: 0.9095, grad_norm: 8.5728
2025-08-03 21:46:22,059 - mmdet - INFO - Epoch [3][200/2935]	lr: 5.000e-03, eta: 0:31:33, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1252, loss_rpn_bbox: 0.1093, loss_cls: 0.2747, acc: 91.5470, loss_bbox: 0.2985, loss: 0.8078, grad_norm: 8.6924
2025-08-03 21:46:38,571 - mmdet - INFO - Epoch [3][250/2935]	lr: 5.000e-03, eta: 0:31:16, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1174, loss_rpn_bbox: 0.1107, loss_cls: 0.2731, acc: 91.6404, loss_bbox: 0.3192, loss: 0.8205, grad_norm: 8.2508
2025-08-03 21:46:55,005 - mmdet - INFO - Epoch [3][300/2935]	lr: 5.000e-03, eta: 0:30:59, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1205, loss_rpn_bbox: 0.1127, loss_cls: 0.2790, acc: 92.0061, loss_bbox: 0.2902, loss: 0.8025, grad_norm: 8.0696
2025-08-03 21:47:11,591 - mmdet - INFO - Epoch [3][350/2935]	lr: 5.000e-03, eta: 0:30:42, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1115, loss_rpn_bbox: 0.1081, loss_cls: 0.2606, acc: 91.7825, loss_bbox: 0.3098, loss: 0.7899, grad_norm: 8.0042
2025-08-03 21:47:28,344 - mmdet - INFO - Epoch [3][400/2935]	lr: 5.000e-03, eta: 0:30:25, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1364, loss_rpn_bbox: 0.1209, loss_cls: 0.2950, acc: 90.9631, loss_bbox: 0.3454, loss: 0.8978, grad_norm: 9.4570
2025-08-03 21:47:44,775 - mmdet - INFO - Epoch [3][450/2935]	lr: 5.000e-03, eta: 0:30:09, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1258, loss_rpn_bbox: 0.1198, loss_cls: 0.2825, acc: 90.9258, loss_bbox: 0.3258, loss: 0.8538, grad_norm: 8.6094
2025-08-03 21:48:01,374 - mmdet - INFO - Epoch [3][500/2935]	lr: 5.000e-03, eta: 0:29:52, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1422, loss_rpn_bbox: 0.1384, loss_cls: 0.3130, acc: 90.1809, loss_bbox: 0.3462, loss: 0.9398, grad_norm: 9.0553
2025-08-03 21:48:18,043 - mmdet - INFO - Epoch [3][550/2935]	lr: 5.000e-03, eta: 0:29:35, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1148, loss_rpn_bbox: 0.0920, loss_cls: 0.2780, acc: 91.1456, loss_bbox: 0.3275, loss: 0.8123, grad_norm: 9.0416
2025-08-03 21:48:34,854 - mmdet - INFO - Epoch [3][600/2935]	lr: 5.000e-03, eta: 0:29:18, time: 0.336, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1103, loss_rpn_bbox: 0.1045, loss_cls: 0.2546, acc: 92.2318, loss_bbox: 0.2875, loss: 0.7569, grad_norm: 8.0620
2025-08-03 21:48:51,358 - mmdet - INFO - Epoch [3][650/2935]	lr: 5.000e-03, eta: 0:29:02, time: 0.330, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1513, loss_rpn_bbox: 0.1384, loss_cls: 0.3244, acc: 89.9275, loss_bbox: 0.3515, loss: 0.9656, grad_norm: 9.9336
2025-08-03 21:49:07,887 - mmdet - INFO - Epoch [3][700/2935]	lr: 5.000e-03, eta: 0:28:45, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1081, loss_rpn_bbox: 0.1133, loss_cls: 0.2643, acc: 91.4631, loss_bbox: 0.3128, loss: 0.7985, grad_norm: 8.4549
2025-08-03 21:49:24,686 - mmdet - INFO - Epoch [3][750/2935]	lr: 5.000e-03, eta: 0:28:28, time: 0.336, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1141, loss_rpn_bbox: 0.1037, loss_cls: 0.2670, acc: 91.6486, loss_bbox: 0.3038, loss: 0.7886, grad_norm: 8.3519
2025-08-03 21:49:41,049 - mmdet - INFO - Epoch [3][800/2935]	lr: 5.000e-03, eta: 0:28:11, time: 0.327, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1301, loss_rpn_bbox: 0.1282, loss_cls: 0.2907, acc: 90.7017, loss_bbox: 0.3435, loss: 0.8925, grad_norm: 8.3318
2025-08-03 21:49:57,563 - mmdet - INFO - Epoch [3][850/2935]	lr: 5.000e-03, eta: 0:27:54, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1262, loss_rpn_bbox: 0.0986, loss_cls: 0.2637, acc: 91.3599, loss_bbox: 0.3091, loss: 0.7976, grad_norm: 8.2808
2025-08-03 21:50:13,735 - mmdet - INFO - Epoch [3][900/2935]	lr: 5.000e-03, eta: 0:27:37, time: 0.323, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1251, loss_rpn_bbox: 0.1216, loss_cls: 0.2902, acc: 90.9245, loss_bbox: 0.3170, loss: 0.8539, grad_norm: 9.2829
2025-08-03 21:50:30,370 - mmdet - INFO - Epoch [3][950/2935]	lr: 5.000e-03, eta: 0:27:21, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1545, loss_rpn_bbox: 0.1069, loss_cls: 0.2672, acc: 91.2767, loss_bbox: 0.3281, loss: 0.8568, grad_norm: 8.3762
2025-08-03 21:50:46,910 - mmdet - INFO - Epoch [3][1000/2935]	lr: 5.000e-03, eta: 0:27:04, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1026, loss_rpn_bbox: 0.1030, loss_cls: 0.2467, acc: 91.8137, loss_bbox: 0.3023, loss: 0.7545, grad_norm: 7.8675
2025-08-03 21:51:03,678 - mmdet - INFO - Epoch [3][1050/2935]	lr: 5.000e-03, eta: 0:26:47, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1210, loss_rpn_bbox: 0.1000, loss_cls: 0.2747, acc: 91.0367, loss_bbox: 0.3223, loss: 0.8180, grad_norm: 9.1478
2025-08-03 21:51:20,310 - mmdet - INFO - Epoch [3][1100/2935]	lr: 5.000e-03, eta: 0:26:31, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1297, loss_rpn_bbox: 0.1158, loss_cls: 0.2795, acc: 91.1395, loss_bbox: 0.3270, loss: 0.8520, grad_norm: 9.0512
2025-08-03 21:51:36,933 - mmdet - INFO - Epoch [3][1150/2935]	lr: 5.000e-03, eta: 0:26:14, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1306, loss_rpn_bbox: 0.1282, loss_cls: 0.2709, acc: 91.1109, loss_bbox: 0.3171, loss: 0.8468, grad_norm: 8.5448
2025-08-03 21:51:53,586 - mmdet - INFO - Epoch [3][1200/2935]	lr: 5.000e-03, eta: 0:25:57, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1353, loss_rpn_bbox: 0.0983, loss_cls: 0.2872, acc: 91.2942, loss_bbox: 0.3258, loss: 0.8466, grad_norm: 8.9155
2025-08-03 21:52:09,568 - mmdet - INFO - Epoch [3][1250/2935]	lr: 5.000e-03, eta: 0:25:40, time: 0.320, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1308, loss_rpn_bbox: 0.1233, loss_cls: 0.2671, acc: 91.6362, loss_bbox: 0.3119, loss: 0.8331, grad_norm: 8.6782
2025-08-03 21:52:26,280 - mmdet - INFO - Epoch [3][1300/2935]	lr: 5.000e-03, eta: 0:25:23, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1174, loss_rpn_bbox: 0.0866, loss_cls: 0.2355, acc: 92.7049, loss_bbox: 0.2593, loss: 0.6988, grad_norm: 8.3029
2025-08-03 21:52:42,444 - mmdet - INFO - Epoch [3][1350/2935]	lr: 5.000e-03, eta: 0:25:06, time: 0.323, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1474, loss_rpn_bbox: 0.1268, loss_cls: 0.2731, acc: 91.5262, loss_bbox: 0.3097, loss: 0.8571, grad_norm: 8.2277
2025-08-03 21:52:58,616 - mmdet - INFO - Epoch [3][1400/2935]	lr: 5.000e-03, eta: 0:24:49, time: 0.323, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1225, loss_rpn_bbox: 0.1447, loss_cls: 0.2915, acc: 90.6562, loss_bbox: 0.3212, loss: 0.8798, grad_norm: 9.1103
2025-08-03 21:53:15,261 - mmdet - INFO - Epoch [3][1450/2935]	lr: 5.000e-03, eta: 0:24:33, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1360, loss_rpn_bbox: 0.1290, loss_cls: 0.2900, acc: 91.2292, loss_bbox: 0.3098, loss: 0.8648, grad_norm: 9.1307
2025-08-03 21:53:31,428 - mmdet - INFO - Epoch [3][1500/2935]	lr: 5.000e-03, eta: 0:24:16, time: 0.323, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1351, loss_rpn_bbox: 0.1082, loss_cls: 0.3181, acc: 90.4623, loss_bbox: 0.3296, loss: 0.8911, grad_norm: 9.5139
2025-08-03 21:53:48,126 - mmdet - INFO - Epoch [3][1550/2935]	lr: 5.000e-03, eta: 0:23:59, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1434, loss_rpn_bbox: 0.0961, loss_cls: 0.2903, acc: 90.7049, loss_bbox: 0.3281, loss: 0.8578, grad_norm: 8.5361
2025-08-03 21:54:05,008 - mmdet - INFO - Epoch [3][1600/2935]	lr: 5.000e-03, eta: 0:23:43, time: 0.338, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1427, loss_rpn_bbox: 0.1420, loss_cls: 0.3566, acc: 88.7923, loss_bbox: 0.3798, loss: 1.0211, grad_norm: 9.4738
2025-08-03 21:54:21,386 - mmdet - INFO - Epoch [3][1650/2935]	lr: 5.000e-03, eta: 0:23:26, time: 0.328, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1198, loss_rpn_bbox: 0.1181, loss_cls: 0.3019, acc: 91.2257, loss_bbox: 0.3003, loss: 0.8402, grad_norm: 8.6239
2025-08-03 21:54:38,204 - mmdet - INFO - Epoch [3][1700/2935]	lr: 5.000e-03, eta: 0:23:09, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1161, loss_rpn_bbox: 0.1132, loss_cls: 0.2742, acc: 91.0673, loss_bbox: 0.3292, loss: 0.8327, grad_norm: 8.2311
2025-08-03 21:54:54,778 - mmdet - INFO - Epoch [3][1750/2935]	lr: 5.000e-03, eta: 0:22:53, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1224, loss_rpn_bbox: 0.1112, loss_cls: 0.2943, acc: 90.9881, loss_bbox: 0.3298, loss: 0.8577, grad_norm: 8.1871
2025-08-03 21:55:11,749 - mmdet - INFO - Epoch [3][1800/2935]	lr: 5.000e-03, eta: 0:22:36, time: 0.339, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1192, loss_rpn_bbox: 0.1041, loss_cls: 0.2678, acc: 91.4000, loss_bbox: 0.3099, loss: 0.8010, grad_norm: 8.2463
2025-08-03 21:55:28,342 - mmdet - INFO - Epoch [3][1850/2935]	lr: 5.000e-03, eta: 0:22:19, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1336, loss_rpn_bbox: 0.1222, loss_cls: 0.2833, acc: 90.9716, loss_bbox: 0.3266, loss: 0.8657, grad_norm: 8.8581
2025-08-03 21:55:45,012 - mmdet - INFO - Epoch [3][1900/2935]	lr: 5.000e-03, eta: 0:22:03, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1213, loss_rpn_bbox: 0.0910, loss_cls: 0.2492, acc: 91.5214, loss_bbox: 0.3121, loss: 0.7736, grad_norm: 8.1372
2025-08-03 21:56:01,923 - mmdet - INFO - Epoch [3][1950/2935]	lr: 5.000e-03, eta: 0:21:46, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1300, loss_rpn_bbox: 0.1130, loss_cls: 0.2947, acc: 90.6564, loss_bbox: 0.3306, loss: 0.8683, grad_norm: 9.3422
2025-08-03 21:56:18,871 - mmdet - INFO - Epoch [3][2000/2935]	lr: 5.000e-03, eta: 0:21:30, time: 0.339, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1180, loss_rpn_bbox: 0.0961, loss_cls: 0.2613, acc: 91.8737, loss_bbox: 0.2971, loss: 0.7725, grad_norm: 8.3338
2025-08-03 21:56:35,930 - mmdet - INFO - Epoch [3][2050/2935]	lr: 5.000e-03, eta: 0:21:13, time: 0.341, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1352, loss_rpn_bbox: 0.1078, loss_cls: 0.2797, acc: 90.7750, loss_bbox: 0.3354, loss: 0.8582, grad_norm: 8.8577
2025-08-03 21:56:52,638 - mmdet - INFO - Epoch [3][2100/2935]	lr: 5.000e-03, eta: 0:20:56, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1112, loss_rpn_bbox: 0.1019, loss_cls: 0.2468, acc: 92.2602, loss_bbox: 0.2980, loss: 0.7580, grad_norm: 8.4200
2025-08-03 21:57:09,376 - mmdet - INFO - Epoch [3][2150/2935]	lr: 5.000e-03, eta: 0:20:40, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1319, loss_rpn_bbox: 0.1282, loss_cls: 0.3176, acc: 90.0978, loss_bbox: 0.3359, loss: 0.9135, grad_norm: 9.9052
2025-08-03 21:57:26,267 - mmdet - INFO - Epoch [3][2200/2935]	lr: 5.000e-03, eta: 0:20:23, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1156, loss_rpn_bbox: 0.1037, loss_cls: 0.2882, acc: 91.0092, loss_bbox: 0.3220, loss: 0.8295, grad_norm: 8.9741
2025-08-03 21:57:43,346 - mmdet - INFO - Epoch [3][2250/2935]	lr: 5.000e-03, eta: 0:20:07, time: 0.342, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1149, loss_rpn_bbox: 0.0971, loss_cls: 0.2447, acc: 91.9562, loss_bbox: 0.2907, loss: 0.7474, grad_norm: 8.1038
2025-08-03 21:58:00,172 - mmdet - INFO - Epoch [3][2300/2935]	lr: 5.000e-03, eta: 0:19:50, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1221, loss_rpn_bbox: 0.1118, loss_cls: 0.2822, acc: 90.7650, loss_bbox: 0.3270, loss: 0.8431, grad_norm: 8.5927
2025-08-03 21:58:17,129 - mmdet - INFO - Epoch [3][2350/2935]	lr: 5.000e-03, eta: 0:19:34, time: 0.339, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1224, loss_rpn_bbox: 0.1175, loss_cls: 0.2849, acc: 90.8945, loss_bbox: 0.3338, loss: 0.8586, grad_norm: 9.0434
2025-08-03 21:58:33,520 - mmdet - INFO - Epoch [3][2400/2935]	lr: 5.000e-03, eta: 0:19:17, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1413, loss_rpn_bbox: 0.1145, loss_cls: 0.2845, acc: 91.1101, loss_bbox: 0.3068, loss: 0.8472, grad_norm: 9.3531
2025-08-03 21:58:49,992 - mmdet - INFO - Epoch [3][2450/2935]	lr: 5.000e-03, eta: 0:19:00, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1246, loss_rpn_bbox: 0.1108, loss_cls: 0.2596, acc: 91.6832, loss_bbox: 0.3068, loss: 0.8019, grad_norm: 8.3378
2025-08-03 21:59:06,528 - mmdet - INFO - Epoch [3][2500/2935]	lr: 5.000e-03, eta: 0:18:43, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1208, loss_rpn_bbox: 0.1096, loss_cls: 0.2655, acc: 91.6143, loss_bbox: 0.2929, loss: 0.7888, grad_norm: 9.1697
2025-08-03 21:59:22,994 - mmdet - INFO - Epoch [3][2550/2935]	lr: 5.000e-03, eta: 0:18:27, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1323, loss_rpn_bbox: 0.1329, loss_cls: 0.2627, acc: 91.7737, loss_bbox: 0.2880, loss: 0.8159, grad_norm: 8.5963
2025-08-03 21:59:39,693 - mmdet - INFO - Epoch [3][2600/2935]	lr: 5.000e-03, eta: 0:18:10, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1305, loss_rpn_bbox: 0.1035, loss_cls: 0.2897, acc: 90.2892, loss_bbox: 0.3298, loss: 0.8534, grad_norm: 9.3901
2025-08-03 21:59:56,385 - mmdet - INFO - Epoch [3][2650/2935]	lr: 5.000e-03, eta: 0:17:53, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1274, loss_rpn_bbox: 0.1160, loss_cls: 0.2926, acc: 90.7587, loss_bbox: 0.3212, loss: 0.8572, grad_norm: 8.8243
2025-08-03 22:00:13,082 - mmdet - INFO - Epoch [3][2700/2935]	lr: 5.000e-03, eta: 0:17:37, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1234, loss_rpn_bbox: 0.1050, loss_cls: 0.2696, acc: 91.0973, loss_bbox: 0.3229, loss: 0.8208, grad_norm: 8.8457
2025-08-03 22:00:29,698 - mmdet - INFO - Epoch [3][2750/2935]	lr: 5.000e-03, eta: 0:17:20, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1224, loss_rpn_bbox: 0.1145, loss_cls: 0.3287, acc: 89.8270, loss_bbox: 0.3553, loss: 0.9209, grad_norm: 10.3287
2025-08-03 22:00:46,606 - mmdet - INFO - Epoch [3][2800/2935]	lr: 5.000e-03, eta: 0:17:03, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1191, loss_rpn_bbox: 0.1152, loss_cls: 0.3207, acc: 90.1512, loss_bbox: 0.3218, loss: 0.8768, grad_norm: 10.1211
2025-08-03 22:01:03,675 - mmdet - INFO - Epoch [3][2850/2935]	lr: 5.000e-03, eta: 0:16:47, time: 0.341, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1301, loss_rpn_bbox: 0.1184, loss_cls: 0.2672, acc: 91.8980, loss_bbox: 0.3019, loss: 0.8175, grad_norm: 8.1436
2025-08-03 22:01:20,704 - mmdet - INFO - Epoch [3][2900/2935]	lr: 5.000e-03, eta: 0:16:30, time: 0.341, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1282, loss_rpn_bbox: 0.1008, loss_cls: 0.2577, acc: 91.6073, loss_bbox: 0.3063, loss: 0.7930, grad_norm: 8.5580
2025-08-03 22:02:04,540 - mmdet - INFO - Epoch [4][50/2935]	lr: 5.000e-04, eta: 0:16:03, time: 0.623, data_time: 0.291, memory: 12372, loss_rpn_cls: 0.1219, loss_rpn_bbox: 0.0995, loss_cls: 0.2522, acc: 91.8307, loss_bbox: 0.3005, loss: 0.7741, grad_norm: 7.8317
2025-08-03 22:02:21,394 - mmdet - INFO - Epoch [4][100/2935]	lr: 5.000e-04, eta: 0:15:46, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1001, loss_rpn_bbox: 0.0849, loss_cls: 0.2558, acc: 91.5492, loss_bbox: 0.2958, loss: 0.7365, grad_norm: 7.8242
2025-08-03 22:02:38,264 - mmdet - INFO - Epoch [4][150/2935]	lr: 5.000e-04, eta: 0:15:29, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1111, loss_rpn_bbox: 0.0914, loss_cls: 0.2396, acc: 91.5480, loss_bbox: 0.3043, loss: 0.7464, grad_norm: 7.6170
2025-08-03 22:02:54,853 - mmdet - INFO - Epoch [4][200/2935]	lr: 5.000e-04, eta: 0:15:13, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1065, loss_rpn_bbox: 0.0867, loss_cls: 0.2351, acc: 92.0662, loss_bbox: 0.3037, loss: 0.7322, grad_norm: 7.4745
2025-08-03 22:03:11,528 - mmdet - INFO - Epoch [4][250/2935]	lr: 5.000e-04, eta: 0:14:56, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1234, loss_rpn_bbox: 0.1133, loss_cls: 0.2587, acc: 91.5601, loss_bbox: 0.3157, loss: 0.8111, grad_norm: 7.7210
2025-08-03 22:03:28,290 - mmdet - INFO - Epoch [4][300/2935]	lr: 5.000e-04, eta: 0:14:39, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1305, loss_rpn_bbox: 0.1094, loss_cls: 0.2744, acc: 90.5543, loss_bbox: 0.3466, loss: 0.8609, grad_norm: 8.1386
2025-08-03 22:03:45,021 - mmdet - INFO - Epoch [4][350/2935]	lr: 5.000e-04, eta: 0:14:23, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1084, loss_rpn_bbox: 0.0892, loss_cls: 0.2295, acc: 92.2309, loss_bbox: 0.2870, loss: 0.7140, grad_norm: 7.6441
2025-08-03 22:04:01,673 - mmdet - INFO - Epoch [4][400/2935]	lr: 5.000e-04, eta: 0:14:06, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1147, loss_rpn_bbox: 0.1083, loss_cls: 0.2487, acc: 91.8810, loss_bbox: 0.3119, loss: 0.7836, grad_norm: 7.4726
2025-08-03 22:04:18,231 - mmdet - INFO - Epoch [4][450/2935]	lr: 5.000e-04, eta: 0:13:49, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1200, loss_rpn_bbox: 0.1020, loss_cls: 0.2637, acc: 91.0280, loss_bbox: 0.3506, loss: 0.8364, grad_norm: 7.9712
2025-08-03 22:04:34,914 - mmdet - INFO - Epoch [4][500/2935]	lr: 5.000e-04, eta: 0:13:33, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1136, loss_rpn_bbox: 0.1106, loss_cls: 0.2515, acc: 91.6234, loss_bbox: 0.3135, loss: 0.7892, grad_norm: 8.2193
2025-08-03 22:04:51,754 - mmdet - INFO - Epoch [4][550/2935]	lr: 5.000e-04, eta: 0:13:16, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1119, loss_rpn_bbox: 0.0975, loss_cls: 0.2356, acc: 92.0571, loss_bbox: 0.2896, loss: 0.7345, grad_norm: 7.5315
2025-08-03 22:05:08,118 - mmdet - INFO - Epoch [4][600/2935]	lr: 5.000e-04, eta: 0:12:59, time: 0.327, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0998, loss_rpn_bbox: 0.1135, loss_cls: 0.2190, acc: 92.4862, loss_bbox: 0.2829, loss: 0.7151, grad_norm: 7.6198
2025-08-03 22:05:24,291 - mmdet - INFO - Epoch [4][650/2935]	lr: 5.000e-04, eta: 0:12:42, time: 0.323, data_time: 0.006, memory: 12372, loss_rpn_cls: 0.1074, loss_rpn_bbox: 0.1282, loss_cls: 0.2544, acc: 91.4086, loss_bbox: 0.3143, loss: 0.8042, grad_norm: 7.9728
2025-08-03 22:05:40,698 - mmdet - INFO - Epoch [4][700/2935]	lr: 5.000e-04, eta: 0:12:26, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1194, loss_rpn_bbox: 0.1118, loss_cls: 0.2576, acc: 91.6005, loss_bbox: 0.3272, loss: 0.8161, grad_norm: 8.2297
2025-08-03 22:05:57,214 - mmdet - INFO - Epoch [4][750/2935]	lr: 5.000e-04, eta: 0:12:09, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1077, loss_rpn_bbox: 0.0858, loss_cls: 0.2685, acc: 91.3435, loss_bbox: 0.3290, loss: 0.7910, grad_norm: 8.1924
2025-08-03 22:06:13,853 - mmdet - INFO - Epoch [4][800/2935]	lr: 5.000e-04, eta: 0:11:52, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1115, loss_rpn_bbox: 0.0997, loss_cls: 0.2536, acc: 91.8831, loss_bbox: 0.3061, loss: 0.7709, grad_norm: 7.7641
2025-08-03 22:06:30,598 - mmdet - INFO - Epoch [4][850/2935]	lr: 5.000e-04, eta: 0:11:35, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1070, loss_rpn_bbox: 0.1063, loss_cls: 0.2667, acc: 90.9391, loss_bbox: 0.3343, loss: 0.8143, grad_norm: 7.8637
2025-08-03 22:06:47,353 - mmdet - INFO - Epoch [4][900/2935]	lr: 5.000e-04, eta: 0:11:19, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1116, loss_rpn_bbox: 0.0967, loss_cls: 0.2669, acc: 90.8253, loss_bbox: 0.3569, loss: 0.8321, grad_norm: 7.8624
2025-08-03 22:07:03,858 - mmdet - INFO - Epoch [4][950/2935]	lr: 5.000e-04, eta: 0:11:02, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1055, loss_rpn_bbox: 0.1011, loss_cls: 0.2567, acc: 91.5778, loss_bbox: 0.3123, loss: 0.7756, grad_norm: 8.0801
2025-08-03 22:07:20,510 - mmdet - INFO - Epoch [4][1000/2935]	lr: 5.000e-04, eta: 0:10:45, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1019, loss_rpn_bbox: 0.0844, loss_cls: 0.2441, acc: 91.7692, loss_bbox: 0.3121, loss: 0.7425, grad_norm: 7.5563
2025-08-03 22:07:37,355 - mmdet - INFO - Epoch [4][1050/2935]	lr: 5.000e-04, eta: 0:10:29, time: 0.337, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1045, loss_rpn_bbox: 0.0822, loss_cls: 0.2237, acc: 92.3468, loss_bbox: 0.2899, loss: 0.7004, grad_norm: 7.5208
2025-08-03 22:07:54,239 - mmdet - INFO - Epoch [4][1100/2935]	lr: 5.000e-04, eta: 0:10:12, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1099, loss_rpn_bbox: 0.0938, loss_cls: 0.2239, acc: 92.3123, loss_bbox: 0.2921, loss: 0.7197, grad_norm: 7.6487
2025-08-03 22:08:10,953 - mmdet - INFO - Epoch [4][1150/2935]	lr: 5.000e-04, eta: 0:09:55, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1087, loss_rpn_bbox: 0.1157, loss_cls: 0.2584, acc: 91.0982, loss_bbox: 0.3354, loss: 0.8183, grad_norm: 8.0249
2025-08-03 22:08:27,490 - mmdet - INFO - Epoch [4][1200/2935]	lr: 5.000e-04, eta: 0:09:39, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1156, loss_rpn_bbox: 0.1230, loss_cls: 0.2692, acc: 90.5317, loss_bbox: 0.3481, loss: 0.8559, grad_norm: 8.2643
2025-08-03 22:08:43,793 - mmdet - INFO - Epoch [4][1250/2935]	lr: 5.000e-04, eta: 0:09:22, time: 0.326, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1007, loss_rpn_bbox: 0.0979, loss_cls: 0.2332, acc: 92.3487, loss_bbox: 0.2751, loss: 0.7069, grad_norm: 7.9689
2025-08-03 22:09:00,376 - mmdet - INFO - Epoch [4][1300/2935]	lr: 5.000e-04, eta: 0:09:05, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1136, loss_rpn_bbox: 0.1145, loss_cls: 0.2526, acc: 91.7898, loss_bbox: 0.3175, loss: 0.7982, grad_norm: 7.9330
2025-08-03 22:09:16,885 - mmdet - INFO - Epoch [4][1350/2935]	lr: 5.000e-04, eta: 0:08:48, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1086, loss_rpn_bbox: 0.1002, loss_cls: 0.2317, acc: 92.2026, loss_bbox: 0.3097, loss: 0.7501, grad_norm: 7.7520
2025-08-03 22:09:33,429 - mmdet - INFO - Epoch [4][1400/2935]	lr: 5.000e-04, eta: 0:08:32, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1135, loss_rpn_bbox: 0.1005, loss_cls: 0.2541, acc: 91.6978, loss_bbox: 0.3019, loss: 0.7700, grad_norm: 8.3149
2025-08-03 22:09:50,106 - mmdet - INFO - Epoch [4][1450/2935]	lr: 5.000e-04, eta: 0:08:15, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1138, loss_rpn_bbox: 0.1027, loss_cls: 0.2459, acc: 91.7514, loss_bbox: 0.3098, loss: 0.7721, grad_norm: 8.2510
2025-08-03 22:10:06,668 - mmdet - INFO - Epoch [4][1500/2935]	lr: 5.000e-04, eta: 0:07:58, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1135, loss_rpn_bbox: 0.1063, loss_cls: 0.2495, acc: 91.4375, loss_bbox: 0.3347, loss: 0.8040, grad_norm: 7.9762
2025-08-03 22:10:23,100 - mmdet - INFO - Epoch [4][1550/2935]	lr: 5.000e-04, eta: 0:07:42, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1157, loss_rpn_bbox: 0.1214, loss_cls: 0.2625, acc: 91.0966, loss_bbox: 0.3222, loss: 0.8218, grad_norm: 8.4123
2025-08-03 22:10:39,732 - mmdet - INFO - Epoch [4][1600/2935]	lr: 5.000e-04, eta: 0:07:25, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0968, loss_rpn_bbox: 0.0985, loss_cls: 0.2272, acc: 92.3232, loss_bbox: 0.2771, loss: 0.6996, grad_norm: 7.6529
2025-08-03 22:10:56,250 - mmdet - INFO - Epoch [4][1650/2935]	lr: 5.000e-04, eta: 0:07:08, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1139, loss_rpn_bbox: 0.0985, loss_cls: 0.2616, acc: 91.1210, loss_bbox: 0.3323, loss: 0.8063, grad_norm: 8.3004
2025-08-03 22:11:12,678 - mmdet - INFO - Epoch [4][1700/2935]	lr: 5.000e-04, eta: 0:06:52, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1035, loss_rpn_bbox: 0.1090, loss_cls: 0.2252, acc: 92.2681, loss_bbox: 0.2939, loss: 0.7317, grad_norm: 7.4862
2025-08-03 22:11:29,178 - mmdet - INFO - Epoch [4][1750/2935]	lr: 5.000e-04, eta: 0:06:35, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1134, loss_rpn_bbox: 0.0868, loss_cls: 0.2624, acc: 91.3559, loss_bbox: 0.3147, loss: 0.7772, grad_norm: 8.4980
2025-08-03 22:11:45,695 - mmdet - INFO - Epoch [4][1800/2935]	lr: 5.000e-04, eta: 0:06:18, time: 0.330, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1050, loss_rpn_bbox: 0.0815, loss_cls: 0.2264, acc: 92.1781, loss_bbox: 0.2888, loss: 0.7016, grad_norm: 7.7704
2025-08-03 22:12:02,418 - mmdet - INFO - Epoch [4][1850/2935]	lr: 5.000e-04, eta: 0:06:01, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1157, loss_rpn_bbox: 0.0982, loss_cls: 0.2751, acc: 90.8926, loss_bbox: 0.3544, loss: 0.8435, grad_norm: 8.2576
2025-08-03 22:12:19,036 - mmdet - INFO - Epoch [4][1900/2935]	lr: 5.000e-04, eta: 0:05:45, time: 0.332, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1124, loss_rpn_bbox: 0.1030, loss_cls: 0.2261, acc: 92.4486, loss_bbox: 0.2963, loss: 0.7378, grad_norm: 7.9008
2025-08-03 22:12:35,458 - mmdet - INFO - Epoch [4][1950/2935]	lr: 5.000e-04, eta: 0:05:28, time: 0.328, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1067, loss_rpn_bbox: 0.0992, loss_cls: 0.2295, acc: 92.2073, loss_bbox: 0.2819, loss: 0.7174, grad_norm: 8.2598
2025-08-03 22:12:52,445 - mmdet - INFO - Epoch [4][2000/2935]	lr: 5.000e-04, eta: 0:05:11, time: 0.340, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1047, loss_rpn_bbox: 0.0870, loss_cls: 0.2257, acc: 92.3469, loss_bbox: 0.2980, loss: 0.7154, grad_norm: 8.4724
2025-08-03 22:13:08,915 - mmdet - INFO - Epoch [4][2050/2935]	lr: 5.000e-04, eta: 0:04:55, time: 0.329, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1171, loss_rpn_bbox: 0.0950, loss_cls: 0.2293, acc: 92.1164, loss_bbox: 0.3035, loss: 0.7449, grad_norm: 7.9054
2025-08-03 22:13:25,725 - mmdet - INFO - Epoch [4][2100/2935]	lr: 5.000e-04, eta: 0:04:38, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1212, loss_rpn_bbox: 0.0915, loss_cls: 0.2505, acc: 91.6254, loss_bbox: 0.3137, loss: 0.7769, grad_norm: 8.4197
2025-08-03 22:13:42,354 - mmdet - INFO - Epoch [4][2150/2935]	lr: 5.000e-04, eta: 0:04:21, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0979, loss_rpn_bbox: 0.0932, loss_cls: 0.2071, acc: 93.1928, loss_bbox: 0.2569, loss: 0.6552, grad_norm: 7.3353
2025-08-03 22:13:59,169 - mmdet - INFO - Epoch [4][2200/2935]	lr: 5.000e-04, eta: 0:04:05, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0991, loss_rpn_bbox: 0.0761, loss_cls: 0.2367, acc: 92.0863, loss_bbox: 0.3080, loss: 0.7200, grad_norm: 7.5689
2025-08-03 22:14:15,730 - mmdet - INFO - Epoch [4][2250/2935]	lr: 5.000e-04, eta: 0:03:48, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0937, loss_rpn_bbox: 0.0916, loss_cls: 0.2115, acc: 92.5589, loss_bbox: 0.2864, loss: 0.6831, grad_norm: 7.7922
2025-08-03 22:14:32,301 - mmdet - INFO - Epoch [4][2300/2935]	lr: 5.000e-04, eta: 0:03:31, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1207, loss_rpn_bbox: 0.0863, loss_cls: 0.2522, acc: 91.6625, loss_bbox: 0.3327, loss: 0.7919, grad_norm: 8.4386
2025-08-03 22:14:49,268 - mmdet - INFO - Epoch [4][2350/2935]	lr: 5.000e-04, eta: 0:03:15, time: 0.339, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1021, loss_rpn_bbox: 0.0852, loss_cls: 0.2321, acc: 92.0764, loss_bbox: 0.3019, loss: 0.7213, grad_norm: 7.9863
2025-08-03 22:15:06,163 - mmdet - INFO - Epoch [4][2400/2935]	lr: 5.000e-04, eta: 0:02:58, time: 0.338, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1115, loss_rpn_bbox: 0.0893, loss_cls: 0.2345, acc: 92.4719, loss_bbox: 0.2818, loss: 0.7171, grad_norm: 7.7014
2025-08-03 22:15:22,790 - mmdet - INFO - Epoch [4][2450/2935]	lr: 5.000e-04, eta: 0:02:41, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1024, loss_rpn_bbox: 0.0933, loss_cls: 0.2524, acc: 91.6269, loss_bbox: 0.3118, loss: 0.7600, grad_norm: 8.4985
2025-08-03 22:15:39,417 - mmdet - INFO - Epoch [4][2500/2935]	lr: 5.000e-04, eta: 0:02:25, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1065, loss_rpn_bbox: 0.0960, loss_cls: 0.2527, acc: 91.4855, loss_bbox: 0.3216, loss: 0.7768, grad_norm: 8.1752
2025-08-03 22:15:56,241 - mmdet - INFO - Epoch [4][2550/2935]	lr: 5.000e-04, eta: 0:02:08, time: 0.336, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1032, loss_rpn_bbox: 0.1029, loss_cls: 0.2372, acc: 92.1718, loss_bbox: 0.2961, loss: 0.7394, grad_norm: 7.9475
2025-08-03 22:16:12,911 - mmdet - INFO - Epoch [4][2600/2935]	lr: 5.000e-04, eta: 0:01:51, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1194, loss_rpn_bbox: 0.1071, loss_cls: 0.2531, acc: 91.7185, loss_bbox: 0.3200, loss: 0.7996, grad_norm: 8.6572
2025-08-03 22:16:29,581 - mmdet - INFO - Epoch [4][2650/2935]	lr: 5.000e-04, eta: 0:01:35, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1089, loss_rpn_bbox: 0.0980, loss_cls: 0.2316, acc: 92.0955, loss_bbox: 0.2978, loss: 0.7362, grad_norm: 8.0421
2025-08-03 22:16:46,277 - mmdet - INFO - Epoch [4][2700/2935]	lr: 5.000e-04, eta: 0:01:18, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1040, loss_rpn_bbox: 0.0908, loss_cls: 0.2515, acc: 91.7363, loss_bbox: 0.3166, loss: 0.7629, grad_norm: 8.3138
2025-08-03 22:17:02,851 - mmdet - INFO - Epoch [4][2750/2935]	lr: 5.000e-04, eta: 0:01:01, time: 0.331, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1086, loss_rpn_bbox: 0.0836, loss_cls: 0.2351, acc: 92.0422, loss_bbox: 0.3009, loss: 0.7282, grad_norm: 8.1797
2025-08-03 22:17:19,584 - mmdet - INFO - Epoch [4][2800/2935]	lr: 5.000e-04, eta: 0:00:45, time: 0.335, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1072, loss_rpn_bbox: 0.1183, loss_cls: 0.2423, acc: 91.8513, loss_bbox: 0.3112, loss: 0.7790, grad_norm: 8.7242
2025-08-03 22:17:36,224 - mmdet - INFO - Epoch [4][2850/2935]	lr: 5.000e-04, eta: 0:00:28, time: 0.333, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.1051, loss_rpn_bbox: 0.1025, loss_cls: 0.2624, acc: 90.9612, loss_bbox: 0.3279, loss: 0.7979, grad_norm: 8.7213
2025-08-03 22:17:52,902 - mmdet - INFO - Epoch [4][2900/2935]	lr: 5.000e-04, eta: 0:00:11, time: 0.334, data_time: 0.005, memory: 12372, loss_rpn_cls: 0.0971, loss_rpn_bbox: 0.0784, loss_cls: 0.2111, acc: 92.8840, loss_bbox: 0.2870, loss: 0.6735, grad_norm: 7.8019
2025-08-03 22:18:05,361 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-08-03 22:19:02,163 - mmdet - INFO - Evaluating bbox...
2025-08-03 22:19:11,619 - mmdet - INFO - Exp name: clip_end2end_faster_rcnn_r50_c4_1x_coco.py
2025-08-03 22:19:11,619 - mmdet - INFO - Epoch(val) [4][850]	bbox_mAP: 0.1790, bbox_mAP_50: 0.3520, bbox_mAP_75: 0.1700, bbox_mAP_s: 0.0860, bbox_mAP_m: 0.2190, bbox_mAP_l: 0.2590, bbox_mAP_copypaste: 0.179 0.352 0.170 0.086 0.219 0.259
