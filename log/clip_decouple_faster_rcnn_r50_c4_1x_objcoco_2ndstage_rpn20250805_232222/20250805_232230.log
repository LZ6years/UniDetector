2025-08-05 23:22:30,792 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 4090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.8.r11.8/compiler.31833905_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.10.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0+cu111
OpenCV: 4.12.0
MMCV: 1.3.17
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.18.0+eb18253
------------------------------------------------------------

2025-08-05 23:22:32,905 - mmdet - INFO - Distributed training: True
2025-08-05 23:22:34,908 - mmdet - INFO - Config:
checkpoint_config = dict(interval=2)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/root/UniDetector/regionclip_pretrained-cc_rn50_mmdet.pth'
resume_from = None
workflow = [('train', 1)]
norm_cfg = dict(type='BN', requires_grad=False)
model = dict(
    type='FastRCNN',
    backbone=dict(type='CLIPResNet', layers=[3, 4, 6, 3], style='pytorch'),
    roi_head=dict(
        type='StandardRoIHead',
        shared_head=dict(type='CLIPResLayer', layers=[3, 4, 6, 3]),
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=1024,
            featmap_strides=[16]),
        bbox_head=dict(
            type='BBoxHeadCLIPPartitioned',
            with_avg_pool=True,
            roi_feat_size=7,
            in_channels=2048,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            with_cls=False,
            reg_class_agnostic=True,
            zeroshot_path=[
                './clip_embeddings/coco_clip_a+cname_rn50_manyprompt.npy',
                './clip_embeddings/objects365_clip_a+cname_rn50_manyprompt.npy'
            ],
            cat_freq_path=[
                None,
                '/root/autodl-tmp/datasets/object365/annotations/object365_cat_freq.json'
            ],
            num_classes=365,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rcnn=dict(
            score_thr=0.0001,
            nms=dict(type='soft_nms', iou_threshold=0.5, method='gaussian'),
            max_per_img=100)))
classes_obj365 = [
    'Person', 'Sneakers', 'Chair', 'Other Shoes', 'Hat', 'Car', 'Lamp',
    'Glasses', 'Bottle', 'Desk', 'Cup', 'Street Lights', 'Cabinet/shelf',
    'Handbag/Satchel', 'Bracelet', 'Plate', 'Picture/Frame', 'Helmet', 'Book',
    'Gloves', 'Storage box', 'Boat', 'Leather Shoes', 'Flower', 'Bench',
    'Potted Plant', 'Bowl/Basin', 'Flag', 'Pillow', 'Boots', 'Vase',
    'Microphone', 'Necklace', 'Ring', 'SUV', 'Wine Glass', 'Belt',
    'Moniter/TV', 'Backpack', 'Umbrella', 'Traffic Light', 'Speaker', 'Watch',
    'Tie', 'Trash bin Can', 'Slippers', 'Bicycle', 'Stool', 'Barrel/bucket',
    'Van', 'Couch', 'Sandals', 'Bakset', 'Drum', 'Pen/Pencil', 'Bus',
    'Wild Bird', 'High Heels', 'Motorcycle', 'Guitar', 'Carpet', 'Cell Phone',
    'Bread', 'Camera', 'Canned', 'Truck', 'Traffic cone', 'Cymbal',
    'Lifesaver', 'Towel', 'Stuffed Toy', 'Candle', 'Sailboat', 'Laptop',
    'Awning', 'Bed', 'Faucet', 'Tent', 'Horse', 'Mirror', 'Power outlet',
    'Sink', 'Apple', 'Air Conditioner', 'Knife', 'Hockey Stick', 'Paddle',
    'Pickup Truck', 'Fork', 'Traffic Sign', 'Ballon', 'Tripod', 'Dog', 'Spoon',
    'Clock', 'Pot', 'Cow', 'Cake', 'Dinning Table', 'Sheep', 'Hanger',
    'Blackboard/Whiteboard', 'Napkin', 'Other Fish', 'Orange/Tangerine',
    'Toiletry', 'Keyboard', 'Tomato', 'Lantern', 'Machinery Vehicle', 'Fan',
    'Green Vegetables', 'Banana', 'Baseball Glove', 'Airplane', 'Mouse',
    'Train', 'Pumpkin', 'Soccer', 'Skiboard', 'Luggage', 'Nightstand',
    'Tea pot', 'Telephone', 'Trolley', 'Head Phone', 'Sports Car', 'Stop Sign',
    'Dessert', 'Scooter', 'Stroller', 'Crane', 'Remote', 'Refrigerator',
    'Oven', 'Lemon', 'Duck', 'Baseball Bat', 'Surveillance Camera', 'Cat',
    'Jug', 'Broccoli', 'Piano', 'Pizza', 'Elephant', 'Skateboard', 'Surfboard',
    'Gun', 'Skating and Skiing shoes', 'Gas stove', 'Donut', 'Bow Tie',
    'Carrot', 'Toilet', 'Kite', 'Strawberry', 'Other Balls', 'Shovel',
    'Pepper', 'Computer Box', 'Toilet Paper', 'Cleaning Products',
    'Chopsticks', 'Microwave', 'Pigeon', 'Baseball', 'Cutting/chopping Board',
    'Coffee Table', 'Side Table', 'Scissors', 'Marker', 'Pie', 'Ladder',
    'Snowboard', 'Cookies', 'Radiator', 'Fire Hydrant', 'Basketball', 'Zebra',
    'Grape', 'Giraffe', 'Potato', 'Sausage', 'Tricycle', 'Violin', 'Egg',
    'Fire Extinguisher', 'Candy', 'Fire Truck', 'Billards', 'Converter',
    'Bathtub', 'Wheelchair', 'Golf Club', 'Briefcase', 'Cucumber',
    'Cigar/Cigarette ', 'Paint Brush', 'Pear', 'Heavy Truck', 'Hamburger',
    'Extractor', 'Extention Cord', 'Tong', 'Tennis Racket', 'Folder',
    'American Football', 'earphone', 'Mask', 'Kettle', 'Tennis', 'Ship',
    'Swing', 'Coffee Machine', 'Slide', 'Carriage', 'Onion', 'Green beans',
    'Projector', 'Frisbee', 'Washing Machine/Drying Machine', 'Chicken',
    'Printer', 'Watermelon', 'Saxophone', 'Tissue', 'Toothbrush', 'Ice cream',
    'Hotair ballon', 'Cello', 'French Fries', 'Scale', 'Trophy', 'Cabbage',
    'Hot dog', 'Blender', 'Peach', 'Rice', 'Wallet/Purse', 'Volleyball',
    'Deer', 'Goose', 'Tape', 'Tablet', 'Cosmetics', 'Trumpet', 'Pineapple',
    'Golf Ball', 'Ambulance', 'Parking meter', 'Mango', 'Key', 'Hurdle',
    'Fishing Rod', 'Medal', 'Flute', 'Brush', 'Penguin', 'Megaphone', 'Corn',
    'Lettuce', 'Garlic', 'Swan', 'Helicopter', 'Green Onion', 'Sandwich',
    'Nuts', 'Speed Limit Sign', 'Induction Cooker', 'Broom', 'Trombone',
    'Plum', 'Rickshaw', 'Goldfish', 'Kiwi fruit', 'Router/modem', 'Poker Card',
    'Toaster', 'Shrimp', 'Sushi', 'Cheese', 'Notepaper', 'Cherry', 'Pliers',
    'CD', 'Pasta', 'Hammer', 'Cue', 'Avocado', 'Hamimelon', 'Flask',
    'Mushroon', 'Screwdriver', 'Soap', 'Recorder', 'Bear', 'Eggplant',
    'Board Eraser', 'Coconut', 'Tape Measur/ Ruler', 'Pig', 'Showerhead',
    'Globe', 'Chips', 'Steak', 'Crosswalk Sign', 'Stapler', 'Campel',
    'Formula 1 ', 'Pomegranate', 'Dishwasher', 'Crab', 'Hoverboard',
    'Meat ball', 'Rice Cooker', 'Tuba', 'Calculator', 'Papaya', 'Antelope',
    'Parrot', 'Seal', 'Buttefly', 'Dumbbell', 'Donkey', 'Lion', 'Urinal',
    'Dolphin', 'Electric Drill', 'Hair Dryer', 'Egg tart', 'Jellyfish',
    'Treadmill', 'Lighter', 'Grapefruit', 'Game board', 'Mop', 'Radish',
    'Baozi', 'Target', 'French', 'Spring Rolls', 'Monkey', 'Rabbit',
    'Pencil Case', 'Yak', 'Red Cabbage', 'Binoculars', 'Asparagus', 'Barbell',
    'Scallop', 'Noddles', 'Comb', 'Dumpling', 'Oyster', 'Table Teniis paddle',
    'Cosmetics Brush/Eyeliner Pencil', 'Chainsaw', 'Eraser', 'Lobster',
    'Durian', 'Okra', 'Lipstick', 'Cosmetics Mirror', 'Curling',
    'Table Tennis '
]
dataset_type = 'CocoDataset'
data_root = '/root/autodl-tmp/datasets/coco/'
img_norm_cfg = dict(
    mean=[122.7709383, 116.7460125, 104.09373615],
    std=[68.5005327, 66.6321579, 70.32316305],
    to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadProposals', num_max_proposals=2000),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=[(1333, 400), (1333, 800)], keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[122.7709383, 116.7460125, 104.09373615],
        std=[68.5005327, 66.6321579, 70.32316305],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadProposals', num_max_proposals=None),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[122.7709383, 116.7460125, 104.09373615],
                std=[68.5005327, 66.6321579, 70.32316305],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['proposals']),
            dict(
                type='ToDataContainer',
                fields=[dict(key='proposals', stack=False)]),
            dict(type='Collect', keys=['img', 'proposals'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type='CocoDataset',
                ann_file=
                '/root/autodl-tmp/datasets/coco/annotations/instances_train2017.1@5.0.json',
                img_prefix='/root/autodl-tmp/datasets/coco/train2017/',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadProposals', num_max_proposals=2000),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        type='Resize',
                        img_scale=[(1333, 400), (1333, 800)],
                        keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='DefaultFormatBundle'),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
                ],
                proposal_file=
                '/root/autodl-tmp/rpl/decouple_oidcoco_coco_rpn_train.pkl',
                dataset_id=0),
            dict(
                type='CocoDataset',
                ann_file=
                '/root/autodl-tmp/datasets/object365/annotations/zhiyuan_objv2_train_patch0-5.1@2.0_cleaned.json',
                img_prefix='/root/autodl-tmp/datasets/object365',
                classes=[
                    'Person', 'Sneakers', 'Chair', 'Other Shoes', 'Hat', 'Car',
                    'Lamp', 'Glasses', 'Bottle', 'Desk', 'Cup',
                    'Street Lights', 'Cabinet/shelf', 'Handbag/Satchel',
                    'Bracelet', 'Plate', 'Picture/Frame', 'Helmet', 'Book',
                    'Gloves', 'Storage box', 'Boat', 'Leather Shoes', 'Flower',
                    'Bench', 'Potted Plant', 'Bowl/Basin', 'Flag', 'Pillow',
                    'Boots', 'Vase', 'Microphone', 'Necklace', 'Ring', 'SUV',
                    'Wine Glass', 'Belt', 'Moniter/TV', 'Backpack', 'Umbrella',
                    'Traffic Light', 'Speaker', 'Watch', 'Tie',
                    'Trash bin Can', 'Slippers', 'Bicycle', 'Stool',
                    'Barrel/bucket', 'Van', 'Couch', 'Sandals', 'Bakset',
                    'Drum', 'Pen/Pencil', 'Bus', 'Wild Bird', 'High Heels',
                    'Motorcycle', 'Guitar', 'Carpet', 'Cell Phone', 'Bread',
                    'Camera', 'Canned', 'Truck', 'Traffic cone', 'Cymbal',
                    'Lifesaver', 'Towel', 'Stuffed Toy', 'Candle', 'Sailboat',
                    'Laptop', 'Awning', 'Bed', 'Faucet', 'Tent', 'Horse',
                    'Mirror', 'Power outlet', 'Sink', 'Apple',
                    'Air Conditioner', 'Knife', 'Hockey Stick', 'Paddle',
                    'Pickup Truck', 'Fork', 'Traffic Sign', 'Ballon', 'Tripod',
                    'Dog', 'Spoon', 'Clock', 'Pot', 'Cow', 'Cake',
                    'Dinning Table', 'Sheep', 'Hanger',
                    'Blackboard/Whiteboard', 'Napkin', 'Other Fish',
                    'Orange/Tangerine', 'Toiletry', 'Keyboard', 'Tomato',
                    'Lantern', 'Machinery Vehicle', 'Fan', 'Green Vegetables',
                    'Banana', 'Baseball Glove', 'Airplane', 'Mouse', 'Train',
                    'Pumpkin', 'Soccer', 'Skiboard', 'Luggage', 'Nightstand',
                    'Tea pot', 'Telephone', 'Trolley', 'Head Phone',
                    'Sports Car', 'Stop Sign', 'Dessert', 'Scooter',
                    'Stroller', 'Crane', 'Remote', 'Refrigerator', 'Oven',
                    'Lemon', 'Duck', 'Baseball Bat', 'Surveillance Camera',
                    'Cat', 'Jug', 'Broccoli', 'Piano', 'Pizza', 'Elephant',
                    'Skateboard', 'Surfboard', 'Gun',
                    'Skating and Skiing shoes', 'Gas stove', 'Donut',
                    'Bow Tie', 'Carrot', 'Toilet', 'Kite', 'Strawberry',
                    'Other Balls', 'Shovel', 'Pepper', 'Computer Box',
                    'Toilet Paper', 'Cleaning Products', 'Chopsticks',
                    'Microwave', 'Pigeon', 'Baseball',
                    'Cutting/chopping Board', 'Coffee Table', 'Side Table',
                    'Scissors', 'Marker', 'Pie', 'Ladder', 'Snowboard',
                    'Cookies', 'Radiator', 'Fire Hydrant', 'Basketball',
                    'Zebra', 'Grape', 'Giraffe', 'Potato', 'Sausage',
                    'Tricycle', 'Violin', 'Egg', 'Fire Extinguisher', 'Candy',
                    'Fire Truck', 'Billards', 'Converter', 'Bathtub',
                    'Wheelchair', 'Golf Club', 'Briefcase', 'Cucumber',
                    'Cigar/Cigarette ', 'Paint Brush', 'Pear', 'Heavy Truck',
                    'Hamburger', 'Extractor', 'Extention Cord', 'Tong',
                    'Tennis Racket', 'Folder', 'American Football', 'earphone',
                    'Mask', 'Kettle', 'Tennis', 'Ship', 'Swing',
                    'Coffee Machine', 'Slide', 'Carriage', 'Onion',
                    'Green beans', 'Projector', 'Frisbee',
                    'Washing Machine/Drying Machine', 'Chicken', 'Printer',
                    'Watermelon', 'Saxophone', 'Tissue', 'Toothbrush',
                    'Ice cream', 'Hotair ballon', 'Cello', 'French Fries',
                    'Scale', 'Trophy', 'Cabbage', 'Hot dog', 'Blender',
                    'Peach', 'Rice', 'Wallet/Purse', 'Volleyball', 'Deer',
                    'Goose', 'Tape', 'Tablet', 'Cosmetics', 'Trumpet',
                    'Pineapple', 'Golf Ball', 'Ambulance', 'Parking meter',
                    'Mango', 'Key', 'Hurdle', 'Fishing Rod', 'Medal', 'Flute',
                    'Brush', 'Penguin', 'Megaphone', 'Corn', 'Lettuce',
                    'Garlic', 'Swan', 'Helicopter', 'Green Onion', 'Sandwich',
                    'Nuts', 'Speed Limit Sign', 'Induction Cooker', 'Broom',
                    'Trombone', 'Plum', 'Rickshaw', 'Goldfish', 'Kiwi fruit',
                    'Router/modem', 'Poker Card', 'Toaster', 'Shrimp', 'Sushi',
                    'Cheese', 'Notepaper', 'Cherry', 'Pliers', 'CD', 'Pasta',
                    'Hammer', 'Cue', 'Avocado', 'Hamimelon', 'Flask',
                    'Mushroon', 'Screwdriver', 'Soap', 'Recorder', 'Bear',
                    'Eggplant', 'Board Eraser', 'Coconut',
                    'Tape Measur/ Ruler', 'Pig', 'Showerhead', 'Globe',
                    'Chips', 'Steak', 'Crosswalk Sign', 'Stapler', 'Campel',
                    'Formula 1 ', 'Pomegranate', 'Dishwasher', 'Crab',
                    'Hoverboard', 'Meat ball', 'Rice Cooker', 'Tuba',
                    'Calculator', 'Papaya', 'Antelope', 'Parrot', 'Seal',
                    'Buttefly', 'Dumbbell', 'Donkey', 'Lion', 'Urinal',
                    'Dolphin', 'Electric Drill', 'Hair Dryer', 'Egg tart',
                    'Jellyfish', 'Treadmill', 'Lighter', 'Grapefruit',
                    'Game board', 'Mop', 'Radish', 'Baozi', 'Target', 'French',
                    'Spring Rolls', 'Monkey', 'Rabbit', 'Pencil Case', 'Yak',
                    'Red Cabbage', 'Binoculars', 'Asparagus', 'Barbell',
                    'Scallop', 'Noddles', 'Comb', 'Dumpling', 'Oyster',
                    'Table Teniis paddle', 'Cosmetics Brush/Eyeliner Pencil',
                    'Chainsaw', 'Eraser', 'Lobster', 'Durian', 'Okra',
                    'Lipstick', 'Cosmetics Mirror', 'Curling', 'Table Tennis '
                ],
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadProposals', num_max_proposals=2000),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        type='Resize',
                        img_scale=[(1333, 400), (1333, 800)],
                        keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='DefaultFormatBundle'),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
                ],
                proposal_file=
                '/root/autodl-tmp/rpl/decouple_oidcoco_obj365_rpn_train.pkl',
                dataset_id=1)
        ]),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        proposal_file='/root/autodl-tmp/rpl/decouple_oidcoco_coco_rpn_val.pkl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadProposals', num_max_proposals=None),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='ToTensor', keys=['proposals']),
                    dict(
                        type='ToDataContainer',
                        fields=[dict(key='proposals', stack=False)]),
                    dict(type='Collect', keys=['img', 'proposals'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        proposal_file='/root/autodl-tmp/rpl/decouple_oidcoco_coco_rpn_val.pkl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadProposals', num_max_proposals=None),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='ToTensor', keys=['proposals']),
                    dict(
                        type='ToDataContainer',
                        fields=[dict(key='proposals', stack=False)]),
                    dict(type='Collect', keys=['img', 'proposals'])
                ])
        ]))
evaluation = dict(interval=2, metric='bbox')
optimizer = dict(
    type='SGD',
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0001,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=0.1, decay_mult=1.0),
            roi_head=dict(lr_mult=0.1, decay_mult=1.0))))
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[3, 4])
runner = dict(type='EpochBasedRunner', max_epochs=4)
seed = 1
work_dir = '/root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn20250805_232222'
gpu_ids = range(0, 1)

2025-08-05 23:22:39,325 - mmdet - INFO - initialize BBoxHeadCLIPPartitioned with init_cfg [{'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.conv2.weight - torch.Size([32, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.conv3.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.attnpool.positional_embedding - torch.Size([50, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.k_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.k_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.q_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.q_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.v_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.v_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.c_proj.weight - torch.Size([1024, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.c_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  
2025-08-05 23:22:41,379 - mmdet - INFO - load checkpoint from local path: /root/UniDetector/regionclip_pretrained-cc_rn50_mmdet.pth
2025-08-05 23:22:41,483 - mmdet - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: roi_head.bbox_head.zs_weights_0, roi_head.bbox_head.zs_weights_1, roi_head.bbox_head.fc_reg.weight, roi_head.bbox_head.fc_reg.bias

2025-08-05 23:22:41,486 - mmdet - INFO - Start running, host: root@autodl-container-4bf6429de3-797681b8, work_dir: /root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn20250805_232222
2025-08-05 23:22:41,486 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-08-05 23:22:41,486 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs
2025-08-05 23:22:41,486 - mmdet - INFO - Checkpoints will be saved to /root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn20250805_232222 by HardDiskBackend.
2025-08-05 23:23:10,071 - mmdet - INFO - Epoch [1][50/4665]	lr: 4.945e-04, eta: 2:57:17, time: 0.572, data_time: 0.290, memory: 11942, loss_cls: 192.4427, acc: 16.4561, loss_bbox: 0.0878, loss: 192.5305, grad_norm: 2102.9449
2025-08-05 23:23:24,475 - mmdet - INFO - Epoch [1][100/4665]	lr: 9.940e-04, eta: 2:12:58, time: 0.288, data_time: 0.005, memory: 11942, loss_cls: 0.5098, acc: 96.1306, loss_bbox: 0.0889, loss: 0.5987, grad_norm: 8.2648
2025-08-05 23:23:39,018 - mmdet - INFO - Epoch [1][150/4665]	lr: 1.494e-03, eta: 1:58:18, time: 0.291, data_time: 0.005, memory: 11942, loss_cls: 0.3664, acc: 94.7411, loss_bbox: 0.1107, loss: 0.4771, grad_norm: 6.6205
2025-08-05 23:23:53,620 - mmdet - INFO - Epoch [1][200/4665]	lr: 1.993e-03, eta: 1:50:57, time: 0.292, data_time: 0.006, memory: 11942, loss_cls: 0.2470, acc: 96.0652, loss_bbox: 0.0850, loss: 0.3319, grad_norm: 4.8787
2025-08-05 23:24:07,879 - mmdet - INFO - Epoch [1][250/4665]	lr: 2.493e-03, eta: 1:46:01, time: 0.285, data_time: 0.005, memory: 11942, loss_cls: 0.2655, acc: 95.4893, loss_bbox: 0.0973, loss: 0.3629, grad_norm: 5.4649
2025-08-05 23:24:22,480 - mmdet - INFO - Epoch [1][300/4665]	lr: 2.992e-03, eta: 1:43:00, time: 0.292, data_time: 0.006, memory: 11942, loss_cls: 0.2371, acc: 95.4925, loss_bbox: 0.0965, loss: 0.3336, grad_norm: 4.6050
2025-08-05 23:24:36,728 - mmdet - INFO - Epoch [1][350/4665]	lr: 3.492e-03, eta: 1:40:28, time: 0.285, data_time: 0.006, memory: 11942, loss_cls: 0.1983, acc: 95.8843, loss_bbox: 0.0874, loss: 0.2857, grad_norm: 4.9306
2025-08-05 23:24:50,750 - mmdet - INFO - Epoch [1][400/4665]	lr: 3.991e-03, eta: 1:38:20, time: 0.280, data_time: 0.006, memory: 11999, loss_cls: 0.2094, acc: 95.7905, loss_bbox: 0.0941, loss: 0.3035, grad_norm: 4.9353
2025-08-05 23:25:05,286 - mmdet - INFO - Epoch [1][450/4665]	lr: 4.491e-03, eta: 1:36:58, time: 0.291, data_time: 0.005, memory: 11999, loss_cls: 0.2315, acc: 94.9242, loss_bbox: 0.1094, loss: 0.3409, grad_norm: 5.4368
2025-08-05 23:25:19,426 - mmdet - INFO - Epoch [1][500/4665]	lr: 4.990e-03, eta: 1:35:36, time: 0.283, data_time: 0.005, memory: 11999, loss_cls: 0.2148, acc: 95.4155, loss_bbox: 0.0980, loss: 0.3128, grad_norm: 4.9370
2025-08-05 23:25:33,784 - mmdet - INFO - Epoch [1][550/4665]	lr: 5.000e-03, eta: 1:34:33, time: 0.287, data_time: 0.005, memory: 11999, loss_cls: 0.2152, acc: 95.7079, loss_bbox: 0.0960, loss: 0.3112, grad_norm: 5.5691
2025-08-05 23:25:48,263 - mmdet - INFO - Epoch [1][600/4665]	lr: 5.000e-03, eta: 1:33:41, time: 0.290, data_time: 0.005, memory: 11999, loss_cls: 0.1740, acc: 95.9823, loss_bbox: 0.0882, loss: 0.2621, grad_norm: 4.0807
2025-08-05 23:26:02,811 - mmdet - INFO - Epoch [1][650/4665]	lr: 5.000e-03, eta: 1:32:58, time: 0.291, data_time: 0.006, memory: 11999, loss_cls: 0.1791, acc: 95.9563, loss_bbox: 0.0829, loss: 0.2620, grad_norm: 4.2548
2025-08-05 23:26:16,890 - mmdet - INFO - Epoch [1][700/4665]	lr: 5.000e-03, eta: 1:32:06, time: 0.282, data_time: 0.005, memory: 11999, loss_cls: 0.1754, acc: 95.9015, loss_bbox: 0.0908, loss: 0.2662, grad_norm: 4.1400
2025-08-05 23:26:31,472 - mmdet - INFO - Epoch [1][750/4665]	lr: 5.000e-03, eta: 1:31:31, time: 0.292, data_time: 0.006, memory: 11999, loss_cls: 0.1728, acc: 96.1048, loss_bbox: 0.0885, loss: 0.2614, grad_norm: 3.9373
2025-08-05 23:26:45,746 - mmdet - INFO - Epoch [1][800/4665]	lr: 5.000e-03, eta: 1:30:52, time: 0.285, data_time: 0.006, memory: 11999, loss_cls: 0.1726, acc: 96.2881, loss_bbox: 0.0895, loss: 0.2621, grad_norm: 4.0017
2025-08-05 23:27:00,030 - mmdet - INFO - Epoch [1][850/4665]	lr: 5.000e-03, eta: 1:30:17, time: 0.286, data_time: 0.006, memory: 11999, loss_cls: 0.1668, acc: 96.0286, loss_bbox: 0.0938, loss: 0.2607, grad_norm: 3.9454
2025-08-05 23:27:14,512 - mmdet - INFO - Epoch [1][900/4665]	lr: 5.000e-03, eta: 1:29:47, time: 0.290, data_time: 0.006, memory: 11999, loss_cls: 0.1783, acc: 95.7273, loss_bbox: 0.0954, loss: 0.2737, grad_norm: 5.0312
2025-08-05 23:27:28,851 - mmdet - INFO - Epoch [1][950/4665]	lr: 5.000e-03, eta: 1:29:16, time: 0.287, data_time: 0.006, memory: 11999, loss_cls: 0.2019, acc: 94.2748, loss_bbox: 0.1091, loss: 0.3110, grad_norm: 4.7187
2025-08-05 23:27:43,312 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-05 23:27:43,313 - mmdet - INFO - Epoch [1][1000/4665]	lr: 5.000e-03, eta: 1:28:50, time: 0.289, data_time: 0.005, memory: 11999, loss_cls: 0.1903, acc: 95.6511, loss_bbox: 0.0956, loss: 0.2860, grad_norm: 4.4916
2025-08-05 23:27:58,018 - mmdet - INFO - Epoch [1][1050/4665]	lr: 5.000e-03, eta: 1:28:28, time: 0.294, data_time: 0.005, memory: 11999, loss_cls: 0.1687, acc: 95.8240, loss_bbox: 0.0962, loss: 0.2649, grad_norm: 3.6980
2025-08-05 23:28:12,671 - mmdet - INFO - Epoch [1][1100/4665]	lr: 5.000e-03, eta: 1:28:06, time: 0.293, data_time: 0.005, memory: 11999, loss_cls: 0.1918, acc: 95.4175, loss_bbox: 0.1046, loss: 0.2964, grad_norm: 3.8438
2025-08-05 23:28:27,200 - mmdet - INFO - Epoch [1][1150/4665]	lr: 5.000e-03, eta: 1:27:43, time: 0.291, data_time: 0.005, memory: 11999, loss_cls: 0.1639, acc: 96.0150, loss_bbox: 0.0958, loss: 0.2597, grad_norm: 3.8750
2025-08-05 23:28:41,585 - mmdet - INFO - Epoch [1][1200/4665]	lr: 5.000e-03, eta: 1:27:19, time: 0.288, data_time: 0.005, memory: 11999, loss_cls: 0.1550, acc: 96.1685, loss_bbox: 0.0914, loss: 0.2464, grad_norm: 3.7144
2025-08-05 23:28:56,109 - mmdet - INFO - Epoch [1][1250/4665]	lr: 5.000e-03, eta: 1:26:57, time: 0.290, data_time: 0.006, memory: 11999, loss_cls: 0.1684, acc: 95.8873, loss_bbox: 0.0919, loss: 0.2603, grad_norm: 4.0555
2025-08-05 23:29:10,896 - mmdet - INFO - Epoch [1][1300/4665]	lr: 5.000e-03, eta: 1:26:39, time: 0.296, data_time: 0.006, memory: 11999, loss_cls: 0.1925, acc: 95.1511, loss_bbox: 0.1145, loss: 0.3070, grad_norm: 4.0252
2025-08-05 23:29:25,401 - mmdet - INFO - Epoch [1][1350/4665]	lr: 5.000e-03, eta: 1:26:18, time: 0.290, data_time: 0.006, memory: 11999, loss_cls: 0.1760, acc: 95.8608, loss_bbox: 0.0958, loss: 0.2718, grad_norm: 4.1060
2025-08-05 23:29:39,830 - mmdet - INFO - Epoch [1][1400/4665]	lr: 5.000e-03, eta: 1:25:57, time: 0.289, data_time: 0.005, memory: 11999, loss_cls: 0.1872, acc: 95.3292, loss_bbox: 0.0979, loss: 0.2851, grad_norm: 4.6220
2025-08-05 23:29:54,159 - mmdet - INFO - Epoch [1][1450/4665]	lr: 5.000e-03, eta: 1:25:35, time: 0.287, data_time: 0.005, memory: 11999, loss_cls: 0.1637, acc: 96.1304, loss_bbox: 0.0923, loss: 0.2560, grad_norm: 3.9656
2025-08-05 23:30:08,442 - mmdet - INFO - Epoch [1][1500/4665]	lr: 5.000e-03, eta: 1:25:13, time: 0.286, data_time: 0.005, memory: 11999, loss_cls: 0.1568, acc: 96.2652, loss_bbox: 0.0964, loss: 0.2532, grad_norm: 3.8355
2025-08-05 23:30:22,676 - mmdet - INFO - Epoch [1][1550/4665]	lr: 5.000e-03, eta: 1:24:50, time: 0.285, data_time: 0.006, memory: 11999, loss_cls: 0.1551, acc: 96.3749, loss_bbox: 0.0877, loss: 0.2428, grad_norm: 4.0526
2025-08-05 23:30:36,756 - mmdet - INFO - Epoch [1][1600/4665]	lr: 5.000e-03, eta: 1:24:27, time: 0.282, data_time: 0.005, memory: 12111, loss_cls: 0.1584, acc: 95.1516, loss_bbox: 0.1029, loss: 0.2613, grad_norm: 3.8753
2025-08-05 23:30:51,047 - mmdet - INFO - Epoch [1][1650/4665]	lr: 5.000e-03, eta: 1:24:06, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1400, acc: 96.7934, loss_bbox: 0.0869, loss: 0.2269, grad_norm: 3.3330
2025-08-05 23:31:05,289 - mmdet - INFO - Epoch [1][1700/4665]	lr: 5.000e-03, eta: 1:23:46, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1552, acc: 96.2051, loss_bbox: 0.0933, loss: 0.2485, grad_norm: 3.5108
2025-08-05 23:31:19,718 - mmdet - INFO - Epoch [1][1750/4665]	lr: 5.000e-03, eta: 1:23:27, time: 0.289, data_time: 0.005, memory: 12111, loss_cls: 0.1481, acc: 96.3912, loss_bbox: 0.0799, loss: 0.2280, grad_norm: 3.8504
2025-08-05 23:31:34,027 - mmdet - INFO - Epoch [1][1800/4665]	lr: 5.000e-03, eta: 1:23:08, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1609, acc: 95.8718, loss_bbox: 0.0981, loss: 0.2590, grad_norm: 3.6241
2025-08-05 23:31:48,695 - mmdet - INFO - Epoch [1][1850/4665]	lr: 5.000e-03, eta: 1:22:52, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1606, acc: 96.0944, loss_bbox: 0.0916, loss: 0.2521, grad_norm: 3.8191
2025-08-05 23:32:03,266 - mmdet - INFO - Epoch [1][1900/4665]	lr: 5.000e-03, eta: 1:22:35, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1882, acc: 95.2974, loss_bbox: 0.1086, loss: 0.2967, grad_norm: 4.1912
2025-08-05 23:32:17,784 - mmdet - INFO - Epoch [1][1950/4665]	lr: 5.000e-03, eta: 1:22:18, time: 0.290, data_time: 0.005, memory: 12111, loss_cls: 0.1772, acc: 95.8628, loss_bbox: 0.1013, loss: 0.2785, grad_norm: 4.1092
2025-08-05 23:32:32,393 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-05 23:32:32,393 - mmdet - INFO - Epoch [1][2000/4665]	lr: 5.000e-03, eta: 1:22:02, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1474, acc: 96.1515, loss_bbox: 0.0991, loss: 0.2465, grad_norm: 3.0897
2025-08-05 23:32:46,909 - mmdet - INFO - Epoch [1][2050/4665]	lr: 5.000e-03, eta: 1:21:45, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1585, acc: 95.7489, loss_bbox: 0.0990, loss: 0.2576, grad_norm: 3.7490
2025-08-05 23:33:01,249 - mmdet - INFO - Epoch [1][2100/4665]	lr: 5.000e-03, eta: 1:21:27, time: 0.287, data_time: 0.005, memory: 12111, loss_cls: 0.1591, acc: 95.0532, loss_bbox: 0.0922, loss: 0.2514, grad_norm: 3.8809
2025-08-05 23:33:15,709 - mmdet - INFO - Epoch [1][2150/4665]	lr: 5.000e-03, eta: 1:21:10, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1413, acc: 96.4233, loss_bbox: 0.0897, loss: 0.2310, grad_norm: 3.1074
2025-08-05 23:33:30,377 - mmdet - INFO - Epoch [1][2200/4665]	lr: 5.000e-03, eta: 1:20:54, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1579, acc: 95.7636, loss_bbox: 0.0992, loss: 0.2571, grad_norm: 3.7170
2025-08-05 23:33:44,949 - mmdet - INFO - Epoch [1][2250/4665]	lr: 5.000e-03, eta: 1:20:38, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1660, acc: 95.5607, loss_bbox: 0.0994, loss: 0.2654, grad_norm: 4.1082
2025-08-05 23:33:59,320 - mmdet - INFO - Epoch [1][2300/4665]	lr: 5.000e-03, eta: 1:20:21, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1470, acc: 96.3713, loss_bbox: 0.0915, loss: 0.2385, grad_norm: 3.3408
2025-08-05 23:34:13,779 - mmdet - INFO - Epoch [1][2350/4665]	lr: 5.000e-03, eta: 1:20:04, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1497, acc: 94.2851, loss_bbox: 0.0940, loss: 0.2437, grad_norm: 3.1858
2025-08-05 23:34:28,087 - mmdet - INFO - Epoch [1][2400/4665]	lr: 5.000e-03, eta: 1:19:47, time: 0.286, data_time: 0.005, memory: 12111, loss_cls: 0.1536, acc: 95.1107, loss_bbox: 0.0959, loss: 0.2495, grad_norm: 3.6427
2025-08-05 23:34:42,325 - mmdet - INFO - Epoch [1][2450/4665]	lr: 5.000e-03, eta: 1:19:29, time: 0.285, data_time: 0.005, memory: 12111, loss_cls: 0.1526, acc: 96.1089, loss_bbox: 0.0945, loss: 0.2471, grad_norm: 3.5358
2025-08-05 23:34:56,717 - mmdet - INFO - Epoch [1][2500/4665]	lr: 5.000e-03, eta: 1:19:12, time: 0.288, data_time: 0.005, memory: 12111, loss_cls: 0.1392, acc: 96.5837, loss_bbox: 0.0823, loss: 0.2215, grad_norm: 3.6167
2025-08-05 23:35:11,216 - mmdet - INFO - Epoch [1][2550/4665]	lr: 5.000e-03, eta: 1:18:56, time: 0.290, data_time: 0.005, memory: 12111, loss_cls: 0.1586, acc: 95.8140, loss_bbox: 0.1011, loss: 0.2596, grad_norm: 3.8561
2025-08-05 23:35:25,706 - mmdet - INFO - Epoch [1][2600/4665]	lr: 5.000e-03, eta: 1:18:40, time: 0.290, data_time: 0.005, memory: 12111, loss_cls: 0.1678, acc: 95.5379, loss_bbox: 0.1062, loss: 0.2740, grad_norm: 3.7422
2025-08-05 23:35:40,049 - mmdet - INFO - Epoch [1][2650/4665]	lr: 5.000e-03, eta: 1:18:23, time: 0.287, data_time: 0.005, memory: 12111, loss_cls: 0.1346, acc: 96.5446, loss_bbox: 0.0901, loss: 0.2247, grad_norm: 3.4088
2025-08-05 23:35:54,304 - mmdet - INFO - Epoch [1][2700/4665]	lr: 5.000e-03, eta: 1:18:06, time: 0.285, data_time: 0.005, memory: 12111, loss_cls: 0.1689, acc: 95.5585, loss_bbox: 0.1054, loss: 0.2744, grad_norm: 3.7954
2025-08-05 23:36:08,388 - mmdet - INFO - Epoch [1][2750/4665]	lr: 5.000e-03, eta: 1:17:48, time: 0.282, data_time: 0.005, memory: 12111, loss_cls: 0.1527, acc: 96.2857, loss_bbox: 0.0916, loss: 0.2442, grad_norm: 3.5301
2025-08-05 23:36:22,901 - mmdet - INFO - Epoch [1][2800/4665]	lr: 5.000e-03, eta: 1:17:32, time: 0.290, data_time: 0.005, memory: 12111, loss_cls: 0.1625, acc: 96.0416, loss_bbox: 0.0899, loss: 0.2525, grad_norm: 3.6679
2025-08-05 23:36:37,320 - mmdet - INFO - Epoch [1][2850/4665]	lr: 5.000e-03, eta: 1:17:16, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1492, acc: 96.0104, loss_bbox: 0.0993, loss: 0.2485, grad_norm: 3.4017
2025-08-05 23:36:51,909 - mmdet - INFO - Epoch [1][2900/4665]	lr: 5.000e-03, eta: 1:17:01, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1366, acc: 96.6243, loss_bbox: 0.0901, loss: 0.2267, grad_norm: 3.2935
2025-08-05 23:37:06,573 - mmdet - INFO - Epoch [1][2950/4665]	lr: 5.000e-03, eta: 1:16:46, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1375, acc: 96.3545, loss_bbox: 0.0921, loss: 0.2295, grad_norm: 3.2852
2025-08-05 23:37:21,100 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-05 23:37:21,101 - mmdet - INFO - Epoch [1][3000/4665]	lr: 5.000e-03, eta: 1:16:31, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1525, acc: 95.9343, loss_bbox: 0.0966, loss: 0.2492, grad_norm: 3.5438
2025-08-05 23:37:35,693 - mmdet - INFO - Epoch [1][3050/4665]	lr: 5.000e-03, eta: 1:16:16, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1426, acc: 96.3212, loss_bbox: 0.0922, loss: 0.2348, grad_norm: 3.2638
2025-08-05 23:37:49,959 - mmdet - INFO - Epoch [1][3100/4665]	lr: 5.000e-03, eta: 1:15:59, time: 0.285, data_time: 0.005, memory: 12111, loss_cls: 0.1510, acc: 96.0549, loss_bbox: 0.0996, loss: 0.2507, grad_norm: 3.5097
2025-08-05 23:38:04,419 - mmdet - INFO - Epoch [1][3150/4665]	lr: 5.000e-03, eta: 1:15:44, time: 0.289, data_time: 0.005, memory: 12111, loss_cls: 0.1681, acc: 94.6961, loss_bbox: 0.1022, loss: 0.2702, grad_norm: 3.8639
2025-08-05 23:38:19,054 - mmdet - INFO - Epoch [1][3200/4665]	lr: 5.000e-03, eta: 1:15:29, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1545, acc: 95.8713, loss_bbox: 0.1017, loss: 0.2562, grad_norm: 3.7851
2025-08-05 23:38:33,243 - mmdet - INFO - Epoch [1][3250/4665]	lr: 5.000e-03, eta: 1:15:12, time: 0.284, data_time: 0.006, memory: 12111, loss_cls: 0.1535, acc: 96.2557, loss_bbox: 0.0943, loss: 0.2477, grad_norm: 3.7871
2025-08-05 23:38:47,844 - mmdet - INFO - Epoch [1][3300/4665]	lr: 5.000e-03, eta: 1:14:57, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1478, acc: 96.1082, loss_bbox: 0.0957, loss: 0.2435, grad_norm: 3.3362
2025-08-05 23:39:02,174 - mmdet - INFO - Epoch [1][3350/4665]	lr: 5.000e-03, eta: 1:14:41, time: 0.287, data_time: 0.005, memory: 12111, loss_cls: 0.1557, acc: 95.7977, loss_bbox: 0.0977, loss: 0.2533, grad_norm: 3.9558
2025-08-05 23:39:16,713 - mmdet - INFO - Epoch [1][3400/4665]	lr: 5.000e-03, eta: 1:14:26, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1365, acc: 96.4881, loss_bbox: 0.0868, loss: 0.2233, grad_norm: 3.1005
2025-08-05 23:39:31,044 - mmdet - INFO - Epoch [1][3450/4665]	lr: 5.000e-03, eta: 1:14:10, time: 0.287, data_time: 0.005, memory: 12111, loss_cls: 0.1511, acc: 96.2281, loss_bbox: 0.0931, loss: 0.2442, grad_norm: 3.3046
2025-08-05 23:39:45,549 - mmdet - INFO - Epoch [1][3500/4665]	lr: 5.000e-03, eta: 1:13:55, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1475, acc: 96.4292, loss_bbox: 0.0917, loss: 0.2392, grad_norm: 3.7635
2025-08-05 23:40:00,379 - mmdet - INFO - Epoch [1][3550/4665]	lr: 5.000e-03, eta: 1:13:41, time: 0.297, data_time: 0.006, memory: 12111, loss_cls: 0.1551, acc: 95.8605, loss_bbox: 0.0938, loss: 0.2489, grad_norm: 3.7861
2025-08-05 23:40:14,646 - mmdet - INFO - Epoch [1][3600/4665]	lr: 5.000e-03, eta: 1:13:25, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1501, acc: 96.3680, loss_bbox: 0.0944, loss: 0.2445, grad_norm: 3.5555
2025-08-05 23:40:29,220 - mmdet - INFO - Epoch [1][3650/4665]	lr: 5.000e-03, eta: 1:13:10, time: 0.291, data_time: 0.005, memory: 12111, loss_cls: 0.1576, acc: 95.7903, loss_bbox: 0.0977, loss: 0.2553, grad_norm: 3.3843
2025-08-05 23:40:43,378 - mmdet - INFO - Epoch [1][3700/4665]	lr: 5.000e-03, eta: 1:12:54, time: 0.283, data_time: 0.005, memory: 12111, loss_cls: 0.1562, acc: 95.9863, loss_bbox: 0.0962, loss: 0.2524, grad_norm: 3.6632
2025-08-05 23:40:57,702 - mmdet - INFO - Epoch [1][3750/4665]	lr: 5.000e-03, eta: 1:12:38, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1430, acc: 96.3354, loss_bbox: 0.1011, loss: 0.2442, grad_norm: 3.5281
2025-08-05 23:41:12,136 - mmdet - INFO - Epoch [1][3800/4665]	lr: 5.000e-03, eta: 1:12:23, time: 0.289, data_time: 0.005, memory: 12111, loss_cls: 0.1788, acc: 95.6644, loss_bbox: 0.0960, loss: 0.2748, grad_norm: 3.9877
2025-08-05 23:41:26,404 - mmdet - INFO - Epoch [1][3850/4665]	lr: 5.000e-03, eta: 1:12:07, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1696, acc: 95.9551, loss_bbox: 0.1052, loss: 0.2748, grad_norm: 3.6105
2025-08-05 23:41:40,791 - mmdet - INFO - Epoch [1][3900/4665]	lr: 5.000e-03, eta: 1:11:51, time: 0.288, data_time: 0.005, memory: 12111, loss_cls: 0.1494, acc: 96.0799, loss_bbox: 0.0968, loss: 0.2462, grad_norm: 3.6093
2025-08-05 23:41:55,029 - mmdet - INFO - Epoch [1][3950/4665]	lr: 5.000e-03, eta: 1:11:35, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1568, acc: 95.7151, loss_bbox: 0.1079, loss: 0.2647, grad_norm: 3.5385
2025-08-05 23:42:09,227 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-05 23:42:09,228 - mmdet - INFO - Epoch [1][4000/4665]	lr: 5.000e-03, eta: 1:11:19, time: 0.284, data_time: 0.006, memory: 12111, loss_cls: 0.1471, acc: 95.2216, loss_bbox: 0.0968, loss: 0.2439, grad_norm: 3.5445
2025-08-05 23:42:23,704 - mmdet - INFO - Epoch [1][4050/4665]	lr: 5.000e-03, eta: 1:11:04, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1653, acc: 94.7458, loss_bbox: 0.1012, loss: 0.2665, grad_norm: 3.5515
2025-08-05 23:42:38,229 - mmdet - INFO - Epoch [1][4100/4665]	lr: 5.000e-03, eta: 1:10:49, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1490, acc: 96.2989, loss_bbox: 0.0977, loss: 0.2468, grad_norm: 3.4741
2025-08-05 23:42:52,829 - mmdet - INFO - Epoch [1][4150/4665]	lr: 5.000e-03, eta: 1:10:35, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1636, acc: 95.9210, loss_bbox: 0.1022, loss: 0.2658, grad_norm: 4.0314
2025-08-05 23:43:07,231 - mmdet - INFO - Epoch [1][4200/4665]	lr: 5.000e-03, eta: 1:10:19, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1583, acc: 95.8977, loss_bbox: 0.1062, loss: 0.2645, grad_norm: 3.4439
2025-08-05 23:43:21,693 - mmdet - INFO - Epoch [1][4250/4665]	lr: 5.000e-03, eta: 1:10:04, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1366, acc: 96.4176, loss_bbox: 0.0874, loss: 0.2240, grad_norm: 3.2278
2025-08-05 23:43:35,683 - mmdet - INFO - Epoch [1][4300/4665]	lr: 5.000e-03, eta: 1:09:48, time: 0.280, data_time: 0.005, memory: 12111, loss_cls: 0.1326, acc: 96.4836, loss_bbox: 0.0944, loss: 0.2270, grad_norm: 3.2449
2025-08-05 23:43:50,058 - mmdet - INFO - Epoch [1][4350/4665]	lr: 5.000e-03, eta: 1:09:33, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1516, acc: 96.0510, loss_bbox: 0.0989, loss: 0.2505, grad_norm: 3.6031
2025-08-05 23:44:04,442 - mmdet - INFO - Epoch [1][4400/4665]	lr: 5.000e-03, eta: 1:09:17, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1718, acc: 95.7880, loss_bbox: 0.1033, loss: 0.2751, grad_norm: 4.1251
2025-08-05 23:44:18,969 - mmdet - INFO - Epoch [1][4450/4665]	lr: 5.000e-03, eta: 1:09:03, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1578, acc: 95.7966, loss_bbox: 0.0999, loss: 0.2576, grad_norm: 3.6840
2025-08-05 23:44:33,457 - mmdet - INFO - Epoch [1][4500/4665]	lr: 5.000e-03, eta: 1:08:48, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1558, acc: 96.0377, loss_bbox: 0.0961, loss: 0.2519, grad_norm: 3.3803
2025-08-05 23:44:48,008 - mmdet - INFO - Epoch [1][4550/4665]	lr: 5.000e-03, eta: 1:08:33, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1474, acc: 96.3495, loss_bbox: 0.0916, loss: 0.2390, grad_norm: 3.7209
2025-08-05 23:45:02,429 - mmdet - INFO - Epoch [1][4600/4665]	lr: 5.000e-03, eta: 1:08:18, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1443, acc: 96.1786, loss_bbox: 0.0887, loss: 0.2330, grad_norm: 3.1489
2025-08-05 23:45:16,791 - mmdet - INFO - Epoch [1][4650/4665]	lr: 5.000e-03, eta: 1:08:03, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1325, acc: 95.4430, loss_bbox: 0.0868, loss: 0.2194, grad_norm: 3.0365
2025-08-05 23:45:51,350 - mmdet - INFO - Epoch [2][50/4665]	lr: 5.000e-03, eta: 1:08:14, time: 0.585, data_time: 0.302, memory: 12111, loss_cls: 0.1150, acc: 97.0427, loss_bbox: 0.0752, loss: 0.1902, grad_norm: 2.6648
2025-08-05 23:46:06,085 - mmdet - INFO - Epoch [2][100/4665]	lr: 5.000e-03, eta: 1:08:00, time: 0.295, data_time: 0.006, memory: 12111, loss_cls: 0.1409, acc: 96.1513, loss_bbox: 0.0952, loss: 0.2361, grad_norm: 3.3924
2025-08-05 23:46:20,710 - mmdet - INFO - Epoch [2][150/4665]	lr: 5.000e-03, eta: 1:07:45, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1399, acc: 96.2993, loss_bbox: 0.0990, loss: 0.2389, grad_norm: 3.4870
2025-08-05 23:46:35,166 - mmdet - INFO - Epoch [2][200/4665]	lr: 5.000e-03, eta: 1:07:30, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1471, acc: 95.8873, loss_bbox: 0.1062, loss: 0.2532, grad_norm: 3.4840
2025-08-05 23:46:49,477 - mmdet - INFO - Epoch [2][250/4665]	lr: 5.000e-03, eta: 1:07:14, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1307, acc: 96.5067, loss_bbox: 0.0916, loss: 0.2223, grad_norm: 3.3086
2025-08-05 23:47:04,255 - mmdet - INFO - Epoch [2][300/4665]	lr: 5.000e-03, eta: 1:07:00, time: 0.296, data_time: 0.006, memory: 12111, loss_cls: 0.1383, acc: 95.9534, loss_bbox: 0.1024, loss: 0.2407, grad_norm: 3.5339
2025-08-05 23:47:18,575 - mmdet - INFO - Epoch [2][350/4665]	lr: 5.000e-03, eta: 1:06:44, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1355, acc: 96.1070, loss_bbox: 0.0952, loss: 0.2307, grad_norm: 3.4510
2025-08-05 23:47:33,193 - mmdet - INFO - Epoch [2][400/4665]	lr: 5.000e-03, eta: 1:06:29, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1486, acc: 95.6863, loss_bbox: 0.1084, loss: 0.2570, grad_norm: 3.5329
2025-08-05 23:47:47,581 - mmdet - INFO - Epoch [2][450/4665]	lr: 5.000e-03, eta: 1:06:14, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1284, acc: 96.5542, loss_bbox: 0.0935, loss: 0.2219, grad_norm: 3.3463
2025-08-05 23:48:02,168 - mmdet - INFO - Epoch [2][500/4665]	lr: 5.000e-03, eta: 1:05:59, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1475, acc: 96.0510, loss_bbox: 0.1005, loss: 0.2480, grad_norm: 3.6371
2025-08-05 23:48:16,919 - mmdet - INFO - Epoch [2][550/4665]	lr: 5.000e-03, eta: 1:05:44, time: 0.295, data_time: 0.007, memory: 12111, loss_cls: 0.1679, acc: 95.4430, loss_bbox: 0.1096, loss: 0.2775, grad_norm: 3.5331
2025-08-05 23:48:31,424 - mmdet - INFO - Epoch [2][600/4665]	lr: 5.000e-03, eta: 1:05:29, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1456, acc: 96.1063, loss_bbox: 0.0955, loss: 0.2411, grad_norm: 3.3803
2025-08-05 23:48:45,744 - mmdet - INFO - Epoch [2][650/4665]	lr: 5.000e-03, eta: 1:05:14, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1259, acc: 96.5978, loss_bbox: 0.0881, loss: 0.2140, grad_norm: 3.1954
2025-08-05 23:49:00,423 - mmdet - INFO - Epoch [2][700/4665]	lr: 5.000e-03, eta: 1:04:59, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1296, acc: 96.5633, loss_bbox: 0.0924, loss: 0.2220, grad_norm: 3.2343
2025-08-05 23:49:14,800 - mmdet - INFO - Epoch [2][750/4665]	lr: 5.000e-03, eta: 1:04:44, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1335, acc: 95.5013, loss_bbox: 0.0922, loss: 0.2258, grad_norm: 3.3157
2025-08-05 23:49:29,279 - mmdet - INFO - Epoch [2][800/4665]	lr: 5.000e-03, eta: 1:04:29, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1483, acc: 95.8929, loss_bbox: 0.1073, loss: 0.2556, grad_norm: 3.4555
2025-08-05 23:49:43,714 - mmdet - INFO - Epoch [2][850/4665]	lr: 5.000e-03, eta: 1:04:13, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1488, acc: 96.1017, loss_bbox: 0.0931, loss: 0.2419, grad_norm: 3.4261
2025-08-05 23:49:58,167 - mmdet - INFO - Epoch [2][900/4665]	lr: 5.000e-03, eta: 1:03:58, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1274, acc: 96.6220, loss_bbox: 0.0799, loss: 0.2073, grad_norm: 3.3886
2025-08-05 23:50:13,015 - mmdet - INFO - Epoch [2][950/4665]	lr: 5.000e-03, eta: 1:03:44, time: 0.297, data_time: 0.006, memory: 12111, loss_cls: 0.1672, acc: 95.4323, loss_bbox: 0.1055, loss: 0.2726, grad_norm: 3.6914
2025-08-05 23:50:27,643 - mmdet - INFO - Epoch [2][1000/4665]	lr: 5.000e-03, eta: 1:03:29, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1383, acc: 96.2359, loss_bbox: 0.0967, loss: 0.2350, grad_norm: 3.1944
2025-08-05 23:50:42,262 - mmdet - INFO - Epoch [2][1050/4665]	lr: 5.000e-03, eta: 1:03:15, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1067, acc: 97.1926, loss_bbox: 0.0723, loss: 0.1790, grad_norm: 2.7184
2025-08-05 23:50:56,528 - mmdet - INFO - Epoch [2][1100/4665]	lr: 5.000e-03, eta: 1:02:59, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1132, acc: 97.0568, loss_bbox: 0.0782, loss: 0.1913, grad_norm: 2.6374
2025-08-05 23:51:11,038 - mmdet - INFO - Epoch [2][1150/4665]	lr: 5.000e-03, eta: 1:02:44, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1338, acc: 96.4790, loss_bbox: 0.0894, loss: 0.2232, grad_norm: 3.2639
2025-08-05 23:51:25,332 - mmdet - INFO - Epoch [2][1200/4665]	lr: 5.000e-03, eta: 1:02:29, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1215, acc: 96.6516, loss_bbox: 0.0858, loss: 0.2073, grad_norm: 3.1934
2025-08-05 23:51:39,728 - mmdet - INFO - Epoch [2][1250/4665]	lr: 5.000e-03, eta: 1:02:13, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1477, acc: 96.0809, loss_bbox: 0.1021, loss: 0.2498, grad_norm: 3.4173
2025-08-05 23:51:54,245 - mmdet - INFO - Epoch [2][1300/4665]	lr: 5.000e-03, eta: 1:01:58, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1412, acc: 96.2328, loss_bbox: 0.0954, loss: 0.2366, grad_norm: 3.3297
2025-08-05 23:52:08,827 - mmdet - INFO - Epoch [2][1350/4665]	lr: 5.000e-03, eta: 1:01:44, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1394, acc: 96.3141, loss_bbox: 0.0945, loss: 0.2339, grad_norm: 3.4339
2025-08-05 23:52:23,424 - mmdet - INFO - Epoch [2][1400/4665]	lr: 5.000e-03, eta: 1:01:29, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1237, acc: 95.5771, loss_bbox: 0.0871, loss: 0.2108, grad_norm: 3.0131
2025-08-05 23:52:38,081 - mmdet - INFO - Epoch [2][1450/4665]	lr: 5.000e-03, eta: 1:01:14, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1451, acc: 96.1509, loss_bbox: 0.1025, loss: 0.2476, grad_norm: 3.3637
2025-08-05 23:52:52,606 - mmdet - INFO - Epoch [2][1500/4665]	lr: 5.000e-03, eta: 1:00:59, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1354, acc: 96.3618, loss_bbox: 0.0972, loss: 0.2326, grad_norm: 3.2335
2025-08-05 23:53:06,945 - mmdet - INFO - Epoch [2][1550/4665]	lr: 5.000e-03, eta: 1:00:44, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1342, acc: 96.4256, loss_bbox: 0.0977, loss: 0.2319, grad_norm: 3.1555
2025-08-05 23:53:21,614 - mmdet - INFO - Epoch [2][1600/4665]	lr: 5.000e-03, eta: 1:00:30, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1705, acc: 95.3288, loss_bbox: 0.1066, loss: 0.2770, grad_norm: 4.0071
2025-08-05 23:53:35,833 - mmdet - INFO - Epoch [2][1650/4665]	lr: 5.000e-03, eta: 1:00:14, time: 0.284, data_time: 0.006, memory: 12111, loss_cls: 0.1465, acc: 95.4056, loss_bbox: 0.0951, loss: 0.2417, grad_norm: 3.6515
2025-08-05 23:53:50,233 - mmdet - INFO - Epoch [2][1700/4665]	lr: 5.000e-03, eta: 0:59:59, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1407, acc: 96.3092, loss_bbox: 0.0940, loss: 0.2347, grad_norm: 3.4329
2025-08-05 23:54:04,595 - mmdet - INFO - Epoch [2][1750/4665]	lr: 5.000e-03, eta: 0:59:44, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1299, acc: 95.3150, loss_bbox: 0.0957, loss: 0.2256, grad_norm: 3.3666
2025-08-05 23:54:18,966 - mmdet - INFO - Epoch [2][1800/4665]	lr: 5.000e-03, eta: 0:59:29, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1237, acc: 96.6405, loss_bbox: 0.0894, loss: 0.2131, grad_norm: 3.1622
2025-08-05 23:54:33,264 - mmdet - INFO - Epoch [2][1850/4665]	lr: 5.000e-03, eta: 0:59:13, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1379, acc: 96.5839, loss_bbox: 0.0879, loss: 0.2258, grad_norm: 3.5489
2025-08-05 23:54:47,723 - mmdet - INFO - Epoch [2][1900/4665]	lr: 5.000e-03, eta: 0:58:58, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1431, acc: 96.2737, loss_bbox: 0.0960, loss: 0.2391, grad_norm: 3.3831
2025-08-05 23:55:02,364 - mmdet - INFO - Epoch [2][1950/4665]	lr: 5.000e-03, eta: 0:58:44, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1384, acc: 96.1205, loss_bbox: 0.0967, loss: 0.2351, grad_norm: 3.2542
2025-08-05 23:55:16,597 - mmdet - INFO - Epoch [2][2000/4665]	lr: 5.000e-03, eta: 0:58:28, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1286, acc: 96.4113, loss_bbox: 0.0942, loss: 0.2228, grad_norm: 3.2864
2025-08-05 23:55:31,144 - mmdet - INFO - Epoch [2][2050/4665]	lr: 5.000e-03, eta: 0:58:14, time: 0.291, data_time: 0.005, memory: 12111, loss_cls: 0.1233, acc: 96.7794, loss_bbox: 0.0797, loss: 0.2029, grad_norm: 3.1729
2025-08-05 23:55:46,070 - mmdet - INFO - Epoch [2][2100/4665]	lr: 5.000e-03, eta: 0:58:00, time: 0.299, data_time: 0.006, memory: 12111, loss_cls: 0.1490, acc: 95.7970, loss_bbox: 0.1045, loss: 0.2534, grad_norm: 3.5550
2025-08-05 23:56:00,514 - mmdet - INFO - Epoch [2][2150/4665]	lr: 5.000e-03, eta: 0:57:45, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1349, acc: 95.4064, loss_bbox: 0.0929, loss: 0.2278, grad_norm: 3.5487
2025-08-05 23:56:15,053 - mmdet - INFO - Epoch [2][2200/4665]	lr: 5.000e-03, eta: 0:57:30, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1343, acc: 96.1859, loss_bbox: 0.0984, loss: 0.2327, grad_norm: 3.3754
2025-08-05 23:56:29,628 - mmdet - INFO - Epoch [2][2250/4665]	lr: 5.000e-03, eta: 0:57:15, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1456, acc: 96.0150, loss_bbox: 0.0967, loss: 0.2423, grad_norm: 3.3814
2025-08-05 23:56:44,053 - mmdet - INFO - Epoch [2][2300/4665]	lr: 5.000e-03, eta: 0:57:00, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1482, acc: 96.1755, loss_bbox: 0.1031, loss: 0.2513, grad_norm: 3.3099
2025-08-05 23:56:58,593 - mmdet - INFO - Epoch [2][2350/4665]	lr: 5.000e-03, eta: 0:56:45, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1431, acc: 96.2637, loss_bbox: 0.0977, loss: 0.2408, grad_norm: 3.3686
2025-08-05 23:57:13,135 - mmdet - INFO - Epoch [2][2400/4665]	lr: 5.000e-03, eta: 0:56:31, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1224, acc: 96.6432, loss_bbox: 0.0875, loss: 0.2099, grad_norm: 3.0055
2025-08-05 23:57:27,495 - mmdet - INFO - Epoch [2][2450/4665]	lr: 5.000e-03, eta: 0:56:16, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1248, acc: 96.5009, loss_bbox: 0.0920, loss: 0.2168, grad_norm: 3.0503
2025-08-05 23:57:41,846 - mmdet - INFO - Epoch [2][2500/4665]	lr: 5.000e-03, eta: 0:56:01, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1345, acc: 96.2976, loss_bbox: 0.0939, loss: 0.2285, grad_norm: 3.4059
2025-08-05 23:57:56,379 - mmdet - INFO - Epoch [2][2550/4665]	lr: 5.000e-03, eta: 0:55:46, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1234, acc: 96.4922, loss_bbox: 0.0935, loss: 0.2169, grad_norm: 3.0015
2025-08-05 23:58:10,516 - mmdet - INFO - Epoch [2][2600/4665]	lr: 5.000e-03, eta: 0:55:30, time: 0.283, data_time: 0.006, memory: 12111, loss_cls: 0.1385, acc: 96.3339, loss_bbox: 0.0967, loss: 0.2353, grad_norm: 3.3005
2025-08-05 23:58:24,866 - mmdet - INFO - Epoch [2][2650/4665]	lr: 5.000e-03, eta: 0:55:15, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1403, acc: 96.4638, loss_bbox: 0.0954, loss: 0.2357, grad_norm: 3.2566
2025-08-05 23:58:39,163 - mmdet - INFO - Epoch [2][2700/4665]	lr: 5.000e-03, eta: 0:55:00, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1235, acc: 96.7437, loss_bbox: 0.0856, loss: 0.2092, grad_norm: 2.9213
2025-08-05 23:58:53,874 - mmdet - INFO - Epoch [2][2750/4665]	lr: 5.000e-03, eta: 0:54:46, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1345, acc: 96.2466, loss_bbox: 0.1027, loss: 0.2372, grad_norm: 3.1624
2025-08-05 23:59:08,698 - mmdet - INFO - Epoch [2][2800/4665]	lr: 5.000e-03, eta: 0:54:32, time: 0.296, data_time: 0.006, memory: 12111, loss_cls: 0.1225, acc: 96.6020, loss_bbox: 0.0848, loss: 0.2073, grad_norm: 2.7139
2025-08-05 23:59:23,256 - mmdet - INFO - Epoch [2][2850/4665]	lr: 5.000e-03, eta: 0:54:17, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1239, acc: 96.4589, loss_bbox: 0.1017, loss: 0.2257, grad_norm: 3.0141
2025-08-05 23:59:37,684 - mmdet - INFO - Epoch [2][2900/4665]	lr: 5.000e-03, eta: 0:54:02, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1470, acc: 95.9837, loss_bbox: 0.1002, loss: 0.2472, grad_norm: 3.3808
2025-08-05 23:59:52,270 - mmdet - INFO - Epoch [2][2950/4665]	lr: 5.000e-03, eta: 0:53:47, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1338, acc: 96.2365, loss_bbox: 0.0954, loss: 0.2292, grad_norm: 3.3012
2025-08-06 00:00:06,770 - mmdet - INFO - Epoch [2][3000/4665]	lr: 5.000e-03, eta: 0:53:33, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1146, acc: 96.7211, loss_bbox: 0.0844, loss: 0.1990, grad_norm: 2.8644
2025-08-06 00:00:21,046 - mmdet - INFO - Epoch [2][3050/4665]	lr: 5.000e-03, eta: 0:53:17, time: 0.286, data_time: 0.005, memory: 12111, loss_cls: 0.1248, acc: 96.4825, loss_bbox: 0.0960, loss: 0.2208, grad_norm: 3.2996
2025-08-06 00:00:35,575 - mmdet - INFO - Epoch [2][3100/4665]	lr: 5.000e-03, eta: 0:53:03, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1445, acc: 95.1987, loss_bbox: 0.0981, loss: 0.2425, grad_norm: 3.3952
2025-08-06 00:00:50,150 - mmdet - INFO - Epoch [2][3150/4665]	lr: 5.000e-03, eta: 0:52:48, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1224, acc: 96.7820, loss_bbox: 0.0855, loss: 0.2079, grad_norm: 3.1971
2025-08-06 00:01:04,682 - mmdet - INFO - Epoch [2][3200/4665]	lr: 5.000e-03, eta: 0:52:33, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1407, acc: 96.2319, loss_bbox: 0.0996, loss: 0.2404, grad_norm: 3.2245
2025-08-06 00:01:19,381 - mmdet - INFO - Epoch [2][3250/4665]	lr: 5.000e-03, eta: 0:52:19, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1336, acc: 96.2482, loss_bbox: 0.0983, loss: 0.2319, grad_norm: 3.1736
2025-08-06 00:01:33,576 - mmdet - INFO - Epoch [2][3300/4665]	lr: 5.000e-03, eta: 0:52:04, time: 0.284, data_time: 0.006, memory: 12111, loss_cls: 0.1252, acc: 96.6087, loss_bbox: 0.0922, loss: 0.2174, grad_norm: 3.0364
2025-08-06 00:01:47,715 - mmdet - INFO - Epoch [2][3350/4665]	lr: 5.000e-03, eta: 0:51:49, time: 0.283, data_time: 0.005, memory: 12111, loss_cls: 0.1315, acc: 96.6215, loss_bbox: 0.0869, loss: 0.2184, grad_norm: 3.2516
2025-08-06 00:02:02,282 - mmdet - INFO - Epoch [2][3400/4665]	lr: 5.000e-03, eta: 0:51:34, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1527, acc: 95.9142, loss_bbox: 0.1042, loss: 0.2569, grad_norm: 3.3928
2025-08-06 00:02:16,738 - mmdet - INFO - Epoch [2][3450/4665]	lr: 5.000e-03, eta: 0:51:19, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1422, acc: 95.1105, loss_bbox: 0.0992, loss: 0.2414, grad_norm: 3.4306
2025-08-06 00:02:30,880 - mmdet - INFO - Epoch [2][3500/4665]	lr: 5.000e-03, eta: 0:51:04, time: 0.283, data_time: 0.005, memory: 12111, loss_cls: 0.1477, acc: 96.1148, loss_bbox: 0.1022, loss: 0.2498, grad_norm: 3.6275
2025-08-06 00:02:45,403 - mmdet - INFO - Epoch [2][3550/4665]	lr: 5.000e-03, eta: 0:50:49, time: 0.290, data_time: 0.005, memory: 12111, loss_cls: 0.1379, acc: 96.0358, loss_bbox: 0.0967, loss: 0.2346, grad_norm: 3.2252
2025-08-06 00:02:59,556 - mmdet - INFO - Epoch [2][3600/4665]	lr: 5.000e-03, eta: 0:50:34, time: 0.283, data_time: 0.006, memory: 12111, loss_cls: 0.1446, acc: 95.1586, loss_bbox: 0.1025, loss: 0.2472, grad_norm: 3.5652
2025-08-06 00:03:14,094 - mmdet - INFO - Epoch [2][3650/4665]	lr: 5.000e-03, eta: 0:50:19, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1320, acc: 96.5784, loss_bbox: 0.0939, loss: 0.2259, grad_norm: 3.0507
2025-08-06 00:03:28,668 - mmdet - INFO - Epoch [2][3700/4665]	lr: 5.000e-03, eta: 0:50:05, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1442, acc: 96.1009, loss_bbox: 0.1050, loss: 0.2492, grad_norm: 3.3637
2025-08-06 00:03:43,505 - mmdet - INFO - Epoch [2][3750/4665]	lr: 5.000e-03, eta: 0:49:50, time: 0.297, data_time: 0.006, memory: 12111, loss_cls: 0.1278, acc: 96.2724, loss_bbox: 0.0922, loss: 0.2200, grad_norm: 3.0204
2025-08-06 00:03:57,783 - mmdet - INFO - Epoch [2][3800/4665]	lr: 5.000e-03, eta: 0:49:35, time: 0.286, data_time: 0.005, memory: 12111, loss_cls: 0.1417, acc: 96.4568, loss_bbox: 0.0893, loss: 0.2311, grad_norm: 3.4350
2025-08-06 00:04:11,992 - mmdet - INFO - Epoch [2][3850/4665]	lr: 5.000e-03, eta: 0:49:20, time: 0.284, data_time: 0.005, memory: 12111, loss_cls: 0.1302, acc: 96.3824, loss_bbox: 0.1049, loss: 0.2350, grad_norm: 3.3208
2025-08-06 00:04:26,645 - mmdet - INFO - Epoch [2][3900/4665]	lr: 5.000e-03, eta: 0:49:06, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1265, acc: 96.6526, loss_bbox: 0.0864, loss: 0.2130, grad_norm: 3.0729
2025-08-06 00:04:41,296 - mmdet - INFO - Epoch [2][3950/4665]	lr: 5.000e-03, eta: 0:48:51, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1322, acc: 96.1911, loss_bbox: 0.0997, loss: 0.2319, grad_norm: 3.1912
2025-08-06 00:04:55,743 - mmdet - INFO - Epoch [2][4000/4665]	lr: 5.000e-03, eta: 0:48:37, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1344, acc: 96.2481, loss_bbox: 0.0949, loss: 0.2293, grad_norm: 3.2178
2025-08-06 00:05:10,380 - mmdet - INFO - Epoch [2][4050/4665]	lr: 5.000e-03, eta: 0:48:22, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1372, acc: 96.0371, loss_bbox: 0.1036, loss: 0.2408, grad_norm: 3.2811
2025-08-06 00:05:24,729 - mmdet - INFO - Epoch [2][4100/4665]	lr: 5.000e-03, eta: 0:48:07, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1273, acc: 96.5277, loss_bbox: 0.0843, loss: 0.2117, grad_norm: 3.1128
2025-08-06 00:05:39,291 - mmdet - INFO - Epoch [2][4150/4665]	lr: 5.000e-03, eta: 0:47:53, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1619, acc: 95.6083, loss_bbox: 0.1045, loss: 0.2663, grad_norm: 3.6773
2025-08-06 00:05:54,213 - mmdet - INFO - Epoch [2][4200/4665]	lr: 5.000e-03, eta: 0:47:38, time: 0.298, data_time: 0.006, memory: 12111, loss_cls: 0.1350, acc: 96.1840, loss_bbox: 0.0944, loss: 0.2293, grad_norm: 3.2551
2025-08-06 00:06:08,662 - mmdet - INFO - Epoch [2][4250/4665]	lr: 5.000e-03, eta: 0:47:24, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1341, acc: 96.3117, loss_bbox: 0.0972, loss: 0.2313, grad_norm: 3.2958
2025-08-06 00:06:23,344 - mmdet - INFO - Epoch [2][4300/4665]	lr: 5.000e-03, eta: 0:47:09, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1460, acc: 95.9431, loss_bbox: 0.1009, loss: 0.2469, grad_norm: 3.3813
2025-08-06 00:06:37,577 - mmdet - INFO - Epoch [2][4350/4665]	lr: 5.000e-03, eta: 0:46:54, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1340, acc: 95.2523, loss_bbox: 0.0932, loss: 0.2272, grad_norm: 3.2716
2025-08-06 00:06:52,234 - mmdet - INFO - Epoch [2][4400/4665]	lr: 5.000e-03, eta: 0:46:40, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1342, acc: 96.3025, loss_bbox: 0.0990, loss: 0.2333, grad_norm: 3.2061
2025-08-06 00:07:06,848 - mmdet - INFO - Epoch [2][4450/4665]	lr: 5.000e-03, eta: 0:46:25, time: 0.292, data_time: 0.005, memory: 12111, loss_cls: 0.1300, acc: 96.4090, loss_bbox: 0.0906, loss: 0.2206, grad_norm: 3.0547
2025-08-06 00:07:21,395 - mmdet - INFO - Epoch [2][4500/4665]	lr: 5.000e-03, eta: 0:46:10, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1357, acc: 96.2631, loss_bbox: 0.1044, loss: 0.2401, grad_norm: 3.1409
2025-08-06 00:07:36,097 - mmdet - INFO - Epoch [2][4550/4665]	lr: 5.000e-03, eta: 0:45:56, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1416, acc: 96.0125, loss_bbox: 0.1007, loss: 0.2422, grad_norm: 3.5262
2025-08-06 00:07:51,015 - mmdet - INFO - Epoch [2][4600/4665]	lr: 5.000e-03, eta: 0:45:42, time: 0.298, data_time: 0.006, memory: 12111, loss_cls: 0.1201, acc: 96.5887, loss_bbox: 0.0900, loss: 0.2101, grad_norm: 2.8748
2025-08-06 00:08:05,641 - mmdet - INFO - Epoch [2][4650/4665]	lr: 5.000e-03, eta: 0:45:27, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1336, acc: 95.4164, loss_bbox: 0.0939, loss: 0.2275, grad_norm: 3.0390
2025-08-06 00:08:10,879 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-08-06 00:09:18,012 - mmdet - INFO - Evaluating bbox...
2025-08-06 00:09:27,324 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-06 00:09:27,325 - mmdet - INFO - Epoch(val) [2][850]	bbox_mAP: 0.1170, bbox_mAP_50: 0.2830, bbox_mAP_75: 0.0730, bbox_mAP_s: 0.0650, bbox_mAP_m: 0.1750, bbox_mAP_l: 0.1630, bbox_mAP_copypaste: 0.117 0.283 0.073 0.065 0.175 0.163
2025-08-06 00:09:57,238 - mmdet - INFO - Epoch [3][50/4665]	lr: 5.000e-03, eta: 0:45:19, time: 0.598, data_time: 0.313, memory: 12111, loss_cls: 0.1344, acc: 96.2569, loss_bbox: 0.0970, loss: 0.2314, grad_norm: 3.2979
2025-08-06 00:10:11,948 - mmdet - INFO - Epoch [3][100/4665]	lr: 5.000e-03, eta: 0:45:04, time: 0.294, data_time: 0.006, memory: 12111, loss_cls: 0.1312, acc: 96.4152, loss_bbox: 0.0953, loss: 0.2265, grad_norm: 3.1684
2025-08-06 00:10:26,531 - mmdet - INFO - Epoch [3][150/4665]	lr: 5.000e-03, eta: 0:44:50, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1319, acc: 96.0579, loss_bbox: 0.0972, loss: 0.2290, grad_norm: 3.4792
2025-08-06 00:10:40,716 - mmdet - INFO - Epoch [3][200/4665]	lr: 5.000e-03, eta: 0:44:34, time: 0.284, data_time: 0.006, memory: 12111, loss_cls: 0.1121, acc: 96.8866, loss_bbox: 0.0752, loss: 0.1873, grad_norm: 2.9462
2025-08-06 00:10:55,303 - mmdet - INFO - Epoch [3][250/4665]	lr: 5.000e-03, eta: 0:44:20, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1181, acc: 96.7194, loss_bbox: 0.0860, loss: 0.2041, grad_norm: 3.1331
2025-08-06 00:11:10,141 - mmdet - INFO - Epoch [3][300/4665]	lr: 5.000e-03, eta: 0:44:05, time: 0.297, data_time: 0.006, memory: 12111, loss_cls: 0.1185, acc: 96.5524, loss_bbox: 0.0900, loss: 0.2085, grad_norm: 2.9389
2025-08-06 00:11:24,682 - mmdet - INFO - Epoch [3][350/4665]	lr: 5.000e-03, eta: 0:43:51, time: 0.291, data_time: 0.006, memory: 12111, loss_cls: 0.1201, acc: 96.6679, loss_bbox: 0.0871, loss: 0.2073, grad_norm: 3.0907
2025-08-06 00:11:39,472 - mmdet - INFO - Epoch [3][400/4665]	lr: 5.000e-03, eta: 0:43:36, time: 0.296, data_time: 0.006, memory: 12111, loss_cls: 0.1211, acc: 96.4987, loss_bbox: 0.0905, loss: 0.2116, grad_norm: 2.8700
2025-08-06 00:11:53,561 - mmdet - INFO - Epoch [3][450/4665]	lr: 5.000e-03, eta: 0:43:21, time: 0.282, data_time: 0.005, memory: 12111, loss_cls: 0.1124, acc: 96.7389, loss_bbox: 0.0919, loss: 0.2043, grad_norm: 3.0011
2025-08-06 00:12:07,645 - mmdet - INFO - Epoch [3][500/4665]	lr: 5.000e-03, eta: 0:43:06, time: 0.282, data_time: 0.005, memory: 12111, loss_cls: 0.1360, acc: 96.3167, loss_bbox: 0.0907, loss: 0.2267, grad_norm: 3.6099
2025-08-06 00:12:22,230 - mmdet - INFO - Epoch [3][550/4665]	lr: 5.000e-03, eta: 0:42:51, time: 0.292, data_time: 0.005, memory: 12111, loss_cls: 0.1331, acc: 96.1275, loss_bbox: 0.0956, loss: 0.2287, grad_norm: 3.1690
2025-08-06 00:12:36,718 - mmdet - INFO - Epoch [3][600/4665]	lr: 5.000e-03, eta: 0:42:36, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1167, acc: 96.6983, loss_bbox: 0.0945, loss: 0.2112, grad_norm: 3.3470
2025-08-06 00:12:50,996 - mmdet - INFO - Epoch [3][650/4665]	lr: 5.000e-03, eta: 0:42:21, time: 0.286, data_time: 0.006, memory: 12111, loss_cls: 0.1210, acc: 96.3942, loss_bbox: 0.0963, loss: 0.2173, grad_norm: 3.2412
2025-08-06 00:13:05,582 - mmdet - INFO - Epoch [3][700/4665]	lr: 5.000e-03, eta: 0:42:07, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1260, acc: 95.2453, loss_bbox: 0.0949, loss: 0.2210, grad_norm: 3.2832
2025-08-06 00:13:20,339 - mmdet - INFO - Epoch [3][750/4665]	lr: 5.000e-03, eta: 0:41:52, time: 0.295, data_time: 0.006, memory: 12111, loss_cls: 0.1265, acc: 96.2603, loss_bbox: 0.0946, loss: 0.2211, grad_norm: 3.2311
2025-08-06 00:13:34,678 - mmdet - INFO - Epoch [3][800/4665]	lr: 5.000e-03, eta: 0:41:37, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1149, acc: 96.7380, loss_bbox: 0.0920, loss: 0.2069, grad_norm: 3.1442
2025-08-06 00:13:49,118 - mmdet - INFO - Epoch [3][850/4665]	lr: 5.000e-03, eta: 0:41:22, time: 0.289, data_time: 0.006, memory: 12111, loss_cls: 0.1399, acc: 95.8177, loss_bbox: 0.1056, loss: 0.2455, grad_norm: 3.4787
2025-08-06 00:14:03,632 - mmdet - INFO - Epoch [3][900/4665]	lr: 5.000e-03, eta: 0:41:08, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1191, acc: 95.4714, loss_bbox: 0.0876, loss: 0.2067, grad_norm: 2.9085
2025-08-06 00:14:18,414 - mmdet - INFO - Epoch [3][950/4665]	lr: 5.000e-03, eta: 0:40:53, time: 0.296, data_time: 0.006, memory: 12111, loss_cls: 0.1356, acc: 96.1712, loss_bbox: 0.0956, loss: 0.2312, grad_norm: 3.1879
2025-08-06 00:14:32,902 - mmdet - INFO - Epoch [3][1000/4665]	lr: 5.000e-03, eta: 0:40:38, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1353, acc: 95.3746, loss_bbox: 0.0964, loss: 0.2317, grad_norm: 3.3813
2025-08-06 00:14:47,383 - mmdet - INFO - Epoch [3][1050/4665]	lr: 5.000e-03, eta: 0:40:24, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1036, acc: 97.0808, loss_bbox: 0.0826, loss: 0.1862, grad_norm: 2.6849
2025-08-06 00:15:02,012 - mmdet - INFO - Epoch [3][1100/4665]	lr: 5.000e-03, eta: 0:40:09, time: 0.293, data_time: 0.006, memory: 12111, loss_cls: 0.1213, acc: 96.4138, loss_bbox: 0.0921, loss: 0.2134, grad_norm: 2.9931
2025-08-06 00:15:16,285 - mmdet - INFO - Epoch [3][1150/4665]	lr: 5.000e-03, eta: 0:39:54, time: 0.285, data_time: 0.006, memory: 12111, loss_cls: 0.1267, acc: 96.4155, loss_bbox: 0.0999, loss: 0.2266, grad_norm: 3.1567
2025-08-06 00:15:30,662 - mmdet - INFO - Epoch [3][1200/4665]	lr: 5.000e-03, eta: 0:39:39, time: 0.288, data_time: 0.006, memory: 12111, loss_cls: 0.1330, acc: 96.2600, loss_bbox: 0.0983, loss: 0.2314, grad_norm: 3.3467
2025-08-06 00:15:44,694 - mmdet - INFO - Epoch [3][1250/4665]	lr: 5.000e-03, eta: 0:39:24, time: 0.281, data_time: 0.006, memory: 12111, loss_cls: 0.1227, acc: 96.7290, loss_bbox: 0.0872, loss: 0.2099, grad_norm: 3.0745
2025-08-06 00:15:59,305 - mmdet - INFO - Epoch [3][1300/4665]	lr: 5.000e-03, eta: 0:39:09, time: 0.292, data_time: 0.006, memory: 12111, loss_cls: 0.1339, acc: 96.0271, loss_bbox: 0.0972, loss: 0.2311, grad_norm: 3.3744
2025-08-06 00:16:14,091 - mmdet - INFO - Epoch [3][1350/4665]	lr: 5.000e-03, eta: 0:38:55, time: 0.296, data_time: 0.006, memory: 12111, loss_cls: 0.1281, acc: 96.2477, loss_bbox: 0.1004, loss: 0.2286, grad_norm: 3.0211
2025-08-06 00:16:28,607 - mmdet - INFO - Epoch [3][1400/4665]	lr: 5.000e-03, eta: 0:38:40, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1160, acc: 96.6238, loss_bbox: 0.0923, loss: 0.2083, grad_norm: 3.0032
2025-08-06 00:16:43,130 - mmdet - INFO - Epoch [3][1450/4665]	lr: 5.000e-03, eta: 0:38:25, time: 0.290, data_time: 0.006, memory: 12111, loss_cls: 0.1328, acc: 96.3174, loss_bbox: 0.0965, loss: 0.2293, grad_norm: 3.4225
2025-08-06 00:16:57,496 - mmdet - INFO - Epoch [3][1500/4665]	lr: 5.000e-03, eta: 0:38:11, time: 0.287, data_time: 0.006, memory: 12111, loss_cls: 0.1073, acc: 96.9580, loss_bbox: 0.0904, loss: 0.1977, grad_norm: 2.7801
2025-08-06 00:17:12,267 - mmdet - INFO - Epoch [3][1550/4665]	lr: 5.000e-03, eta: 0:37:56, time: 0.295, data_time: 0.005, memory: 12111, loss_cls: 0.1349, acc: 96.0998, loss_bbox: 0.0921, loss: 0.2270, grad_norm: 3.6381
2025-08-06 00:17:26,804 - mmdet - INFO - Epoch [3][1600/4665]	lr: 5.000e-03, eta: 0:37:41, time: 0.291, data_time: 0.005, memory: 12111, loss_cls: 0.1175, acc: 96.5408, loss_bbox: 0.0916, loss: 0.2091, grad_norm: 2.9509
2025-08-06 00:17:41,065 - mmdet - INFO - Epoch [3][1650/4665]	lr: 5.000e-03, eta: 0:37:27, time: 0.285, data_time: 0.005, memory: 12111, loss_cls: 0.1107, acc: 96.7869, loss_bbox: 0.0836, loss: 0.1944, grad_norm: 2.9726
2025-08-06 00:17:55,552 - mmdet - INFO - Epoch [3][1700/4665]	lr: 5.000e-03, eta: 0:37:12, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1287, acc: 96.2667, loss_bbox: 0.0971, loss: 0.2258, grad_norm: 3.3359
2025-08-06 00:18:09,923 - mmdet - INFO - Epoch [3][1750/4665]	lr: 5.000e-03, eta: 0:36:57, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1218, acc: 96.3643, loss_bbox: 0.0935, loss: 0.2153, grad_norm: 2.9771
2025-08-06 00:18:24,350 - mmdet - INFO - Epoch [3][1800/4665]	lr: 5.000e-03, eta: 0:36:42, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1346, acc: 96.0629, loss_bbox: 0.1005, loss: 0.2352, grad_norm: 3.5249
2025-08-06 00:18:38,475 - mmdet - INFO - Epoch [3][1850/4665]	lr: 5.000e-03, eta: 0:36:27, time: 0.282, data_time: 0.006, memory: 12134, loss_cls: 0.1403, acc: 95.1775, loss_bbox: 0.1018, loss: 0.2422, grad_norm: 3.6222
2025-08-06 00:18:53,158 - mmdet - INFO - Epoch [3][1900/4665]	lr: 5.000e-03, eta: 0:36:13, time: 0.294, data_time: 0.005, memory: 12134, loss_cls: 0.1391, acc: 96.0399, loss_bbox: 0.0961, loss: 0.2352, grad_norm: 3.3023
2025-08-06 00:19:07,755 - mmdet - INFO - Epoch [3][1950/4665]	lr: 5.000e-03, eta: 0:35:58, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1335, acc: 96.0717, loss_bbox: 0.1029, loss: 0.2364, grad_norm: 3.3001
2025-08-06 00:19:22,039 - mmdet - INFO - Epoch [3][2000/4665]	lr: 5.000e-03, eta: 0:35:43, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1291, acc: 95.4295, loss_bbox: 0.0956, loss: 0.2247, grad_norm: 3.4192
2025-08-06 00:19:36,665 - mmdet - INFO - Epoch [3][2050/4665]	lr: 5.000e-03, eta: 0:35:29, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1234, acc: 96.3322, loss_bbox: 0.0934, loss: 0.2168, grad_norm: 2.9711
2025-08-06 00:19:51,301 - mmdet - INFO - Epoch [3][2100/4665]	lr: 5.000e-03, eta: 0:35:14, time: 0.293, data_time: 0.005, memory: 12134, loss_cls: 0.1160, acc: 96.5453, loss_bbox: 0.0903, loss: 0.2063, grad_norm: 3.0282
2025-08-06 00:20:05,735 - mmdet - INFO - Epoch [3][2150/4665]	lr: 5.000e-03, eta: 0:34:59, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1281, acc: 96.3785, loss_bbox: 0.1029, loss: 0.2310, grad_norm: 3.1684
2025-08-06 00:20:20,178 - mmdet - INFO - Epoch [3][2200/4665]	lr: 5.000e-03, eta: 0:34:44, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1208, acc: 96.7481, loss_bbox: 0.0903, loss: 0.2111, grad_norm: 3.2087
2025-08-06 00:20:34,740 - mmdet - INFO - Epoch [3][2250/4665]	lr: 5.000e-03, eta: 0:34:30, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1223, acc: 96.3863, loss_bbox: 0.0934, loss: 0.2157, grad_norm: 3.1267
2025-08-06 00:20:49,494 - mmdet - INFO - Epoch [3][2300/4665]	lr: 5.000e-03, eta: 0:34:15, time: 0.295, data_time: 0.006, memory: 12134, loss_cls: 0.1337, acc: 96.3261, loss_bbox: 0.0974, loss: 0.2310, grad_norm: 3.1727
2025-08-06 00:21:03,925 - mmdet - INFO - Epoch [3][2350/4665]	lr: 5.000e-03, eta: 0:34:01, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1381, acc: 95.6777, loss_bbox: 0.1116, loss: 0.2497, grad_norm: 3.2912
2025-08-06 00:21:18,719 - mmdet - INFO - Epoch [3][2400/4665]	lr: 5.000e-03, eta: 0:33:46, time: 0.296, data_time: 0.006, memory: 12134, loss_cls: 0.1335, acc: 95.9865, loss_bbox: 0.1046, loss: 0.2381, grad_norm: 3.4349
2025-08-06 00:21:33,367 - mmdet - INFO - Epoch [3][2450/4665]	lr: 5.000e-03, eta: 0:33:31, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1262, acc: 96.4223, loss_bbox: 0.0939, loss: 0.2200, grad_norm: 3.0525
2025-08-06 00:21:47,770 - mmdet - INFO - Epoch [3][2500/4665]	lr: 5.000e-03, eta: 0:33:17, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1162, acc: 96.6843, loss_bbox: 0.0910, loss: 0.2072, grad_norm: 3.0930
2025-08-06 00:22:02,279 - mmdet - INFO - Epoch [3][2550/4665]	lr: 5.000e-03, eta: 0:33:02, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1437, acc: 95.7436, loss_bbox: 0.1025, loss: 0.2462, grad_norm: 3.4960
2025-08-06 00:22:16,723 - mmdet - INFO - Epoch [3][2600/4665]	lr: 5.000e-03, eta: 0:32:47, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1260, acc: 96.4035, loss_bbox: 0.1043, loss: 0.2302, grad_norm: 3.1458
2025-08-06 00:22:31,097 - mmdet - INFO - Epoch [3][2650/4665]	lr: 5.000e-03, eta: 0:32:33, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1242, acc: 96.6256, loss_bbox: 0.0959, loss: 0.2202, grad_norm: 3.3947
2025-08-06 00:22:45,653 - mmdet - INFO - Epoch [3][2700/4665]	lr: 5.000e-03, eta: 0:32:18, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1245, acc: 96.3381, loss_bbox: 0.0941, loss: 0.2186, grad_norm: 3.1773
2025-08-06 00:22:59,819 - mmdet - INFO - Epoch [3][2750/4665]	lr: 5.000e-03, eta: 0:32:03, time: 0.283, data_time: 0.006, memory: 12134, loss_cls: 0.1171, acc: 96.6661, loss_bbox: 0.0903, loss: 0.2074, grad_norm: 2.9732
2025-08-06 00:23:14,171 - mmdet - INFO - Epoch [3][2800/4665]	lr: 5.000e-03, eta: 0:31:48, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1167, acc: 96.5319, loss_bbox: 0.0917, loss: 0.2084, grad_norm: 3.0273
2025-08-06 00:23:28,156 - mmdet - INFO - Epoch [3][2850/4665]	lr: 5.000e-03, eta: 0:31:33, time: 0.280, data_time: 0.006, memory: 12134, loss_cls: 0.1097, acc: 96.9097, loss_bbox: 0.0926, loss: 0.2023, grad_norm: 3.0288
2025-08-06 00:23:42,537 - mmdet - INFO - Epoch [3][2900/4665]	lr: 5.000e-03, eta: 0:31:19, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1228, acc: 96.6385, loss_bbox: 0.0928, loss: 0.2156, grad_norm: 3.2882
2025-08-06 00:23:57,110 - mmdet - INFO - Epoch [3][2950/4665]	lr: 5.000e-03, eta: 0:31:04, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1108, acc: 96.5975, loss_bbox: 0.0927, loss: 0.2035, grad_norm: 2.8095
2025-08-06 00:24:11,651 - mmdet - INFO - Epoch [3][3000/4665]	lr: 5.000e-03, eta: 0:30:49, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1149, acc: 95.7676, loss_bbox: 0.0848, loss: 0.1996, grad_norm: 3.0904
2025-08-06 00:24:26,182 - mmdet - INFO - Epoch [3][3050/4665]	lr: 5.000e-03, eta: 0:30:35, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1404, acc: 95.2465, loss_bbox: 0.0973, loss: 0.2376, grad_norm: 3.3491
2025-08-06 00:24:40,691 - mmdet - INFO - Epoch [3][3100/4665]	lr: 5.000e-03, eta: 0:30:20, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1330, acc: 96.2074, loss_bbox: 0.0951, loss: 0.2281, grad_norm: 3.1966
2025-08-06 00:24:55,344 - mmdet - INFO - Epoch [3][3150/4665]	lr: 5.000e-03, eta: 0:30:05, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1280, acc: 96.3765, loss_bbox: 0.0927, loss: 0.2207, grad_norm: 3.3331
2025-08-06 00:25:09,672 - mmdet - INFO - Epoch [3][3200/4665]	lr: 5.000e-03, eta: 0:29:51, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1444, acc: 96.1653, loss_bbox: 0.1007, loss: 0.2451, grad_norm: 3.5563
2025-08-06 00:25:24,187 - mmdet - INFO - Epoch [3][3250/4665]	lr: 5.000e-03, eta: 0:29:36, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1235, acc: 96.5969, loss_bbox: 0.0915, loss: 0.2150, grad_norm: 3.1723
2025-08-06 00:25:38,808 - mmdet - INFO - Epoch [3][3300/4665]	lr: 5.000e-03, eta: 0:29:21, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1191, acc: 96.3936, loss_bbox: 0.0918, loss: 0.2109, grad_norm: 2.9996
2025-08-06 00:25:53,476 - mmdet - INFO - Epoch [3][3350/4665]	lr: 5.000e-03, eta: 0:29:07, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1283, acc: 96.3258, loss_bbox: 0.0972, loss: 0.2255, grad_norm: 3.0533
2025-08-06 00:26:07,672 - mmdet - INFO - Epoch [3][3400/4665]	lr: 5.000e-03, eta: 0:28:52, time: 0.284, data_time: 0.006, memory: 12134, loss_cls: 0.1238, acc: 96.4502, loss_bbox: 0.0966, loss: 0.2204, grad_norm: 3.1346
2025-08-06 00:26:22,213 - mmdet - INFO - Epoch [3][3450/4665]	lr: 5.000e-03, eta: 0:28:37, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1223, acc: 96.4706, loss_bbox: 0.0944, loss: 0.2167, grad_norm: 3.1046
2025-08-06 00:26:37,129 - mmdet - INFO - Epoch [3][3500/4665]	lr: 5.000e-03, eta: 0:28:23, time: 0.298, data_time: 0.006, memory: 12134, loss_cls: 0.1397, acc: 95.7844, loss_bbox: 0.1011, loss: 0.2408, grad_norm: 3.2899
2025-08-06 00:26:51,625 - mmdet - INFO - Epoch [3][3550/4665]	lr: 5.000e-03, eta: 0:28:08, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1309, acc: 96.2974, loss_bbox: 0.0969, loss: 0.2279, grad_norm: 3.2606
2025-08-06 00:27:06,379 - mmdet - INFO - Epoch [3][3600/4665]	lr: 5.000e-03, eta: 0:27:54, time: 0.295, data_time: 0.005, memory: 12134, loss_cls: 0.1256, acc: 96.2769, loss_bbox: 0.0962, loss: 0.2218, grad_norm: 3.0759
2025-08-06 00:27:20,905 - mmdet - INFO - Epoch [3][3650/4665]	lr: 5.000e-03, eta: 0:27:39, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1377, acc: 96.0479, loss_bbox: 0.1045, loss: 0.2423, grad_norm: 3.2659
2025-08-06 00:27:35,326 - mmdet - INFO - Epoch [3][3700/4665]	lr: 5.000e-03, eta: 0:27:24, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1137, acc: 96.7751, loss_bbox: 0.0899, loss: 0.2037, grad_norm: 3.0767
2025-08-06 00:27:49,706 - mmdet - INFO - Epoch [3][3750/4665]	lr: 5.000e-03, eta: 0:27:10, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1300, acc: 96.3382, loss_bbox: 0.1001, loss: 0.2301, grad_norm: 3.3999
2025-08-06 00:28:04,118 - mmdet - INFO - Epoch [3][3800/4665]	lr: 5.000e-03, eta: 0:26:55, time: 0.288, data_time: 0.005, memory: 12134, loss_cls: 0.1303, acc: 96.1503, loss_bbox: 0.0961, loss: 0.2264, grad_norm: 3.1166
2025-08-06 00:28:18,546 - mmdet - INFO - Epoch [3][3850/4665]	lr: 5.000e-03, eta: 0:26:40, time: 0.289, data_time: 0.005, memory: 12134, loss_cls: 0.1220, acc: 96.6236, loss_bbox: 0.0880, loss: 0.2100, grad_norm: 3.2627
2025-08-06 00:28:32,826 - mmdet - INFO - Epoch [3][3900/4665]	lr: 5.000e-03, eta: 0:26:26, time: 0.286, data_time: 0.005, memory: 12134, loss_cls: 0.1403, acc: 96.1765, loss_bbox: 0.1050, loss: 0.2453, grad_norm: 3.4619
2025-08-06 00:28:46,875 - mmdet - INFO - Epoch [3][3950/4665]	lr: 5.000e-03, eta: 0:26:11, time: 0.281, data_time: 0.005, memory: 12134, loss_cls: 0.1199, acc: 95.6520, loss_bbox: 0.0963, loss: 0.2162, grad_norm: 3.0713
2025-08-06 00:29:01,343 - mmdet - INFO - Epoch [3][4000/4665]	lr: 5.000e-03, eta: 0:25:56, time: 0.289, data_time: 0.005, memory: 12134, loss_cls: 0.1249, acc: 96.6601, loss_bbox: 0.0849, loss: 0.2098, grad_norm: 3.0939
2025-08-06 00:29:15,746 - mmdet - INFO - Epoch [3][4050/4665]	lr: 5.000e-03, eta: 0:25:41, time: 0.288, data_time: 0.005, memory: 12134, loss_cls: 0.1085, acc: 96.7584, loss_bbox: 0.0882, loss: 0.1966, grad_norm: 2.8007
2025-08-06 00:29:30,259 - mmdet - INFO - Epoch [3][4100/4665]	lr: 5.000e-03, eta: 0:25:27, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1157, acc: 96.7292, loss_bbox: 0.0879, loss: 0.2036, grad_norm: 2.8039
2025-08-06 00:29:44,941 - mmdet - INFO - Epoch [3][4150/4665]	lr: 5.000e-03, eta: 0:25:12, time: 0.294, data_time: 0.005, memory: 12134, loss_cls: 0.1276, acc: 96.2688, loss_bbox: 0.1010, loss: 0.2286, grad_norm: 3.1644
2025-08-06 00:29:59,551 - mmdet - INFO - Epoch [3][4200/4665]	lr: 5.000e-03, eta: 0:24:58, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1189, acc: 95.5377, loss_bbox: 0.0922, loss: 0.2111, grad_norm: 3.1910
2025-08-06 00:30:14,381 - mmdet - INFO - Epoch [3][4250/4665]	lr: 5.000e-03, eta: 0:24:43, time: 0.297, data_time: 0.006, memory: 12134, loss_cls: 0.1385, acc: 95.9309, loss_bbox: 0.1023, loss: 0.2408, grad_norm: 3.9016
2025-08-06 00:30:29,110 - mmdet - INFO - Epoch [3][4300/4665]	lr: 5.000e-03, eta: 0:24:28, time: 0.295, data_time: 0.006, memory: 12134, loss_cls: 0.1405, acc: 95.8919, loss_bbox: 0.1172, loss: 0.2577, grad_norm: 3.3932
2025-08-06 00:30:43,846 - mmdet - INFO - Epoch [3][4350/4665]	lr: 5.000e-03, eta: 0:24:14, time: 0.295, data_time: 0.006, memory: 12134, loss_cls: 0.1314, acc: 96.2139, loss_bbox: 0.1028, loss: 0.2341, grad_norm: 3.2828
2025-08-06 00:30:58,113 - mmdet - INFO - Epoch [3][4400/4665]	lr: 5.000e-03, eta: 0:23:59, time: 0.285, data_time: 0.006, memory: 12134, loss_cls: 0.1153, acc: 95.8217, loss_bbox: 0.0916, loss: 0.2068, grad_norm: 3.1290
2025-08-06 00:31:12,630 - mmdet - INFO - Epoch [3][4450/4665]	lr: 5.000e-03, eta: 0:23:45, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1397, acc: 96.0798, loss_bbox: 0.0973, loss: 0.2370, grad_norm: 3.4159
2025-08-06 00:31:27,201 - mmdet - INFO - Epoch [3][4500/4665]	lr: 5.000e-03, eta: 0:23:30, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1365, acc: 96.1527, loss_bbox: 0.1004, loss: 0.2369, grad_norm: 3.2677
2025-08-06 00:31:41,479 - mmdet - INFO - Epoch [3][4550/4665]	lr: 5.000e-03, eta: 0:23:15, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1320, acc: 96.4158, loss_bbox: 0.0911, loss: 0.2231, grad_norm: 3.1582
2025-08-06 00:31:55,857 - mmdet - INFO - Epoch [3][4600/4665]	lr: 5.000e-03, eta: 0:23:01, time: 0.288, data_time: 0.005, memory: 12134, loss_cls: 0.1268, acc: 95.4196, loss_bbox: 0.0932, loss: 0.2199, grad_norm: 2.9776
2025-08-06 00:32:10,110 - mmdet - INFO - Epoch [3][4650/4665]	lr: 5.000e-03, eta: 0:22:46, time: 0.285, data_time: 0.005, memory: 12134, loss_cls: 0.1313, acc: 96.1617, loss_bbox: 0.1035, loss: 0.2348, grad_norm: 3.0365
2025-08-06 00:32:46,227 - mmdet - INFO - Epoch [4][50/4665]	lr: 5.000e-04, eta: 0:22:31, time: 0.619, data_time: 0.329, memory: 12134, loss_cls: 0.1063, acc: 96.5014, loss_bbox: 0.0893, loss: 0.1956, grad_norm: 2.5830
2025-08-06 00:33:00,545 - mmdet - INFO - Epoch [4][100/4665]	lr: 5.000e-04, eta: 0:22:16, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1170, acc: 96.4259, loss_bbox: 0.0970, loss: 0.2140, grad_norm: 2.8537
2025-08-06 00:33:15,296 - mmdet - INFO - Epoch [4][150/4665]	lr: 5.000e-04, eta: 0:22:01, time: 0.295, data_time: 0.005, memory: 12134, loss_cls: 0.1252, acc: 96.1749, loss_bbox: 0.0964, loss: 0.2216, grad_norm: 2.7764
2025-08-06 00:33:30,088 - mmdet - INFO - Epoch [4][200/4665]	lr: 5.000e-04, eta: 0:21:47, time: 0.296, data_time: 0.005, memory: 12134, loss_cls: 0.1341, acc: 96.2944, loss_bbox: 0.0945, loss: 0.2286, grad_norm: 2.8702
2025-08-06 00:33:44,436 - mmdet - INFO - Epoch [4][250/4665]	lr: 5.000e-04, eta: 0:21:32, time: 0.287, data_time: 0.005, memory: 12134, loss_cls: 0.1213, acc: 96.3496, loss_bbox: 0.0979, loss: 0.2192, grad_norm: 2.8036
2025-08-06 00:33:58,964 - mmdet - INFO - Epoch [4][300/4665]	lr: 5.000e-04, eta: 0:21:17, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.0980, acc: 96.9931, loss_bbox: 0.0810, loss: 0.1790, grad_norm: 2.3252
2025-08-06 00:34:13,135 - mmdet - INFO - Epoch [4][350/4665]	lr: 5.000e-04, eta: 0:21:03, time: 0.283, data_time: 0.005, memory: 12134, loss_cls: 0.1242, acc: 96.4177, loss_bbox: 0.0978, loss: 0.2220, grad_norm: 2.7811
2025-08-06 00:34:27,491 - mmdet - INFO - Epoch [4][400/4665]	lr: 5.000e-04, eta: 0:20:48, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1206, acc: 96.2037, loss_bbox: 0.1008, loss: 0.2214, grad_norm: 2.8140
2025-08-06 00:34:41,768 - mmdet - INFO - Epoch [4][450/4665]	lr: 5.000e-04, eta: 0:20:33, time: 0.286, data_time: 0.005, memory: 12134, loss_cls: 0.1188, acc: 95.5849, loss_bbox: 0.0920, loss: 0.2108, grad_norm: 2.7166
2025-08-06 00:34:56,266 - mmdet - INFO - Epoch [4][500/4665]	lr: 5.000e-04, eta: 0:20:19, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1210, acc: 96.2825, loss_bbox: 0.1009, loss: 0.2219, grad_norm: 2.8482
2025-08-06 00:35:10,664 - mmdet - INFO - Epoch [4][550/4665]	lr: 5.000e-04, eta: 0:20:04, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1175, acc: 96.4810, loss_bbox: 0.0886, loss: 0.2061, grad_norm: 2.7388
2025-08-06 00:35:24,808 - mmdet - INFO - Epoch [4][600/4665]	lr: 5.000e-04, eta: 0:19:49, time: 0.283, data_time: 0.005, memory: 12134, loss_cls: 0.1118, acc: 96.5177, loss_bbox: 0.1039, loss: 0.2157, grad_norm: 2.7491
2025-08-06 00:35:39,593 - mmdet - INFO - Epoch [4][650/4665]	lr: 5.000e-04, eta: 0:19:34, time: 0.296, data_time: 0.006, memory: 12134, loss_cls: 0.1198, acc: 96.3429, loss_bbox: 0.0995, loss: 0.2193, grad_norm: 2.8568
2025-08-06 00:35:53,862 - mmdet - INFO - Epoch [4][700/4665]	lr: 5.000e-04, eta: 0:19:20, time: 0.285, data_time: 0.006, memory: 12134, loss_cls: 0.1143, acc: 96.5185, loss_bbox: 0.0971, loss: 0.2114, grad_norm: 2.7329
2025-08-06 00:36:08,417 - mmdet - INFO - Epoch [4][750/4665]	lr: 5.000e-04, eta: 0:19:05, time: 0.291, data_time: 0.005, memory: 12134, loss_cls: 0.0916, acc: 97.0917, loss_bbox: 0.0816, loss: 0.1732, grad_norm: 2.5241
2025-08-06 00:36:23,094 - mmdet - INFO - Epoch [4][800/4665]	lr: 5.000e-04, eta: 0:18:50, time: 0.294, data_time: 0.006, memory: 12134, loss_cls: 0.1238, acc: 96.2900, loss_bbox: 0.1007, loss: 0.2245, grad_norm: 2.8570
2025-08-06 00:36:37,601 - mmdet - INFO - Epoch [4][850/4665]	lr: 5.000e-04, eta: 0:18:36, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1118, acc: 95.7677, loss_bbox: 0.0896, loss: 0.2014, grad_norm: 2.7551
2025-08-06 00:36:51,951 - mmdet - INFO - Epoch [4][900/4665]	lr: 5.000e-04, eta: 0:18:21, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1136, acc: 96.8579, loss_bbox: 0.0920, loss: 0.2056, grad_norm: 2.6339
2025-08-06 00:37:06,138 - mmdet - INFO - Epoch [4][950/4665]	lr: 5.000e-04, eta: 0:18:06, time: 0.284, data_time: 0.006, memory: 12134, loss_cls: 0.1070, acc: 96.8297, loss_bbox: 0.0839, loss: 0.1908, grad_norm: 2.6376
2025-08-06 00:37:20,807 - mmdet - INFO - Epoch [4][1000/4665]	lr: 5.000e-04, eta: 0:17:52, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1272, acc: 96.1343, loss_bbox: 0.1042, loss: 0.2314, grad_norm: 2.8334
2025-08-06 00:37:35,213 - mmdet - INFO - Epoch [4][1050/4665]	lr: 5.000e-04, eta: 0:17:37, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1206, acc: 96.4181, loss_bbox: 0.0984, loss: 0.2190, grad_norm: 2.9486
2025-08-06 00:37:49,599 - mmdet - INFO - Epoch [4][1100/4665]	lr: 5.000e-04, eta: 0:17:22, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1144, acc: 96.6083, loss_bbox: 0.0953, loss: 0.2097, grad_norm: 2.6970
2025-08-06 00:38:03,991 - mmdet - INFO - Epoch [4][1150/4665]	lr: 5.000e-04, eta: 0:17:08, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1085, acc: 96.8279, loss_bbox: 0.0898, loss: 0.1983, grad_norm: 2.7401
2025-08-06 00:38:18,563 - mmdet - INFO - Epoch [4][1200/4665]	lr: 5.000e-04, eta: 0:16:53, time: 0.291, data_time: 0.005, memory: 12134, loss_cls: 0.1159, acc: 96.5087, loss_bbox: 0.0989, loss: 0.2148, grad_norm: 2.7500
2025-08-06 00:38:33,084 - mmdet - INFO - Epoch [4][1250/4665]	lr: 5.000e-04, eta: 0:16:38, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1242, acc: 96.1734, loss_bbox: 0.0979, loss: 0.2221, grad_norm: 2.9974
2025-08-06 00:38:47,736 - mmdet - INFO - Epoch [4][1300/4665]	lr: 5.000e-04, eta: 0:16:24, time: 0.293, data_time: 0.005, memory: 12134, loss_cls: 0.1174, acc: 96.4802, loss_bbox: 0.0961, loss: 0.2134, grad_norm: 2.8182
2025-08-06 00:39:02,351 - mmdet - INFO - Epoch [4][1350/4665]	lr: 5.000e-04, eta: 0:16:09, time: 0.292, data_time: 0.005, memory: 12134, loss_cls: 0.1158, acc: 96.5147, loss_bbox: 0.0850, loss: 0.2007, grad_norm: 2.7797
2025-08-06 00:39:16,992 - mmdet - INFO - Epoch [4][1400/4665]	lr: 5.000e-04, eta: 0:15:55, time: 0.293, data_time: 0.005, memory: 12134, loss_cls: 0.1065, acc: 96.7338, loss_bbox: 0.0842, loss: 0.1907, grad_norm: 2.6341
2025-08-06 00:39:31,208 - mmdet - INFO - Epoch [4][1450/4665]	lr: 5.000e-04, eta: 0:15:40, time: 0.284, data_time: 0.005, memory: 12134, loss_cls: 0.1144, acc: 96.8833, loss_bbox: 0.0897, loss: 0.2041, grad_norm: 2.8368
2025-08-06 00:39:45,557 - mmdet - INFO - Epoch [4][1500/4665]	lr: 5.000e-04, eta: 0:15:25, time: 0.287, data_time: 0.005, memory: 12134, loss_cls: 0.1223, acc: 96.2352, loss_bbox: 0.1024, loss: 0.2247, grad_norm: 2.9053
2025-08-06 00:40:00,197 - mmdet - INFO - Epoch [4][1550/4665]	lr: 5.000e-04, eta: 0:15:11, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1031, acc: 96.8056, loss_bbox: 0.0901, loss: 0.1932, grad_norm: 2.5729
2025-08-06 00:40:14,246 - mmdet - INFO - Epoch [4][1600/4665]	lr: 5.000e-04, eta: 0:14:56, time: 0.281, data_time: 0.005, memory: 12134, loss_cls: 0.1117, acc: 95.6169, loss_bbox: 0.1049, loss: 0.2167, grad_norm: 2.9462
2025-08-06 00:40:28,828 - mmdet - INFO - Epoch [4][1650/4665]	lr: 5.000e-04, eta: 0:14:41, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1037, acc: 95.8104, loss_bbox: 0.0910, loss: 0.1947, grad_norm: 2.6666
2025-08-06 00:40:43,107 - mmdet - INFO - Epoch [4][1700/4665]	lr: 5.000e-04, eta: 0:14:26, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1071, acc: 96.6386, loss_bbox: 0.0849, loss: 0.1920, grad_norm: 2.8108
2025-08-06 00:40:57,396 - mmdet - INFO - Epoch [4][1750/4665]	lr: 5.000e-04, eta: 0:14:12, time: 0.286, data_time: 0.005, memory: 12134, loss_cls: 0.1111, acc: 96.6313, loss_bbox: 0.0939, loss: 0.2050, grad_norm: 2.6952
2025-08-06 00:41:12,020 - mmdet - INFO - Epoch [4][1800/4665]	lr: 5.000e-04, eta: 0:13:57, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.0926, acc: 97.1100, loss_bbox: 0.0787, loss: 0.1713, grad_norm: 2.5039
2025-08-06 00:41:26,387 - mmdet - INFO - Epoch [4][1850/4665]	lr: 5.000e-04, eta: 0:13:43, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1195, acc: 96.8011, loss_bbox: 0.0932, loss: 0.2127, grad_norm: 2.7657
2025-08-06 00:41:40,817 - mmdet - INFO - Epoch [4][1900/4665]	lr: 5.000e-04, eta: 0:13:28, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1017, acc: 97.1108, loss_bbox: 0.0844, loss: 0.1860, grad_norm: 2.6205
2025-08-06 00:41:55,150 - mmdet - INFO - Epoch [4][1950/4665]	lr: 5.000e-04, eta: 0:13:13, time: 0.287, data_time: 0.005, memory: 12134, loss_cls: 0.1068, acc: 96.9670, loss_bbox: 0.0858, loss: 0.1926, grad_norm: 2.6948
2025-08-06 00:42:09,568 - mmdet - INFO - Epoch [4][2000/4665]	lr: 5.000e-04, eta: 0:12:59, time: 0.288, data_time: 0.005, memory: 12134, loss_cls: 0.1118, acc: 96.6106, loss_bbox: 0.0963, loss: 0.2082, grad_norm: 2.7743
2025-08-06 00:42:23,921 - mmdet - INFO - Epoch [4][2050/4665]	lr: 5.000e-04, eta: 0:12:44, time: 0.287, data_time: 0.005, memory: 12134, loss_cls: 0.1142, acc: 96.4472, loss_bbox: 0.0962, loss: 0.2104, grad_norm: 2.7932
2025-08-06 00:42:38,107 - mmdet - INFO - Epoch [4][2100/4665]	lr: 5.000e-04, eta: 0:12:29, time: 0.284, data_time: 0.006, memory: 12134, loss_cls: 0.1245, acc: 95.9473, loss_bbox: 0.1076, loss: 0.2321, grad_norm: 3.0904
2025-08-06 00:42:52,319 - mmdet - INFO - Epoch [4][2150/4665]	lr: 5.000e-04, eta: 0:12:15, time: 0.284, data_time: 0.006, memory: 12134, loss_cls: 0.1048, acc: 96.7336, loss_bbox: 0.0903, loss: 0.1951, grad_norm: 2.6290
2025-08-06 00:43:06,584 - mmdet - INFO - Epoch [4][2200/4665]	lr: 5.000e-04, eta: 0:12:00, time: 0.285, data_time: 0.005, memory: 12134, loss_cls: 0.1080, acc: 96.8224, loss_bbox: 0.0882, loss: 0.1962, grad_norm: 2.7369
2025-08-06 00:43:21,052 - mmdet - INFO - Epoch [4][2250/4665]	lr: 5.000e-04, eta: 0:11:45, time: 0.289, data_time: 0.005, memory: 12134, loss_cls: 0.1214, acc: 96.5655, loss_bbox: 0.0916, loss: 0.2130, grad_norm: 2.8836
2025-08-06 00:43:35,450 - mmdet - INFO - Epoch [4][2300/4665]	lr: 5.000e-04, eta: 0:11:31, time: 0.288, data_time: 0.006, memory: 12134, loss_cls: 0.1144, acc: 96.6831, loss_bbox: 0.0936, loss: 0.2080, grad_norm: 2.7981
2025-08-06 00:43:49,921 - mmdet - INFO - Epoch [4][2350/4665]	lr: 5.000e-04, eta: 0:11:16, time: 0.289, data_time: 0.005, memory: 12134, loss_cls: 0.1349, acc: 95.9479, loss_bbox: 0.1137, loss: 0.2486, grad_norm: 3.1508
2025-08-06 00:44:04,328 - mmdet - INFO - Epoch [4][2400/4665]	lr: 5.000e-04, eta: 0:11:01, time: 0.288, data_time: 0.005, memory: 12134, loss_cls: 0.1135, acc: 96.5547, loss_bbox: 0.0982, loss: 0.2117, grad_norm: 2.7310
2025-08-06 00:44:18,858 - mmdet - INFO - Epoch [4][2450/4665]	lr: 5.000e-04, eta: 0:10:47, time: 0.291, data_time: 0.005, memory: 12134, loss_cls: 0.1102, acc: 96.4553, loss_bbox: 0.0902, loss: 0.2004, grad_norm: 2.7747
2025-08-06 00:44:33,144 - mmdet - INFO - Epoch [4][2500/4665]	lr: 5.000e-04, eta: 0:10:32, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1196, acc: 96.5492, loss_bbox: 0.0996, loss: 0.2191, grad_norm: 2.9071
2025-08-06 00:44:48,041 - mmdet - INFO - Epoch [4][2550/4665]	lr: 5.000e-04, eta: 0:10:17, time: 0.298, data_time: 0.006, memory: 12134, loss_cls: 0.1115, acc: 96.5615, loss_bbox: 0.0951, loss: 0.2066, grad_norm: 2.6423
2025-08-06 00:45:02,626 - mmdet - INFO - Epoch [4][2600/4665]	lr: 5.000e-04, eta: 0:10:03, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.0919, acc: 97.2109, loss_bbox: 0.0789, loss: 0.1707, grad_norm: 2.3830
2025-08-06 00:45:17,314 - mmdet - INFO - Epoch [4][2650/4665]	lr: 5.000e-04, eta: 0:09:48, time: 0.294, data_time: 0.006, memory: 12134, loss_cls: 0.1280, acc: 96.1159, loss_bbox: 0.0995, loss: 0.2275, grad_norm: 3.0762
2025-08-06 00:45:31,765 - mmdet - INFO - Epoch [4][2700/4665]	lr: 5.000e-04, eta: 0:09:34, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1265, acc: 96.3195, loss_bbox: 0.1054, loss: 0.2319, grad_norm: 2.9152
2025-08-06 00:45:46,340 - mmdet - INFO - Epoch [4][2750/4665]	lr: 5.000e-04, eta: 0:09:19, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1345, acc: 96.0859, loss_bbox: 0.1086, loss: 0.2432, grad_norm: 3.0901
2025-08-06 00:46:00,929 - mmdet - INFO - Epoch [4][2800/4665]	lr: 5.000e-04, eta: 0:09:04, time: 0.292, data_time: 0.005, memory: 12134, loss_cls: 0.1127, acc: 96.5526, loss_bbox: 0.0904, loss: 0.2031, grad_norm: 2.7314
2025-08-06 00:46:15,672 - mmdet - INFO - Epoch [4][2850/4665]	lr: 5.000e-04, eta: 0:08:50, time: 0.295, data_time: 0.006, memory: 12134, loss_cls: 0.1110, acc: 96.5281, loss_bbox: 0.0971, loss: 0.2081, grad_norm: 2.7300
2025-08-06 00:46:30,289 - mmdet - INFO - Epoch [4][2900/4665]	lr: 5.000e-04, eta: 0:08:35, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1172, acc: 96.4962, loss_bbox: 0.1003, loss: 0.2175, grad_norm: 2.7793
2025-08-06 00:46:44,376 - mmdet - INFO - Epoch [4][2950/4665]	lr: 5.000e-04, eta: 0:08:21, time: 0.282, data_time: 0.006, memory: 12134, loss_cls: 0.1204, acc: 94.5581, loss_bbox: 0.0991, loss: 0.2195, grad_norm: 3.2207
2025-08-06 00:46:58,632 - mmdet - INFO - Epoch [4][3000/4665]	lr: 5.000e-04, eta: 0:08:06, time: 0.285, data_time: 0.006, memory: 12134, loss_cls: 0.1118, acc: 96.7422, loss_bbox: 0.0918, loss: 0.2036, grad_norm: 2.7698
2025-08-06 00:47:13,171 - mmdet - INFO - Epoch [4][3050/4665]	lr: 5.000e-04, eta: 0:07:51, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1126, acc: 96.6923, loss_bbox: 0.0880, loss: 0.2005, grad_norm: 2.7898
2025-08-06 00:47:27,631 - mmdet - INFO - Epoch [4][3100/4665]	lr: 5.000e-04, eta: 0:07:37, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1131, acc: 96.7578, loss_bbox: 0.0957, loss: 0.2088, grad_norm: 2.8063
2025-08-06 00:47:42,373 - mmdet - INFO - Epoch [4][3150/4665]	lr: 5.000e-04, eta: 0:07:22, time: 0.295, data_time: 0.006, memory: 12134, loss_cls: 0.1264, acc: 96.4053, loss_bbox: 0.0969, loss: 0.2233, grad_norm: 3.1197
2025-08-06 00:47:56,650 - mmdet - INFO - Epoch [4][3200/4665]	lr: 5.000e-04, eta: 0:07:07, time: 0.286, data_time: 0.005, memory: 12134, loss_cls: 0.1121, acc: 96.5845, loss_bbox: 0.0945, loss: 0.2066, grad_norm: 2.7431
2025-08-06 00:48:11,164 - mmdet - INFO - Epoch [4][3250/4665]	lr: 5.000e-04, eta: 0:06:53, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1153, acc: 96.6003, loss_bbox: 0.0945, loss: 0.2098, grad_norm: 2.7425
2025-08-06 00:48:25,651 - mmdet - INFO - Epoch [4][3300/4665]	lr: 5.000e-04, eta: 0:06:38, time: 0.290, data_time: 0.005, memory: 12134, loss_cls: 0.1195, acc: 96.3005, loss_bbox: 0.1060, loss: 0.2255, grad_norm: 2.7716
2025-08-06 00:48:39,657 - mmdet - INFO - Epoch [4][3350/4665]	lr: 5.000e-04, eta: 0:06:24, time: 0.280, data_time: 0.005, memory: 12134, loss_cls: 0.1054, acc: 96.8154, loss_bbox: 0.0840, loss: 0.1894, grad_norm: 3.0096
2025-08-06 00:48:53,889 - mmdet - INFO - Epoch [4][3400/4665]	lr: 5.000e-04, eta: 0:06:09, time: 0.285, data_time: 0.005, memory: 12134, loss_cls: 0.1061, acc: 96.7579, loss_bbox: 0.0954, loss: 0.2015, grad_norm: 2.7066
2025-08-06 00:49:08,808 - mmdet - INFO - Epoch [4][3450/4665]	lr: 5.000e-04, eta: 0:05:54, time: 0.298, data_time: 0.006, memory: 12134, loss_cls: 0.1202, acc: 96.5022, loss_bbox: 0.0929, loss: 0.2131, grad_norm: 2.7221
2025-08-06 00:49:23,492 - mmdet - INFO - Epoch [4][3500/4665]	lr: 5.000e-04, eta: 0:05:40, time: 0.294, data_time: 0.006, memory: 12134, loss_cls: 0.1161, acc: 96.4131, loss_bbox: 0.0951, loss: 0.2112, grad_norm: 2.7363
2025-08-06 00:49:37,964 - mmdet - INFO - Epoch [4][3550/4665]	lr: 5.000e-04, eta: 0:05:25, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1026, acc: 96.8968, loss_bbox: 0.0829, loss: 0.1854, grad_norm: 2.5050
2025-08-06 00:49:52,230 - mmdet - INFO - Epoch [4][3600/4665]	lr: 5.000e-04, eta: 0:05:11, time: 0.285, data_time: 0.006, memory: 12134, loss_cls: 0.0975, acc: 96.9887, loss_bbox: 0.0855, loss: 0.1829, grad_norm: 2.6873
2025-08-06 00:50:06,595 - mmdet - INFO - Epoch [4][3650/4665]	lr: 5.000e-04, eta: 0:04:56, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1213, acc: 96.4670, loss_bbox: 0.0965, loss: 0.2178, grad_norm: 3.0975
2025-08-06 00:50:21,119 - mmdet - INFO - Epoch [4][3700/4665]	lr: 5.000e-04, eta: 0:04:41, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1109, acc: 96.5343, loss_bbox: 0.0941, loss: 0.2051, grad_norm: 2.6867
2025-08-06 00:50:35,688 - mmdet - INFO - Epoch [4][3750/4665]	lr: 5.000e-04, eta: 0:04:27, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1337, acc: 96.0994, loss_bbox: 0.1047, loss: 0.2384, grad_norm: 3.1842
2025-08-06 00:50:50,028 - mmdet - INFO - Epoch [4][3800/4665]	lr: 5.000e-04, eta: 0:04:12, time: 0.287, data_time: 0.006, memory: 12134, loss_cls: 0.1024, acc: 96.9222, loss_bbox: 0.0850, loss: 0.1874, grad_norm: 2.6763
2025-08-06 00:51:04,936 - mmdet - INFO - Epoch [4][3850/4665]	lr: 5.000e-04, eta: 0:03:58, time: 0.298, data_time: 0.006, memory: 12134, loss_cls: 0.1115, acc: 96.5562, loss_bbox: 0.0903, loss: 0.2018, grad_norm: 2.6874
2025-08-06 00:51:19,613 - mmdet - INFO - Epoch [4][3900/4665]	lr: 5.000e-04, eta: 0:03:43, time: 0.294, data_time: 0.006, memory: 12134, loss_cls: 0.1317, acc: 96.0995, loss_bbox: 0.1010, loss: 0.2327, grad_norm: 3.0825
2025-08-06 00:51:34,103 - mmdet - INFO - Epoch [4][3950/4665]	lr: 5.000e-04, eta: 0:03:28, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1274, acc: 95.9232, loss_bbox: 0.1075, loss: 0.2349, grad_norm: 2.9830
2025-08-06 00:51:48,419 - mmdet - INFO - Epoch [4][4000/4665]	lr: 5.000e-04, eta: 0:03:14, time: 0.286, data_time: 0.005, memory: 12134, loss_cls: 0.1101, acc: 96.6851, loss_bbox: 0.0979, loss: 0.2080, grad_norm: 2.7897
2025-08-06 00:52:03,122 - mmdet - INFO - Epoch [4][4050/4665]	lr: 5.000e-04, eta: 0:02:59, time: 0.294, data_time: 0.005, memory: 12134, loss_cls: 0.1005, acc: 96.9773, loss_bbox: 0.0809, loss: 0.1814, grad_norm: 2.4853
2025-08-06 00:52:17,750 - mmdet - INFO - Epoch [4][4100/4665]	lr: 5.000e-04, eta: 0:02:44, time: 0.293, data_time: 0.006, memory: 12134, loss_cls: 0.1123, acc: 96.7255, loss_bbox: 0.0911, loss: 0.2034, grad_norm: 2.8446
2025-08-06 00:52:32,041 - mmdet - INFO - Epoch [4][4150/4665]	lr: 5.000e-04, eta: 0:02:30, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1053, acc: 96.8136, loss_bbox: 0.0967, loss: 0.2020, grad_norm: 2.7880
2025-08-06 00:52:46,776 - mmdet - INFO - Epoch [4][4200/4665]	lr: 5.000e-04, eta: 0:02:15, time: 0.295, data_time: 0.005, memory: 12134, loss_cls: 0.1228, acc: 96.3329, loss_bbox: 0.0950, loss: 0.2178, grad_norm: 2.9396
2025-08-06 00:53:01,339 - mmdet - INFO - Epoch [4][4250/4665]	lr: 5.000e-04, eta: 0:02:01, time: 0.291, data_time: 0.006, memory: 12134, loss_cls: 0.1138, acc: 95.6868, loss_bbox: 0.0851, loss: 0.1989, grad_norm: 2.7848
2025-08-06 00:53:15,962 - mmdet - INFO - Epoch [4][4300/4665]	lr: 5.000e-04, eta: 0:01:46, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.1017, acc: 96.9989, loss_bbox: 0.0826, loss: 0.1842, grad_norm: 2.6206
2025-08-06 00:53:30,245 - mmdet - INFO - Epoch [4][4350/4665]	lr: 5.000e-04, eta: 0:01:31, time: 0.286, data_time: 0.006, memory: 12134, loss_cls: 0.1067, acc: 96.8846, loss_bbox: 0.0948, loss: 0.2015, grad_norm: 2.8518
2025-08-06 00:53:44,728 - mmdet - INFO - Epoch [4][4400/4665]	lr: 5.000e-04, eta: 0:01:17, time: 0.290, data_time: 0.006, memory: 12134, loss_cls: 0.1162, acc: 96.4212, loss_bbox: 0.0948, loss: 0.2110, grad_norm: 2.7721
2025-08-06 00:53:59,164 - mmdet - INFO - Epoch [4][4450/4665]	lr: 5.000e-04, eta: 0:01:02, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1105, acc: 96.6518, loss_bbox: 0.0967, loss: 0.2072, grad_norm: 2.7803
2025-08-06 00:54:13,599 - mmdet - INFO - Epoch [4][4500/4665]	lr: 5.000e-04, eta: 0:00:48, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1133, acc: 96.3998, loss_bbox: 0.0978, loss: 0.2111, grad_norm: 2.8214
2025-08-06 00:54:28,032 - mmdet - INFO - Epoch [4][4550/4665]	lr: 5.000e-04, eta: 0:00:33, time: 0.289, data_time: 0.006, memory: 12134, loss_cls: 0.1110, acc: 96.7917, loss_bbox: 0.0976, loss: 0.2086, grad_norm: 2.7744
2025-08-06 00:54:42,612 - mmdet - INFO - Epoch [4][4600/4665]	lr: 5.000e-04, eta: 0:00:18, time: 0.292, data_time: 0.006, memory: 12134, loss_cls: 0.0953, acc: 97.2226, loss_bbox: 0.0826, loss: 0.1779, grad_norm: 2.4672
2025-08-06 00:54:57,157 - mmdet - INFO - Epoch [4][4650/4665]	lr: 5.000e-04, eta: 0:00:04, time: 0.291, data_time: 0.005, memory: 12134, loss_cls: 0.0993, acc: 96.9294, loss_bbox: 0.0834, loss: 0.1827, grad_norm: 2.6272
2025-08-06 00:55:02,426 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-08-06 00:56:07,535 - mmdet - INFO - Evaluating bbox...
2025-08-06 00:56:16,968 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage_rpn.py
2025-08-06 00:56:16,968 - mmdet - INFO - Epoch(val) [4][850]	bbox_mAP: 0.1280, bbox_mAP_50: 0.3100, bbox_mAP_75: 0.0790, bbox_mAP_s: 0.0750, bbox_mAP_m: 0.1920, bbox_mAP_l: 0.1820, bbox_mAP_copypaste: 0.128 0.310 0.079 0.075 0.192 0.182
