2025-08-05 14:44:51,456 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 4090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.8.r11.8/compiler.31833905_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.10.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0+cu111
OpenCV: 4.12.0
MMCV: 1.3.17
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.18.0+eb18253
------------------------------------------------------------

2025-08-05 14:44:53,477 - mmdet - INFO - Distributed training: True
2025-08-05 14:44:55,445 - mmdet - INFO - Config:
checkpoint_config = dict(interval=2)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/root/UniDetector/regionclip_pretrained-cc_rn50_mmdet.pth'
resume_from = None
workflow = [('train', 1)]
norm_cfg = dict(type='BN', requires_grad=False)
model = dict(
    type='FastRCNN',
    backbone=dict(type='CLIPResNet', layers=[3, 4, 6, 3], style='pytorch'),
    roi_head=dict(
        type='StandardRoIHead',
        shared_head=dict(type='CLIPResLayer', layers=[3, 4, 6, 3]),
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=1024,
            featmap_strides=[16]),
        bbox_head=dict(
            type='BBoxHeadCLIPPartitioned',
            with_avg_pool=True,
            roi_feat_size=7,
            in_channels=2048,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            with_cls=False,
            reg_class_agnostic=True,
            zeroshot_path=[
                './clip_embeddings/coco_clip_a+cname_rn50_manyprompt.npy',
                './clip_embeddings/objects365_clip_a+cname_rn50_manyprompt.npy'
            ],
            cat_freq_path=[
                None,
                '/root/autodl-tmp/datasets/object365/annotations/object365_cat_freq.json'
            ],
            num_classes=365,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rcnn=dict(
            score_thr=0.0001,
            nms=dict(type='soft_nms', iou_threshold=0.5, method='gaussian'),
            max_per_img=100)))
classes_obj365 = [
    'Person', 'Sneakers', 'Chair', 'Other Shoes', 'Hat', 'Car', 'Lamp',
    'Glasses', 'Bottle', 'Desk', 'Cup', 'Street Lights', 'Cabinet/shelf',
    'Handbag/Satchel', 'Bracelet', 'Plate', 'Picture/Frame', 'Helmet', 'Book',
    'Gloves', 'Storage box', 'Boat', 'Leather Shoes', 'Flower', 'Bench',
    'Potted Plant', 'Bowl/Basin', 'Flag', 'Pillow', 'Boots', 'Vase',
    'Microphone', 'Necklace', 'Ring', 'SUV', 'Wine Glass', 'Belt',
    'Moniter/TV', 'Backpack', 'Umbrella', 'Traffic Light', 'Speaker', 'Watch',
    'Tie', 'Trash bin Can', 'Slippers', 'Bicycle', 'Stool', 'Barrel/bucket',
    'Van', 'Couch', 'Sandals', 'Bakset', 'Drum', 'Pen/Pencil', 'Bus',
    'Wild Bird', 'High Heels', 'Motorcycle', 'Guitar', 'Carpet', 'Cell Phone',
    'Bread', 'Camera', 'Canned', 'Truck', 'Traffic cone', 'Cymbal',
    'Lifesaver', 'Towel', 'Stuffed Toy', 'Candle', 'Sailboat', 'Laptop',
    'Awning', 'Bed', 'Faucet', 'Tent', 'Horse', 'Mirror', 'Power outlet',
    'Sink', 'Apple', 'Air Conditioner', 'Knife', 'Hockey Stick', 'Paddle',
    'Pickup Truck', 'Fork', 'Traffic Sign', 'Ballon', 'Tripod', 'Dog', 'Spoon',
    'Clock', 'Pot', 'Cow', 'Cake', 'Dinning Table', 'Sheep', 'Hanger',
    'Blackboard/Whiteboard', 'Napkin', 'Other Fish', 'Orange/Tangerine',
    'Toiletry', 'Keyboard', 'Tomato', 'Lantern', 'Machinery Vehicle', 'Fan',
    'Green Vegetables', 'Banana', 'Baseball Glove', 'Airplane', 'Mouse',
    'Train', 'Pumpkin', 'Soccer', 'Skiboard', 'Luggage', 'Nightstand',
    'Tea pot', 'Telephone', 'Trolley', 'Head Phone', 'Sports Car', 'Stop Sign',
    'Dessert', 'Scooter', 'Stroller', 'Crane', 'Remote', 'Refrigerator',
    'Oven', 'Lemon', 'Duck', 'Baseball Bat', 'Surveillance Camera', 'Cat',
    'Jug', 'Broccoli', 'Piano', 'Pizza', 'Elephant', 'Skateboard', 'Surfboard',
    'Gun', 'Skating and Skiing shoes', 'Gas stove', 'Donut', 'Bow Tie',
    'Carrot', 'Toilet', 'Kite', 'Strawberry', 'Other Balls', 'Shovel',
    'Pepper', 'Computer Box', 'Toilet Paper', 'Cleaning Products',
    'Chopsticks', 'Microwave', 'Pigeon', 'Baseball', 'Cutting/chopping Board',
    'Coffee Table', 'Side Table', 'Scissors', 'Marker', 'Pie', 'Ladder',
    'Snowboard', 'Cookies', 'Radiator', 'Fire Hydrant', 'Basketball', 'Zebra',
    'Grape', 'Giraffe', 'Potato', 'Sausage', 'Tricycle', 'Violin', 'Egg',
    'Fire Extinguisher', 'Candy', 'Fire Truck', 'Billards', 'Converter',
    'Bathtub', 'Wheelchair', 'Golf Club', 'Briefcase', 'Cucumber',
    'Cigar/Cigarette ', 'Paint Brush', 'Pear', 'Heavy Truck', 'Hamburger',
    'Extractor', 'Extention Cord', 'Tong', 'Tennis Racket', 'Folder',
    'American Football', 'earphone', 'Mask', 'Kettle', 'Tennis', 'Ship',
    'Swing', 'Coffee Machine', 'Slide', 'Carriage', 'Onion', 'Green beans',
    'Projector', 'Frisbee', 'Washing Machine/Drying Machine', 'Chicken',
    'Printer', 'Watermelon', 'Saxophone', 'Tissue', 'Toothbrush', 'Ice cream',
    'Hotair ballon', 'Cello', 'French Fries', 'Scale', 'Trophy', 'Cabbage',
    'Hot dog', 'Blender', 'Peach', 'Rice', 'Wallet/Purse', 'Volleyball',
    'Deer', 'Goose', 'Tape', 'Tablet', 'Cosmetics', 'Trumpet', 'Pineapple',
    'Golf Ball', 'Ambulance', 'Parking meter', 'Mango', 'Key', 'Hurdle',
    'Fishing Rod', 'Medal', 'Flute', 'Brush', 'Penguin', 'Megaphone', 'Corn',
    'Lettuce', 'Garlic', 'Swan', 'Helicopter', 'Green Onion', 'Sandwich',
    'Nuts', 'Speed Limit Sign', 'Induction Cooker', 'Broom', 'Trombone',
    'Plum', 'Rickshaw', 'Goldfish', 'Kiwi fruit', 'Router/modem', 'Poker Card',
    'Toaster', 'Shrimp', 'Sushi', 'Cheese', 'Notepaper', 'Cherry', 'Pliers',
    'CD', 'Pasta', 'Hammer', 'Cue', 'Avocado', 'Hamimelon', 'Flask',
    'Mushroon', 'Screwdriver', 'Soap', 'Recorder', 'Bear', 'Eggplant',
    'Board Eraser', 'Coconut', 'Tape Measur/ Ruler', 'Pig', 'Showerhead',
    'Globe', 'Chips', 'Steak', 'Crosswalk Sign', 'Stapler', 'Campel',
    'Formula 1 ', 'Pomegranate', 'Dishwasher', 'Crab', 'Hoverboard',
    'Meat ball', 'Rice Cooker', 'Tuba', 'Calculator', 'Papaya', 'Antelope',
    'Parrot', 'Seal', 'Buttefly', 'Dumbbell', 'Donkey', 'Lion', 'Urinal',
    'Dolphin', 'Electric Drill', 'Hair Dryer', 'Egg tart', 'Jellyfish',
    'Treadmill', 'Lighter', 'Grapefruit', 'Game board', 'Mop', 'Radish',
    'Baozi', 'Target', 'French', 'Spring Rolls', 'Monkey', 'Rabbit',
    'Pencil Case', 'Yak', 'Red Cabbage', 'Binoculars', 'Asparagus', 'Barbell',
    'Scallop', 'Noddles', 'Comb', 'Dumpling', 'Oyster', 'Table Teniis paddle',
    'Cosmetics Brush/Eyeliner Pencil', 'Chainsaw', 'Eraser', 'Lobster',
    'Durian', 'Okra', 'Lipstick', 'Cosmetics Mirror', 'Curling',
    'Table Tennis '
]
dataset_type = 'CocoDataset'
data_root = '/root/autodl-tmp/datasets/coco/'
img_norm_cfg = dict(
    mean=[122.7709383, 116.7460125, 104.09373615],
    std=[68.5005327, 66.6321579, 70.32316305],
    to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadProposals', num_max_proposals=2000),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=[(1333, 400), (1333, 800)], keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[122.7709383, 116.7460125, 104.09373615],
        std=[68.5005327, 66.6321579, 70.32316305],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadProposals', num_max_proposals=None),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[122.7709383, 116.7460125, 104.09373615],
                std=[68.5005327, 66.6321579, 70.32316305],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['proposals']),
            dict(
                type='ToDataContainer',
                fields=[dict(key='proposals', stack=False)]),
            dict(type='Collect', keys=['img', 'proposals'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type='CocoDataset',
                ann_file=
                '/root/autodl-tmp/datasets/coco/annotations/instances_train2017.1@5.0.json',
                img_prefix='/root/autodl-tmp/datasets/coco/train2017/',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadProposals', num_max_proposals=2000),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        type='Resize',
                        img_scale=[(1333, 400), (1333, 800)],
                        keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='DefaultFormatBundle'),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
                ],
                proposal_file=
                '/root/autodl-tmp/rpl/decouple_oidcoco_coco_rp_train.pkl',
                dataset_id=0),
            dict(
                type='CocoDataset',
                ann_file=
                '/root/autodl-tmp/datasets/object365/annotations/zhiyuan_objv2_train_patch0-5.1@2.0_cleaned.json',
                img_prefix='/root/autodl-tmp/datasets/object365',
                classes=[
                    'Person', 'Sneakers', 'Chair', 'Other Shoes', 'Hat', 'Car',
                    'Lamp', 'Glasses', 'Bottle', 'Desk', 'Cup',
                    'Street Lights', 'Cabinet/shelf', 'Handbag/Satchel',
                    'Bracelet', 'Plate', 'Picture/Frame', 'Helmet', 'Book',
                    'Gloves', 'Storage box', 'Boat', 'Leather Shoes', 'Flower',
                    'Bench', 'Potted Plant', 'Bowl/Basin', 'Flag', 'Pillow',
                    'Boots', 'Vase', 'Microphone', 'Necklace', 'Ring', 'SUV',
                    'Wine Glass', 'Belt', 'Moniter/TV', 'Backpack', 'Umbrella',
                    'Traffic Light', 'Speaker', 'Watch', 'Tie',
                    'Trash bin Can', 'Slippers', 'Bicycle', 'Stool',
                    'Barrel/bucket', 'Van', 'Couch', 'Sandals', 'Bakset',
                    'Drum', 'Pen/Pencil', 'Bus', 'Wild Bird', 'High Heels',
                    'Motorcycle', 'Guitar', 'Carpet', 'Cell Phone', 'Bread',
                    'Camera', 'Canned', 'Truck', 'Traffic cone', 'Cymbal',
                    'Lifesaver', 'Towel', 'Stuffed Toy', 'Candle', 'Sailboat',
                    'Laptop', 'Awning', 'Bed', 'Faucet', 'Tent', 'Horse',
                    'Mirror', 'Power outlet', 'Sink', 'Apple',
                    'Air Conditioner', 'Knife', 'Hockey Stick', 'Paddle',
                    'Pickup Truck', 'Fork', 'Traffic Sign', 'Ballon', 'Tripod',
                    'Dog', 'Spoon', 'Clock', 'Pot', 'Cow', 'Cake',
                    'Dinning Table', 'Sheep', 'Hanger',
                    'Blackboard/Whiteboard', 'Napkin', 'Other Fish',
                    'Orange/Tangerine', 'Toiletry', 'Keyboard', 'Tomato',
                    'Lantern', 'Machinery Vehicle', 'Fan', 'Green Vegetables',
                    'Banana', 'Baseball Glove', 'Airplane', 'Mouse', 'Train',
                    'Pumpkin', 'Soccer', 'Skiboard', 'Luggage', 'Nightstand',
                    'Tea pot', 'Telephone', 'Trolley', 'Head Phone',
                    'Sports Car', 'Stop Sign', 'Dessert', 'Scooter',
                    'Stroller', 'Crane', 'Remote', 'Refrigerator', 'Oven',
                    'Lemon', 'Duck', 'Baseball Bat', 'Surveillance Camera',
                    'Cat', 'Jug', 'Broccoli', 'Piano', 'Pizza', 'Elephant',
                    'Skateboard', 'Surfboard', 'Gun',
                    'Skating and Skiing shoes', 'Gas stove', 'Donut',
                    'Bow Tie', 'Carrot', 'Toilet', 'Kite', 'Strawberry',
                    'Other Balls', 'Shovel', 'Pepper', 'Computer Box',
                    'Toilet Paper', 'Cleaning Products', 'Chopsticks',
                    'Microwave', 'Pigeon', 'Baseball',
                    'Cutting/chopping Board', 'Coffee Table', 'Side Table',
                    'Scissors', 'Marker', 'Pie', 'Ladder', 'Snowboard',
                    'Cookies', 'Radiator', 'Fire Hydrant', 'Basketball',
                    'Zebra', 'Grape', 'Giraffe', 'Potato', 'Sausage',
                    'Tricycle', 'Violin', 'Egg', 'Fire Extinguisher', 'Candy',
                    'Fire Truck', 'Billards', 'Converter', 'Bathtub',
                    'Wheelchair', 'Golf Club', 'Briefcase', 'Cucumber',
                    'Cigar/Cigarette ', 'Paint Brush', 'Pear', 'Heavy Truck',
                    'Hamburger', 'Extractor', 'Extention Cord', 'Tong',
                    'Tennis Racket', 'Folder', 'American Football', 'earphone',
                    'Mask', 'Kettle', 'Tennis', 'Ship', 'Swing',
                    'Coffee Machine', 'Slide', 'Carriage', 'Onion',
                    'Green beans', 'Projector', 'Frisbee',
                    'Washing Machine/Drying Machine', 'Chicken', 'Printer',
                    'Watermelon', 'Saxophone', 'Tissue', 'Toothbrush',
                    'Ice cream', 'Hotair ballon', 'Cello', 'French Fries',
                    'Scale', 'Trophy', 'Cabbage', 'Hot dog', 'Blender',
                    'Peach', 'Rice', 'Wallet/Purse', 'Volleyball', 'Deer',
                    'Goose', 'Tape', 'Tablet', 'Cosmetics', 'Trumpet',
                    'Pineapple', 'Golf Ball', 'Ambulance', 'Parking meter',
                    'Mango', 'Key', 'Hurdle', 'Fishing Rod', 'Medal', 'Flute',
                    'Brush', 'Penguin', 'Megaphone', 'Corn', 'Lettuce',
                    'Garlic', 'Swan', 'Helicopter', 'Green Onion', 'Sandwich',
                    'Nuts', 'Speed Limit Sign', 'Induction Cooker', 'Broom',
                    'Trombone', 'Plum', 'Rickshaw', 'Goldfish', 'Kiwi fruit',
                    'Router/modem', 'Poker Card', 'Toaster', 'Shrimp', 'Sushi',
                    'Cheese', 'Notepaper', 'Cherry', 'Pliers', 'CD', 'Pasta',
                    'Hammer', 'Cue', 'Avocado', 'Hamimelon', 'Flask',
                    'Mushroon', 'Screwdriver', 'Soap', 'Recorder', 'Bear',
                    'Eggplant', 'Board Eraser', 'Coconut',
                    'Tape Measur/ Ruler', 'Pig', 'Showerhead', 'Globe',
                    'Chips', 'Steak', 'Crosswalk Sign', 'Stapler', 'Campel',
                    'Formula 1 ', 'Pomegranate', 'Dishwasher', 'Crab',
                    'Hoverboard', 'Meat ball', 'Rice Cooker', 'Tuba',
                    'Calculator', 'Papaya', 'Antelope', 'Parrot', 'Seal',
                    'Buttefly', 'Dumbbell', 'Donkey', 'Lion', 'Urinal',
                    'Dolphin', 'Electric Drill', 'Hair Dryer', 'Egg tart',
                    'Jellyfish', 'Treadmill', 'Lighter', 'Grapefruit',
                    'Game board', 'Mop', 'Radish', 'Baozi', 'Target', 'French',
                    'Spring Rolls', 'Monkey', 'Rabbit', 'Pencil Case', 'Yak',
                    'Red Cabbage', 'Binoculars', 'Asparagus', 'Barbell',
                    'Scallop', 'Noddles', 'Comb', 'Dumpling', 'Oyster',
                    'Table Teniis paddle', 'Cosmetics Brush/Eyeliner Pencil',
                    'Chainsaw', 'Eraser', 'Lobster', 'Durian', 'Okra',
                    'Lipstick', 'Cosmetics Mirror', 'Curling', 'Table Tennis '
                ],
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadProposals', num_max_proposals=2000),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        type='Resize',
                        img_scale=[(1333, 400), (1333, 800)],
                        keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.5),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='DefaultFormatBundle'),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bboxes', 'gt_labels', 'proposals'])
                ],
                proposal_file=
                '/root/autodl-tmp/rpl/decouple_oidcoco_obj365_rp_train.pkl',
                dataset_id=1)
        ]),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        proposal_file='/root/autodl-tmp/rpl/decouple_oidcoco_coco_rp_val.pkl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadProposals', num_max_proposals=None),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='ToTensor', keys=['proposals']),
                    dict(
                        type='ToDataContainer',
                        fields=[dict(key='proposals', stack=False)]),
                    dict(type='Collect', keys=['img', 'proposals'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/root/autodl-tmp/datasets/coco/annotations/instances_val2017.1@17.0.json',
        img_prefix='/root/autodl-tmp/datasets/coco/val2017/',
        proposal_file='/root/autodl-tmp/rpl/decouple_oidcoco_coco_rp_val.pkl',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadProposals', num_max_proposals=None),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[122.7709383, 116.7460125, 104.09373615],
                        std=[68.5005327, 66.6321579, 70.32316305],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='ToTensor', keys=['proposals']),
                    dict(
                        type='ToDataContainer',
                        fields=[dict(key='proposals', stack=False)]),
                    dict(type='Collect', keys=['img', 'proposals'])
                ])
        ]))
evaluation = dict(interval=2, metric='bbox')
optimizer = dict(
    type='SGD',
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0001,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=0.1, decay_mult=1.0),
            roi_head=dict(lr_mult=0.1, decay_mult=1.0))))
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[3, 4])
runner = dict(type='EpochBasedRunner', max_epochs=4)
seed = 1
work_dir = '/root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage20250805_144443'
gpu_ids = range(0, 1)

2025-08-05 14:44:59,953 - mmdet - INFO - initialize BBoxHeadCLIPPartitioned with init_cfg [{'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.conv2.weight - torch.Size([32, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn2.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn2.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.conv3.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.bn3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn3.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.shared_head.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.attnpool.positional_embedding - torch.Size([50, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.k_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.k_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.q_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.q_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.v_proj.weight - torch.Size([2048, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.v_proj.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.c_proj.weight - torch.Size([1024, 2048]): 
The value is the same before and after calling `init_weights` of FastRCNN  

roi_head.bbox_head.attnpool.c_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of FastRCNN  
2025-08-05 14:45:03,506 - mmdet - INFO - load checkpoint from local path: /root/UniDetector/regionclip_pretrained-cc_rn50_mmdet.pth
2025-08-05 14:45:03,615 - mmdet - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: roi_head.bbox_head.zs_weights_0, roi_head.bbox_head.zs_weights_1, roi_head.bbox_head.fc_reg.weight, roi_head.bbox_head.fc_reg.bias

2025-08-05 14:45:03,615 - mmdet - INFO - Start running, host: root@autodl-container-4bf6429de3-797681b8, work_dir: /root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage20250805_144443
2025-08-05 14:45:03,615 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-08-05 14:45:03,616 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs
2025-08-05 14:45:03,616 - mmdet - INFO - Checkpoints will be saved to /root/autodl-tmp/log/clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage20250805_144443 by HardDiskBackend.
2025-08-05 14:45:35,191 - mmdet - INFO - Epoch [1][50/4665]	lr: 4.945e-04, eta: 3:15:50, time: 0.631, data_time: 0.315, memory: 12094, loss_cls: 209.7722, acc: 16.9199, loss_bbox: 0.2903, loss: 210.0625, grad_norm: 2434.9472
2025-08-05 14:45:51,277 - mmdet - INFO - Epoch [1][100/4665]	lr: 9.940e-04, eta: 2:27:25, time: 0.322, data_time: 0.005, memory: 12142, loss_cls: 0.7762, acc: 88.8652, loss_bbox: 0.2978, loss: 1.0741, grad_norm: 20.8321
2025-08-05 14:46:07,381 - mmdet - INFO - Epoch [1][150/4665]	lr: 1.494e-03, eta: 2:11:08, time: 0.322, data_time: 0.005, memory: 12142, loss_cls: 0.5239, acc: 87.6348, loss_bbox: 0.3881, loss: 0.9120, grad_norm: 12.4068
2025-08-05 14:46:23,635 - mmdet - INFO - Epoch [1][200/4665]	lr: 1.993e-03, eta: 2:03:05, time: 0.325, data_time: 0.006, memory: 12142, loss_cls: 0.4019, acc: 89.8809, loss_bbox: 0.3027, loss: 0.7046, grad_norm: 12.6493
2025-08-05 14:46:39,854 - mmdet - INFO - Epoch [1][250/4665]	lr: 2.493e-03, eta: 1:58:06, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.4177, acc: 88.6836, loss_bbox: 0.3557, loss: 0.7734, grad_norm: 11.9343
2025-08-05 14:46:56,024 - mmdet - INFO - Epoch [1][300/4665]	lr: 2.992e-03, eta: 1:54:39, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.3871, acc: 90.1504, loss_bbox: 0.3210, loss: 0.7080, grad_norm: 9.7695
2025-08-05 14:47:12,269 - mmdet - INFO - Epoch [1][350/4665]	lr: 3.492e-03, eta: 1:52:10, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.3234, acc: 90.6582, loss_bbox: 0.3070, loss: 0.6304, grad_norm: 10.4887
2025-08-05 14:47:28,538 - mmdet - INFO - Epoch [1][400/4665]	lr: 3.991e-03, eta: 1:50:15, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.3569, acc: 90.8613, loss_bbox: 0.3007, loss: 0.6577, grad_norm: 10.1836
2025-08-05 14:47:44,686 - mmdet - INFO - Epoch [1][450/4665]	lr: 4.491e-03, eta: 1:48:37, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.3837, acc: 88.7266, loss_bbox: 0.3515, loss: 0.7352, grad_norm: 9.8046
2025-08-05 14:48:00,833 - mmdet - INFO - Epoch [1][500/4665]	lr: 4.990e-03, eta: 1:47:16, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.3560, acc: 90.0117, loss_bbox: 0.3296, loss: 0.6856, grad_norm: 9.7679
2025-08-05 14:48:17,041 - mmdet - INFO - Epoch [1][550/4665]	lr: 5.000e-03, eta: 1:46:08, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.3189, acc: 91.1660, loss_bbox: 0.2891, loss: 0.6080, grad_norm: 8.1746
2025-08-05 14:48:33,153 - mmdet - INFO - Epoch [1][600/4665]	lr: 5.000e-03, eta: 1:45:06, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.3347, acc: 90.8262, loss_bbox: 0.2786, loss: 0.6133, grad_norm: 9.6883
2025-08-05 14:48:49,521 - mmdet - INFO - Epoch [1][650/4665]	lr: 5.000e-03, eta: 1:44:19, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.3140, acc: 91.2891, loss_bbox: 0.2699, loss: 0.5839, grad_norm: 8.2605
2025-08-05 14:49:05,865 - mmdet - INFO - Epoch [1][700/4665]	lr: 5.000e-03, eta: 1:43:35, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.3323, acc: 90.1777, loss_bbox: 0.3176, loss: 0.6499, grad_norm: 8.0453
2025-08-05 14:49:22,079 - mmdet - INFO - Epoch [1][750/4665]	lr: 5.000e-03, eta: 1:42:51, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2967, acc: 90.9727, loss_bbox: 0.3058, loss: 0.6025, grad_norm: 7.6108
2025-08-05 14:49:38,271 - mmdet - INFO - Epoch [1][800/4665]	lr: 5.000e-03, eta: 1:42:11, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.3089, acc: 91.2637, loss_bbox: 0.3433, loss: 0.6522, grad_norm: 7.2598
2025-08-05 14:49:54,397 - mmdet - INFO - Epoch [1][850/4665]	lr: 5.000e-03, eta: 1:41:32, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2773, acc: 91.3984, loss_bbox: 0.2915, loss: 0.5688, grad_norm: 7.6716
2025-08-05 14:50:10,550 - mmdet - INFO - Epoch [1][900/4665]	lr: 5.000e-03, eta: 1:40:56, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2953, acc: 91.0312, loss_bbox: 0.3068, loss: 0.6020, grad_norm: 8.0446
2025-08-05 14:50:26,887 - mmdet - INFO - Epoch [1][950/4665]	lr: 5.000e-03, eta: 1:40:26, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.3166, acc: 90.7461, loss_bbox: 0.3208, loss: 0.6374, grad_norm: 7.8208
2025-08-05 14:50:43,030 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 14:50:43,030 - mmdet - INFO - Epoch [1][1000/4665]	lr: 5.000e-03, eta: 1:39:53, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2807, acc: 91.5547, loss_bbox: 0.2939, loss: 0.5746, grad_norm: 6.8028
2025-08-05 14:50:59,299 - mmdet - INFO - Epoch [1][1050/4665]	lr: 5.000e-03, eta: 1:39:25, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2852, acc: 91.1934, loss_bbox: 0.3077, loss: 0.5929, grad_norm: 7.7127
2025-08-05 14:51:15,597 - mmdet - INFO - Epoch [1][1100/4665]	lr: 5.000e-03, eta: 1:38:58, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.3344, acc: 90.3105, loss_bbox: 0.3520, loss: 0.6865, grad_norm: 7.1471
2025-08-05 14:51:31,857 - mmdet - INFO - Epoch [1][1150/4665]	lr: 5.000e-03, eta: 1:38:31, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2922, acc: 91.5156, loss_bbox: 0.3089, loss: 0.6011, grad_norm: 7.2140
2025-08-05 14:51:48,039 - mmdet - INFO - Epoch [1][1200/4665]	lr: 5.000e-03, eta: 1:38:04, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2865, acc: 91.4902, loss_bbox: 0.3074, loss: 0.5938, grad_norm: 8.1220
2025-08-05 14:52:04,276 - mmdet - INFO - Epoch [1][1250/4665]	lr: 5.000e-03, eta: 1:37:38, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2955, acc: 91.3125, loss_bbox: 0.3217, loss: 0.6172, grad_norm: 7.6333
2025-08-05 14:52:20,548 - mmdet - INFO - Epoch [1][1300/4665]	lr: 5.000e-03, eta: 1:37:14, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.3354, acc: 90.2324, loss_bbox: 0.3304, loss: 0.6658, grad_norm: 7.4542
2025-08-05 14:52:36,742 - mmdet - INFO - Epoch [1][1350/4665]	lr: 5.000e-03, eta: 1:36:49, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2808, acc: 91.7871, loss_bbox: 0.2912, loss: 0.5720, grad_norm: 6.5035
2025-08-05 14:52:52,945 - mmdet - INFO - Epoch [1][1400/4665]	lr: 5.000e-03, eta: 1:36:26, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2819, acc: 91.9453, loss_bbox: 0.2920, loss: 0.5739, grad_norm: 6.6081
2025-08-05 14:53:09,141 - mmdet - INFO - Epoch [1][1450/4665]	lr: 5.000e-03, eta: 1:36:02, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2677, acc: 92.2891, loss_bbox: 0.2707, loss: 0.5384, grad_norm: 6.7921
2025-08-05 14:53:25,370 - mmdet - INFO - Epoch [1][1500/4665]	lr: 5.000e-03, eta: 1:35:39, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2698, acc: 92.1621, loss_bbox: 0.2737, loss: 0.5436, grad_norm: 6.9630
2025-08-05 14:53:41,540 - mmdet - INFO - Epoch [1][1550/4665]	lr: 5.000e-03, eta: 1:35:17, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.3005, acc: 91.5469, loss_bbox: 0.3385, loss: 0.6390, grad_norm: 7.8021
2025-08-05 14:53:57,777 - mmdet - INFO - Epoch [1][1600/4665]	lr: 5.000e-03, eta: 1:34:55, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2587, acc: 91.9961, loss_bbox: 0.3025, loss: 0.5612, grad_norm: 7.1187
2025-08-05 14:54:14,058 - mmdet - INFO - Epoch [1][1650/4665]	lr: 5.000e-03, eta: 1:34:34, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2435, acc: 92.5039, loss_bbox: 0.2788, loss: 0.5223, grad_norm: 6.6885
2025-08-05 14:54:30,193 - mmdet - INFO - Epoch [1][1700/4665]	lr: 5.000e-03, eta: 1:34:12, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2940, acc: 90.7910, loss_bbox: 0.3368, loss: 0.6308, grad_norm: 7.1327
2025-08-05 14:54:46,329 - mmdet - INFO - Epoch [1][1750/4665]	lr: 5.000e-03, eta: 1:33:50, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2326, acc: 92.7871, loss_bbox: 0.2418, loss: 0.4743, grad_norm: 6.2084
2025-08-05 14:55:02,484 - mmdet - INFO - Epoch [1][1800/4665]	lr: 5.000e-03, eta: 1:33:29, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2845, acc: 91.1191, loss_bbox: 0.3303, loss: 0.6147, grad_norm: 6.8090
2025-08-05 14:55:18,666 - mmdet - INFO - Epoch [1][1850/4665]	lr: 5.000e-03, eta: 1:33:08, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2631, acc: 92.1074, loss_bbox: 0.2632, loss: 0.5262, grad_norm: 7.0682
2025-08-05 14:55:34,822 - mmdet - INFO - Epoch [1][1900/4665]	lr: 5.000e-03, eta: 1:32:47, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2857, acc: 91.7793, loss_bbox: 0.2944, loss: 0.5802, grad_norm: 6.4691
2025-08-05 14:55:51,039 - mmdet - INFO - Epoch [1][1950/4665]	lr: 5.000e-03, eta: 1:32:27, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2660, acc: 91.7969, loss_bbox: 0.3065, loss: 0.5725, grad_norm: 6.2512
2025-08-05 14:56:07,301 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 14:56:07,301 - mmdet - INFO - Epoch [1][2000/4665]	lr: 5.000e-03, eta: 1:32:08, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2545, acc: 91.9121, loss_bbox: 0.3275, loss: 0.5820, grad_norm: 6.1716
2025-08-05 14:56:23,599 - mmdet - INFO - Epoch [1][2050/4665]	lr: 5.000e-03, eta: 1:31:49, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2754, acc: 91.5508, loss_bbox: 0.2966, loss: 0.5720, grad_norm: 7.2146
2025-08-05 14:56:39,916 - mmdet - INFO - Epoch [1][2100/4665]	lr: 5.000e-03, eta: 1:31:30, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2672, acc: 91.7148, loss_bbox: 0.2920, loss: 0.5591, grad_norm: 7.0611
2025-08-05 14:56:55,980 - mmdet - INFO - Epoch [1][2150/4665]	lr: 5.000e-03, eta: 1:31:10, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2462, acc: 92.5234, loss_bbox: 0.2852, loss: 0.5314, grad_norm: 5.9892
2025-08-05 14:57:12,090 - mmdet - INFO - Epoch [1][2200/4665]	lr: 5.000e-03, eta: 1:30:50, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2658, acc: 91.7773, loss_bbox: 0.2836, loss: 0.5494, grad_norm: 6.5006
2025-08-05 14:57:28,262 - mmdet - INFO - Epoch [1][2250/4665]	lr: 5.000e-03, eta: 1:30:30, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2866, acc: 91.2617, loss_bbox: 0.2927, loss: 0.5793, grad_norm: 7.3281
2025-08-05 14:57:44,309 - mmdet - INFO - Epoch [1][2300/4665]	lr: 5.000e-03, eta: 1:30:10, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2365, acc: 92.2910, loss_bbox: 0.2837, loss: 0.5202, grad_norm: 6.4579
2025-08-05 14:58:00,571 - mmdet - INFO - Epoch [1][2350/4665]	lr: 5.000e-03, eta: 1:29:52, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2551, acc: 91.7773, loss_bbox: 0.2875, loss: 0.5426, grad_norm: 6.2777
2025-08-05 14:58:16,709 - mmdet - INFO - Epoch [1][2400/4665]	lr: 5.000e-03, eta: 1:29:33, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2466, acc: 92.2559, loss_bbox: 0.2885, loss: 0.5351, grad_norm: 6.2758
2025-08-05 14:58:32,982 - mmdet - INFO - Epoch [1][2450/4665]	lr: 5.000e-03, eta: 1:29:14, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2527, acc: 92.0625, loss_bbox: 0.2829, loss: 0.5356, grad_norm: 6.2643
2025-08-05 14:58:49,187 - mmdet - INFO - Epoch [1][2500/4665]	lr: 5.000e-03, eta: 1:28:56, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2570, acc: 92.7031, loss_bbox: 0.2740, loss: 0.5310, grad_norm: 6.8846
2025-08-05 14:59:05,353 - mmdet - INFO - Epoch [1][2550/4665]	lr: 5.000e-03, eta: 1:28:37, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2775, acc: 91.0000, loss_bbox: 0.3235, loss: 0.6010, grad_norm: 7.5132
2025-08-05 14:59:21,526 - mmdet - INFO - Epoch [1][2600/4665]	lr: 5.000e-03, eta: 1:28:19, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2661, acc: 91.5840, loss_bbox: 0.3085, loss: 0.5746, grad_norm: 6.8178
2025-08-05 14:59:37,835 - mmdet - INFO - Epoch [1][2650/4665]	lr: 5.000e-03, eta: 1:28:01, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2363, acc: 92.2891, loss_bbox: 0.2811, loss: 0.5174, grad_norm: 6.6554
2025-08-05 14:59:54,107 - mmdet - INFO - Epoch [1][2700/4665]	lr: 5.000e-03, eta: 1:27:43, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2986, acc: 90.9121, loss_bbox: 0.3197, loss: 0.6183, grad_norm: 7.5183
2025-08-05 15:00:10,298 - mmdet - INFO - Epoch [1][2750/4665]	lr: 5.000e-03, eta: 1:27:25, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2379, acc: 92.8477, loss_bbox: 0.2612, loss: 0.4991, grad_norm: 6.2247
2025-08-05 15:00:26,509 - mmdet - INFO - Epoch [1][2800/4665]	lr: 5.000e-03, eta: 1:27:07, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2362, acc: 92.9336, loss_bbox: 0.2557, loss: 0.4920, grad_norm: 5.8588
2025-08-05 15:00:42,607 - mmdet - INFO - Epoch [1][2850/4665]	lr: 5.000e-03, eta: 1:26:48, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2270, acc: 92.3262, loss_bbox: 0.2938, loss: 0.5208, grad_norm: 6.0008
2025-08-05 15:00:58,818 - mmdet - INFO - Epoch [1][2900/4665]	lr: 5.000e-03, eta: 1:26:30, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2301, acc: 92.4277, loss_bbox: 0.2658, loss: 0.4959, grad_norm: 6.6096
2025-08-05 15:01:14,976 - mmdet - INFO - Epoch [1][2950/4665]	lr: 5.000e-03, eta: 1:26:12, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2314, acc: 92.4844, loss_bbox: 0.2741, loss: 0.5055, grad_norm: 6.7442
2025-08-05 15:01:31,191 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 15:01:31,191 - mmdet - INFO - Epoch [1][3000/4665]	lr: 5.000e-03, eta: 1:25:55, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2605, acc: 91.6328, loss_bbox: 0.2798, loss: 0.5403, grad_norm: 7.2418
2025-08-05 15:01:47,382 - mmdet - INFO - Epoch [1][3050/4665]	lr: 5.000e-03, eta: 1:25:37, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2741, acc: 91.5312, loss_bbox: 0.2905, loss: 0.5646, grad_norm: 7.4837
2025-08-05 15:02:03,583 - mmdet - INFO - Epoch [1][3100/4665]	lr: 5.000e-03, eta: 1:25:19, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2586, acc: 92.1211, loss_bbox: 0.2797, loss: 0.5382, grad_norm: 6.6245
2025-08-05 15:02:19,946 - mmdet - INFO - Epoch [1][3150/4665]	lr: 5.000e-03, eta: 1:25:02, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2521, acc: 91.9375, loss_bbox: 0.2906, loss: 0.5427, grad_norm: 6.4457
2025-08-05 15:02:36,021 - mmdet - INFO - Epoch [1][3200/4665]	lr: 5.000e-03, eta: 1:24:44, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2456, acc: 92.7168, loss_bbox: 0.2691, loss: 0.5147, grad_norm: 6.3700
2025-08-05 15:02:52,233 - mmdet - INFO - Epoch [1][3250/4665]	lr: 5.000e-03, eta: 1:24:26, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2487, acc: 92.2852, loss_bbox: 0.2666, loss: 0.5153, grad_norm: 6.0661
2025-08-05 15:03:08,612 - mmdet - INFO - Epoch [1][3300/4665]	lr: 5.000e-03, eta: 1:24:10, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2646, acc: 91.8984, loss_bbox: 0.2821, loss: 0.5467, grad_norm: 7.2568
2025-08-05 15:03:24,878 - mmdet - INFO - Epoch [1][3350/4665]	lr: 5.000e-03, eta: 1:23:52, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2524, acc: 92.0547, loss_bbox: 0.2829, loss: 0.5353, grad_norm: 6.6236
2025-08-05 15:03:41,011 - mmdet - INFO - Epoch [1][3400/4665]	lr: 5.000e-03, eta: 1:23:35, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2301, acc: 92.7363, loss_bbox: 0.2688, loss: 0.4988, grad_norm: 6.2605
2025-08-05 15:03:57,206 - mmdet - INFO - Epoch [1][3450/4665]	lr: 5.000e-03, eta: 1:23:17, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2299, acc: 92.3730, loss_bbox: 0.2926, loss: 0.5225, grad_norm: 5.9117
2025-08-05 15:04:13,564 - mmdet - INFO - Epoch [1][3500/4665]	lr: 5.000e-03, eta: 1:23:00, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2549, acc: 92.2871, loss_bbox: 0.2880, loss: 0.5428, grad_norm: 6.6644
2025-08-05 15:04:29,769 - mmdet - INFO - Epoch [1][3550/4665]	lr: 5.000e-03, eta: 1:22:43, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2157, acc: 92.7520, loss_bbox: 0.2418, loss: 0.4575, grad_norm: 5.9612
2025-08-05 15:04:45,877 - mmdet - INFO - Epoch [1][3600/4665]	lr: 5.000e-03, eta: 1:22:25, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2521, acc: 91.9160, loss_bbox: 0.2905, loss: 0.5427, grad_norm: 7.0803
2025-08-05 15:05:01,951 - mmdet - INFO - Epoch [1][3650/4665]	lr: 5.000e-03, eta: 1:22:07, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2789, acc: 91.6523, loss_bbox: 0.2964, loss: 0.5753, grad_norm: 7.2227
2025-08-05 15:05:18,239 - mmdet - INFO - Epoch [1][3700/4665]	lr: 5.000e-03, eta: 1:21:50, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2566, acc: 91.6934, loss_bbox: 0.2835, loss: 0.5401, grad_norm: 6.9310
2025-08-05 15:05:34,366 - mmdet - INFO - Epoch [1][3750/4665]	lr: 5.000e-03, eta: 1:21:33, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2528, acc: 91.9961, loss_bbox: 0.3135, loss: 0.5663, grad_norm: 6.9686
2025-08-05 15:05:50,628 - mmdet - INFO - Epoch [1][3800/4665]	lr: 5.000e-03, eta: 1:21:16, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.2421, acc: 92.5957, loss_bbox: 0.2563, loss: 0.4985, grad_norm: 5.8811
2025-08-05 15:06:06,866 - mmdet - INFO - Epoch [1][3850/4665]	lr: 5.000e-03, eta: 1:20:59, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2611, acc: 92.3184, loss_bbox: 0.2610, loss: 0.5221, grad_norm: 5.7865
2025-08-05 15:06:23,182 - mmdet - INFO - Epoch [1][3900/4665]	lr: 5.000e-03, eta: 1:20:42, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2522, acc: 91.4160, loss_bbox: 0.2941, loss: 0.5463, grad_norm: 7.0752
2025-08-05 15:06:39,368 - mmdet - INFO - Epoch [1][3950/4665]	lr: 5.000e-03, eta: 1:20:25, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2380, acc: 92.1621, loss_bbox: 0.2766, loss: 0.5146, grad_norm: 6.4714
2025-08-05 15:06:55,519 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 15:06:55,519 - mmdet - INFO - Epoch [1][4000/4665]	lr: 5.000e-03, eta: 1:20:08, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2357, acc: 92.5430, loss_bbox: 0.2616, loss: 0.4973, grad_norm: 6.2627
2025-08-05 15:07:11,639 - mmdet - INFO - Epoch [1][4050/4665]	lr: 5.000e-03, eta: 1:19:50, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2754, acc: 91.3594, loss_bbox: 0.2896, loss: 0.5651, grad_norm: 7.0433
2025-08-05 15:07:27,930 - mmdet - INFO - Epoch [1][4100/4665]	lr: 5.000e-03, eta: 1:19:33, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2533, acc: 92.0527, loss_bbox: 0.2936, loss: 0.5468, grad_norm: 6.5729
2025-08-05 15:07:44,301 - mmdet - INFO - Epoch [1][4150/4665]	lr: 5.000e-03, eta: 1:19:17, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2900, acc: 90.8242, loss_bbox: 0.2882, loss: 0.5782, grad_norm: 7.7786
2025-08-05 15:08:00,700 - mmdet - INFO - Epoch [1][4200/4665]	lr: 5.000e-03, eta: 1:19:01, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2693, acc: 91.7500, loss_bbox: 0.2834, loss: 0.5528, grad_norm: 6.9752
2025-08-05 15:08:16,806 - mmdet - INFO - Epoch [1][4250/4665]	lr: 5.000e-03, eta: 1:18:43, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2220, acc: 93.3262, loss_bbox: 0.2475, loss: 0.4695, grad_norm: 5.5793
2025-08-05 15:08:32,977 - mmdet - INFO - Epoch [1][4300/4665]	lr: 5.000e-03, eta: 1:18:26, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2516, acc: 91.4512, loss_bbox: 0.3155, loss: 0.5670, grad_norm: 6.9290
2025-08-05 15:08:49,244 - mmdet - INFO - Epoch [1][4350/4665]	lr: 5.000e-03, eta: 1:18:09, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.2821, acc: 90.8379, loss_bbox: 0.3200, loss: 0.6020, grad_norm: 6.8555
2025-08-05 15:09:05,457 - mmdet - INFO - Epoch [1][4400/4665]	lr: 5.000e-03, eta: 1:17:52, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2659, acc: 91.5137, loss_bbox: 0.2883, loss: 0.5542, grad_norm: 6.7073
2025-08-05 15:09:21,686 - mmdet - INFO - Epoch [1][4450/4665]	lr: 5.000e-03, eta: 1:17:35, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2668, acc: 91.4238, loss_bbox: 0.3067, loss: 0.5736, grad_norm: 6.7420
2025-08-05 15:09:37,893 - mmdet - INFO - Epoch [1][4500/4665]	lr: 5.000e-03, eta: 1:17:18, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2489, acc: 91.8730, loss_bbox: 0.2737, loss: 0.5226, grad_norm: 6.4363
2025-08-05 15:09:54,068 - mmdet - INFO - Epoch [1][4550/4665]	lr: 5.000e-03, eta: 1:17:01, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2528, acc: 92.3047, loss_bbox: 0.2625, loss: 0.5153, grad_norm: 6.5201
2025-08-05 15:10:10,377 - mmdet - INFO - Epoch [1][4600/4665]	lr: 5.000e-03, eta: 1:16:45, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2524, acc: 92.3047, loss_bbox: 0.2716, loss: 0.5241, grad_norm: 6.0363
2025-08-05 15:10:26,507 - mmdet - INFO - Epoch [1][4650/4665]	lr: 5.000e-03, eta: 1:16:28, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2176, acc: 93.0410, loss_bbox: 0.2522, loss: 0.4698, grad_norm: 5.6122
2025-08-05 15:11:03,710 - mmdet - INFO - Epoch [2][50/4665]	lr: 5.000e-03, eta: 1:16:36, time: 0.628, data_time: 0.310, memory: 12189, loss_cls: 0.2061, acc: 93.3691, loss_bbox: 0.2453, loss: 0.4514, grad_norm: 5.7079
2025-08-05 15:11:19,860 - mmdet - INFO - Epoch [2][100/4665]	lr: 5.000e-03, eta: 1:16:19, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2343, acc: 92.1348, loss_bbox: 0.2800, loss: 0.5143, grad_norm: 6.1495
2025-08-05 15:11:36,006 - mmdet - INFO - Epoch [2][150/4665]	lr: 5.000e-03, eta: 1:16:01, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2340, acc: 92.4902, loss_bbox: 0.2726, loss: 0.5066, grad_norm: 6.5777
2025-08-05 15:11:52,207 - mmdet - INFO - Epoch [2][200/4665]	lr: 5.000e-03, eta: 1:15:44, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2293, acc: 91.7617, loss_bbox: 0.2921, loss: 0.5214, grad_norm: 5.9383
2025-08-05 15:12:08,546 - mmdet - INFO - Epoch [2][250/4665]	lr: 5.000e-03, eta: 1:15:27, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2224, acc: 92.4746, loss_bbox: 0.2726, loss: 0.4951, grad_norm: 6.7850
2025-08-05 15:12:24,747 - mmdet - INFO - Epoch [2][300/4665]	lr: 5.000e-03, eta: 1:15:10, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2241, acc: 92.0859, loss_bbox: 0.2892, loss: 0.5134, grad_norm: 6.3264
2025-08-05 15:12:40,923 - mmdet - INFO - Epoch [2][350/4665]	lr: 5.000e-03, eta: 1:14:53, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2232, acc: 92.1562, loss_bbox: 0.2669, loss: 0.4901, grad_norm: 6.9240
2025-08-05 15:12:57,185 - mmdet - INFO - Epoch [2][400/4665]	lr: 5.000e-03, eta: 1:14:36, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2309, acc: 91.9746, loss_bbox: 0.2862, loss: 0.5171, grad_norm: 6.6887
2025-08-05 15:13:13,389 - mmdet - INFO - Epoch [2][450/4665]	lr: 5.000e-03, eta: 1:14:19, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2286, acc: 92.5176, loss_bbox: 0.2776, loss: 0.5062, grad_norm: 6.7309
2025-08-05 15:13:29,380 - mmdet - INFO - Epoch [2][500/4665]	lr: 5.000e-03, eta: 1:14:01, time: 0.320, data_time: 0.005, memory: 12189, loss_cls: 0.2473, acc: 91.6465, loss_bbox: 0.3070, loss: 0.5543, grad_norm: 6.6155
2025-08-05 15:13:45,588 - mmdet - INFO - Epoch [2][550/4665]	lr: 5.000e-03, eta: 1:13:44, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2766, acc: 90.4668, loss_bbox: 0.3422, loss: 0.6188, grad_norm: 6.6111
2025-08-05 15:14:01,790 - mmdet - INFO - Epoch [2][600/4665]	lr: 5.000e-03, eta: 1:13:27, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2211, acc: 92.8359, loss_bbox: 0.2486, loss: 0.4697, grad_norm: 5.7443
2025-08-05 15:14:18,064 - mmdet - INFO - Epoch [2][650/4665]	lr: 5.000e-03, eta: 1:13:10, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2187, acc: 92.7285, loss_bbox: 0.2669, loss: 0.4856, grad_norm: 6.4909
2025-08-05 15:14:34,163 - mmdet - INFO - Epoch [2][700/4665]	lr: 5.000e-03, eta: 1:12:53, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2181, acc: 93.0762, loss_bbox: 0.2675, loss: 0.4856, grad_norm: 6.3854
2025-08-05 15:14:50,356 - mmdet - INFO - Epoch [2][750/4665]	lr: 5.000e-03, eta: 1:12:36, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2275, acc: 92.6621, loss_bbox: 0.2700, loss: 0.4975, grad_norm: 6.9088
2025-08-05 15:15:06,635 - mmdet - INFO - Epoch [2][800/4665]	lr: 5.000e-03, eta: 1:12:19, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2539, acc: 91.4492, loss_bbox: 0.2992, loss: 0.5531, grad_norm: 7.1025
2025-08-05 15:15:22,911 - mmdet - INFO - Epoch [2][850/4665]	lr: 5.000e-03, eta: 1:12:02, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2152, acc: 92.4766, loss_bbox: 0.2470, loss: 0.4622, grad_norm: 6.5867
2025-08-05 15:15:38,979 - mmdet - INFO - Epoch [2][900/4665]	lr: 5.000e-03, eta: 1:11:45, time: 0.321, data_time: 0.006, memory: 12189, loss_cls: 0.2426, acc: 92.7266, loss_bbox: 0.2411, loss: 0.4837, grad_norm: 7.3917
2025-08-05 15:15:55,337 - mmdet - INFO - Epoch [2][950/4665]	lr: 5.000e-03, eta: 1:11:28, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2953, acc: 90.6191, loss_bbox: 0.3216, loss: 0.6170, grad_norm: 7.0662
2025-08-05 15:16:11,667 - mmdet - INFO - Epoch [2][1000/4665]	lr: 5.000e-03, eta: 1:11:11, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2277, acc: 92.2949, loss_bbox: 0.2668, loss: 0.4946, grad_norm: 6.1510
2025-08-05 15:16:27,966 - mmdet - INFO - Epoch [2][1050/4665]	lr: 5.000e-03, eta: 1:10:55, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1943, acc: 93.5781, loss_bbox: 0.2159, loss: 0.4103, grad_norm: 5.8341
2025-08-05 15:16:44,209 - mmdet - INFO - Epoch [2][1100/4665]	lr: 5.000e-03, eta: 1:10:38, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2055, acc: 93.1133, loss_bbox: 0.2526, loss: 0.4581, grad_norm: 6.2676
2025-08-05 15:17:00,402 - mmdet - INFO - Epoch [2][1150/4665]	lr: 5.000e-03, eta: 1:10:21, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1996, acc: 93.4219, loss_bbox: 0.2504, loss: 0.4500, grad_norm: 5.6113
2025-08-05 15:17:16,592 - mmdet - INFO - Epoch [2][1200/4665]	lr: 5.000e-03, eta: 1:10:04, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1861, acc: 93.7559, loss_bbox: 0.2261, loss: 0.4122, grad_norm: 6.0147
2025-08-05 15:17:32,874 - mmdet - INFO - Epoch [2][1250/4665]	lr: 5.000e-03, eta: 1:09:47, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2367, acc: 92.0352, loss_bbox: 0.2911, loss: 0.5277, grad_norm: 6.6644
2025-08-05 15:17:49,178 - mmdet - INFO - Epoch [2][1300/4665]	lr: 5.000e-03, eta: 1:09:30, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2159, acc: 92.4062, loss_bbox: 0.2580, loss: 0.4739, grad_norm: 6.1139
2025-08-05 15:18:05,401 - mmdet - INFO - Epoch [2][1350/4665]	lr: 5.000e-03, eta: 1:09:13, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2145, acc: 93.3086, loss_bbox: 0.2348, loss: 0.4494, grad_norm: 5.7756
2025-08-05 15:18:21,469 - mmdet - INFO - Epoch [2][1400/4665]	lr: 5.000e-03, eta: 1:08:56, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2132, acc: 92.8574, loss_bbox: 0.2703, loss: 0.4835, grad_norm: 6.1096
2025-08-05 15:18:37,650 - mmdet - INFO - Epoch [2][1450/4665]	lr: 5.000e-03, eta: 1:08:39, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2214, acc: 92.6113, loss_bbox: 0.2743, loss: 0.4958, grad_norm: 6.5405
2025-08-05 15:18:53,771 - mmdet - INFO - Epoch [2][1500/4665]	lr: 5.000e-03, eta: 1:08:22, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2277, acc: 92.6699, loss_bbox: 0.2540, loss: 0.4817, grad_norm: 6.4430
2025-08-05 15:19:10,087 - mmdet - INFO - Epoch [2][1550/4665]	lr: 5.000e-03, eta: 1:08:06, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2121, acc: 93.0156, loss_bbox: 0.2670, loss: 0.4791, grad_norm: 5.7697
2025-08-05 15:19:26,309 - mmdet - INFO - Epoch [2][1600/4665]	lr: 5.000e-03, eta: 1:07:49, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2598, acc: 91.4141, loss_bbox: 0.2964, loss: 0.5562, grad_norm: 6.9860
2025-08-05 15:19:42,482 - mmdet - INFO - Epoch [2][1650/4665]	lr: 5.000e-03, eta: 1:07:32, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2313, acc: 92.6289, loss_bbox: 0.2604, loss: 0.4917, grad_norm: 6.1884
2025-08-05 15:19:58,657 - mmdet - INFO - Epoch [2][1700/4665]	lr: 5.000e-03, eta: 1:07:15, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2283, acc: 92.4434, loss_bbox: 0.2568, loss: 0.4851, grad_norm: 6.7386
2025-08-05 15:20:14,748 - mmdet - INFO - Epoch [2][1750/4665]	lr: 5.000e-03, eta: 1:06:58, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2109, acc: 92.5781, loss_bbox: 0.2639, loss: 0.4748, grad_norm: 6.0502
2025-08-05 15:20:30,955 - mmdet - INFO - Epoch [2][1800/4665]	lr: 5.000e-03, eta: 1:06:41, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1927, acc: 93.3535, loss_bbox: 0.2416, loss: 0.4343, grad_norm: 6.1759
2025-08-05 15:20:47,261 - mmdet - INFO - Epoch [2][1850/4665]	lr: 5.000e-03, eta: 1:06:25, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2369, acc: 91.8535, loss_bbox: 0.2919, loss: 0.5288, grad_norm: 6.6331
2025-08-05 15:21:03,382 - mmdet - INFO - Epoch [2][1900/4665]	lr: 5.000e-03, eta: 1:06:08, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2148, acc: 92.8086, loss_bbox: 0.2626, loss: 0.4774, grad_norm: 6.0418
2025-08-05 15:21:19,598 - mmdet - INFO - Epoch [2][1950/4665]	lr: 5.000e-03, eta: 1:05:51, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2254, acc: 92.2461, loss_bbox: 0.2726, loss: 0.4979, grad_norm: 6.5197
2025-08-05 15:21:35,869 - mmdet - INFO - Epoch [2][2000/4665]	lr: 5.000e-03, eta: 1:05:34, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2078, acc: 93.2715, loss_bbox: 0.2454, loss: 0.4532, grad_norm: 5.8321
2025-08-05 15:21:52,127 - mmdet - INFO - Epoch [2][2050/4665]	lr: 5.000e-03, eta: 1:05:18, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1959, acc: 93.3652, loss_bbox: 0.2350, loss: 0.4308, grad_norm: 6.1287
2025-08-05 15:22:08,324 - mmdet - INFO - Epoch [2][2100/4665]	lr: 5.000e-03, eta: 1:05:01, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2353, acc: 91.8848, loss_bbox: 0.2524, loss: 0.4877, grad_norm: 6.4380
2025-08-05 15:22:24,610 - mmdet - INFO - Epoch [2][2150/4665]	lr: 5.000e-03, eta: 1:04:44, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2375, acc: 92.4609, loss_bbox: 0.2485, loss: 0.4860, grad_norm: 6.9322
2025-08-05 15:22:40,882 - mmdet - INFO - Epoch [2][2200/4665]	lr: 5.000e-03, eta: 1:04:28, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2053, acc: 93.2402, loss_bbox: 0.2343, loss: 0.4396, grad_norm: 6.0893
2025-08-05 15:22:57,217 - mmdet - INFO - Epoch [2][2250/4665]	lr: 5.000e-03, eta: 1:04:11, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2235, acc: 92.5000, loss_bbox: 0.2591, loss: 0.4826, grad_norm: 6.4707
2025-08-05 15:23:13,375 - mmdet - INFO - Epoch [2][2300/4665]	lr: 5.000e-03, eta: 1:03:54, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2472, acc: 92.0430, loss_bbox: 0.2841, loss: 0.5313, grad_norm: 6.1758
2025-08-05 15:23:29,551 - mmdet - INFO - Epoch [2][2350/4665]	lr: 5.000e-03, eta: 1:03:38, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2094, acc: 92.7324, loss_bbox: 0.2559, loss: 0.4653, grad_norm: 5.6984
2025-08-05 15:23:45,803 - mmdet - INFO - Epoch [2][2400/4665]	lr: 5.000e-03, eta: 1:03:21, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2092, acc: 92.5410, loss_bbox: 0.2706, loss: 0.4798, grad_norm: 6.1098
2025-08-05 15:24:02,007 - mmdet - INFO - Epoch [2][2450/4665]	lr: 5.000e-03, eta: 1:03:04, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2108, acc: 92.2344, loss_bbox: 0.2702, loss: 0.4810, grad_norm: 6.0359
2025-08-05 15:24:18,425 - mmdet - INFO - Epoch [2][2500/4665]	lr: 5.000e-03, eta: 1:02:48, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2298, acc: 92.2910, loss_bbox: 0.2725, loss: 0.5024, grad_norm: 6.7082
2025-08-05 15:24:34,731 - mmdet - INFO - Epoch [2][2550/4665]	lr: 5.000e-03, eta: 1:02:31, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2214, acc: 92.6328, loss_bbox: 0.2533, loss: 0.4747, grad_norm: 6.5994
2025-08-05 15:24:50,902 - mmdet - INFO - Epoch [2][2600/4665]	lr: 5.000e-03, eta: 1:02:15, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2139, acc: 92.4824, loss_bbox: 0.2494, loss: 0.4633, grad_norm: 6.6148
2025-08-05 15:25:07,120 - mmdet - INFO - Epoch [2][2650/4665]	lr: 5.000e-03, eta: 1:01:58, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2326, acc: 92.5957, loss_bbox: 0.2613, loss: 0.4938, grad_norm: 6.4571
2025-08-05 15:25:23,374 - mmdet - INFO - Epoch [2][2700/4665]	lr: 5.000e-03, eta: 1:01:42, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2284, acc: 92.6152, loss_bbox: 0.2605, loss: 0.4889, grad_norm: 6.2047
2025-08-05 15:25:39,482 - mmdet - INFO - Epoch [2][2750/4665]	lr: 5.000e-03, eta: 1:01:25, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2115, acc: 92.9375, loss_bbox: 0.2541, loss: 0.4656, grad_norm: 6.1183
2025-08-05 15:25:55,536 - mmdet - INFO - Epoch [2][2800/4665]	lr: 5.000e-03, eta: 1:01:08, time: 0.321, data_time: 0.006, memory: 12189, loss_cls: 0.2240, acc: 92.5781, loss_bbox: 0.2736, loss: 0.4975, grad_norm: 6.1151
2025-08-05 15:26:11,774 - mmdet - INFO - Epoch [2][2850/4665]	lr: 5.000e-03, eta: 1:00:51, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2209, acc: 92.1387, loss_bbox: 0.2845, loss: 0.5053, grad_norm: 6.1704
2025-08-05 15:26:27,895 - mmdet - INFO - Epoch [2][2900/4665]	lr: 5.000e-03, eta: 1:00:34, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2616, acc: 91.2109, loss_bbox: 0.3047, loss: 0.5663, grad_norm: 7.2235
2025-08-05 15:26:44,097 - mmdet - INFO - Epoch [2][2950/4665]	lr: 5.000e-03, eta: 1:00:18, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2222, acc: 92.5762, loss_bbox: 0.2438, loss: 0.4660, grad_norm: 6.8971
2025-08-05 15:27:00,346 - mmdet - INFO - Epoch [2][3000/4665]	lr: 5.000e-03, eta: 1:00:01, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2086, acc: 92.7285, loss_bbox: 0.2556, loss: 0.4641, grad_norm: 6.2843
2025-08-05 15:27:16,543 - mmdet - INFO - Epoch [2][3050/4665]	lr: 5.000e-03, eta: 0:59:45, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2078, acc: 92.7207, loss_bbox: 0.2499, loss: 0.4576, grad_norm: 6.3739
2025-08-05 15:27:32,743 - mmdet - INFO - Epoch [2][3100/4665]	lr: 5.000e-03, eta: 0:59:28, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2293, acc: 92.0137, loss_bbox: 0.2742, loss: 0.5035, grad_norm: 6.2796
2025-08-05 15:27:48,877 - mmdet - INFO - Epoch [2][3150/4665]	lr: 5.000e-03, eta: 0:59:11, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2142, acc: 92.5176, loss_bbox: 0.2446, loss: 0.4587, grad_norm: 6.4753
2025-08-05 15:28:05,076 - mmdet - INFO - Epoch [2][3200/4665]	lr: 5.000e-03, eta: 0:58:55, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2272, acc: 92.6133, loss_bbox: 0.2644, loss: 0.4915, grad_norm: 6.3593
2025-08-05 15:28:21,283 - mmdet - INFO - Epoch [2][3250/4665]	lr: 5.000e-03, eta: 0:58:38, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1989, acc: 92.9766, loss_bbox: 0.2451, loss: 0.4440, grad_norm: 5.6405
2025-08-05 15:28:37,402 - mmdet - INFO - Epoch [2][3300/4665]	lr: 5.000e-03, eta: 0:58:21, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2313, acc: 92.3047, loss_bbox: 0.2809, loss: 0.5122, grad_norm: 7.0756
2025-08-05 15:28:53,597 - mmdet - INFO - Epoch [2][3350/4665]	lr: 5.000e-03, eta: 0:58:05, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2131, acc: 93.4023, loss_bbox: 0.2223, loss: 0.4354, grad_norm: 6.1256
2025-08-05 15:29:09,808 - mmdet - INFO - Epoch [2][3400/4665]	lr: 5.000e-03, eta: 0:57:48, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2391, acc: 92.2773, loss_bbox: 0.2793, loss: 0.5184, grad_norm: 6.4921
2025-08-05 15:29:26,079 - mmdet - INFO - Epoch [2][3450/4665]	lr: 5.000e-03, eta: 0:57:32, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2391, acc: 92.4492, loss_bbox: 0.2719, loss: 0.5110, grad_norm: 6.8992
2025-08-05 15:29:42,320 - mmdet - INFO - Epoch [2][3500/4665]	lr: 5.000e-03, eta: 0:57:15, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2401, acc: 92.1719, loss_bbox: 0.2585, loss: 0.4986, grad_norm: 6.7704
2025-08-05 15:29:58,700 - mmdet - INFO - Epoch [2][3550/4665]	lr: 5.000e-03, eta: 0:56:59, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2312, acc: 92.0312, loss_bbox: 0.2759, loss: 0.5071, grad_norm: 6.1073
2025-08-05 15:30:14,958 - mmdet - INFO - Epoch [2][3600/4665]	lr: 5.000e-03, eta: 0:56:42, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2140, acc: 92.7129, loss_bbox: 0.2549, loss: 0.4688, grad_norm: 5.9440
2025-08-05 15:30:31,259 - mmdet - INFO - Epoch [2][3650/4665]	lr: 5.000e-03, eta: 0:56:26, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2305, acc: 92.7734, loss_bbox: 0.2490, loss: 0.4795, grad_norm: 6.3750
2025-08-05 15:30:47,461 - mmdet - INFO - Epoch [2][3700/4665]	lr: 5.000e-03, eta: 0:56:09, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2143, acc: 93.0469, loss_bbox: 0.2467, loss: 0.4610, grad_norm: 5.9228
2025-08-05 15:31:03,609 - mmdet - INFO - Epoch [2][3750/4665]	lr: 5.000e-03, eta: 0:55:53, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2168, acc: 92.5156, loss_bbox: 0.2604, loss: 0.4772, grad_norm: 6.5768
2025-08-05 15:31:19,780 - mmdet - INFO - Epoch [2][3800/4665]	lr: 5.000e-03, eta: 0:55:36, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2332, acc: 92.5703, loss_bbox: 0.2526, loss: 0.4857, grad_norm: 6.7551
2025-08-05 15:31:36,062 - mmdet - INFO - Epoch [2][3850/4665]	lr: 5.000e-03, eta: 0:55:20, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2007, acc: 93.0801, loss_bbox: 0.2531, loss: 0.4538, grad_norm: 6.2909
2025-08-05 15:31:52,216 - mmdet - INFO - Epoch [2][3900/4665]	lr: 5.000e-03, eta: 0:55:03, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2057, acc: 93.0820, loss_bbox: 0.2532, loss: 0.4589, grad_norm: 6.0129
2025-08-05 15:32:08,444 - mmdet - INFO - Epoch [2][3950/4665]	lr: 5.000e-03, eta: 0:54:46, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2253, acc: 92.4668, loss_bbox: 0.2677, loss: 0.4930, grad_norm: 6.5834
2025-08-05 15:32:24,474 - mmdet - INFO - Epoch [2][4000/4665]	lr: 5.000e-03, eta: 0:54:30, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2205, acc: 92.5215, loss_bbox: 0.2570, loss: 0.4775, grad_norm: 6.2894
2025-08-05 15:32:40,702 - mmdet - INFO - Epoch [2][4050/4665]	lr: 5.000e-03, eta: 0:54:13, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2061, acc: 92.6797, loss_bbox: 0.2615, loss: 0.4676, grad_norm: 5.6778
2025-08-05 15:32:56,824 - mmdet - INFO - Epoch [2][4100/4665]	lr: 5.000e-03, eta: 0:53:57, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.1978, acc: 93.4238, loss_bbox: 0.2315, loss: 0.4292, grad_norm: 5.6673
2025-08-05 15:33:13,020 - mmdet - INFO - Epoch [2][4150/4665]	lr: 5.000e-03, eta: 0:53:40, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2558, acc: 91.7500, loss_bbox: 0.3002, loss: 0.5561, grad_norm: 6.2719
2025-08-05 15:33:29,261 - mmdet - INFO - Epoch [2][4200/4665]	lr: 5.000e-03, eta: 0:53:24, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1951, acc: 92.9043, loss_bbox: 0.2346, loss: 0.4297, grad_norm: 6.0878
2025-08-05 15:33:45,524 - mmdet - INFO - Epoch [2][4250/4665]	lr: 5.000e-03, eta: 0:53:07, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2138, acc: 92.6055, loss_bbox: 0.2505, loss: 0.4643, grad_norm: 6.4017
2025-08-05 15:34:01,670 - mmdet - INFO - Epoch [2][4300/4665]	lr: 5.000e-03, eta: 0:52:50, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2315, acc: 92.0215, loss_bbox: 0.2634, loss: 0.4949, grad_norm: 6.7601
2025-08-05 15:34:17,957 - mmdet - INFO - Epoch [2][4350/4665]	lr: 5.000e-03, eta: 0:52:34, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2122, acc: 92.8281, loss_bbox: 0.2517, loss: 0.4640, grad_norm: 6.6378
2025-08-05 15:34:34,222 - mmdet - INFO - Epoch [2][4400/4665]	lr: 5.000e-03, eta: 0:52:18, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2329, acc: 92.6113, loss_bbox: 0.2701, loss: 0.5031, grad_norm: 6.7337
2025-08-05 15:34:50,596 - mmdet - INFO - Epoch [2][4450/4665]	lr: 5.000e-03, eta: 0:52:01, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2249, acc: 92.3965, loss_bbox: 0.2637, loss: 0.4886, grad_norm: 6.3358
2025-08-05 15:35:06,809 - mmdet - INFO - Epoch [2][4500/4665]	lr: 5.000e-03, eta: 0:51:45, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2117, acc: 93.0332, loss_bbox: 0.2621, loss: 0.4737, grad_norm: 5.9748
2025-08-05 15:35:23,100 - mmdet - INFO - Epoch [2][4550/4665]	lr: 5.000e-03, eta: 0:51:28, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2417, acc: 91.8867, loss_bbox: 0.2752, loss: 0.5169, grad_norm: 6.6699
2025-08-05 15:35:39,357 - mmdet - INFO - Epoch [2][4600/4665]	lr: 5.000e-03, eta: 0:51:12, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2137, acc: 93.0723, loss_bbox: 0.2683, loss: 0.4821, grad_norm: 6.0801
2025-08-05 15:35:55,501 - mmdet - INFO - Epoch [2][4650/4665]	lr: 5.000e-03, eta: 0:50:55, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2158, acc: 92.7363, loss_bbox: 0.2614, loss: 0.4772, grad_norm: 5.9015
2025-08-05 15:36:01,250 - mmdet - INFO - Saving checkpoint at 2 epochs
2025-08-05 15:38:44,170 - mmdet - INFO - Evaluating bbox...
2025-08-05 15:38:53,118 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 15:38:53,119 - mmdet - INFO - Epoch(val) [2][850]	bbox_mAP: 0.0630, bbox_mAP_50: 0.1700, bbox_mAP_75: 0.0350, bbox_mAP_s: 0.0160, bbox_mAP_m: 0.0510, bbox_mAP_l: 0.1370, bbox_mAP_copypaste: 0.063 0.170 0.035 0.016 0.051 0.137
2025-08-05 15:39:24,496 - mmdet - INFO - Epoch [3][50/4665]	lr: 5.000e-03, eta: 0:50:44, time: 0.627, data_time: 0.309, memory: 12189, loss_cls: 0.1988, acc: 93.0762, loss_bbox: 0.2410, loss: 0.4398, grad_norm: 5.9400
2025-08-05 15:39:40,694 - mmdet - INFO - Epoch [3][100/4665]	lr: 5.000e-03, eta: 0:50:27, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1940, acc: 92.8301, loss_bbox: 0.2393, loss: 0.4333, grad_norm: 5.8944
2025-08-05 15:39:56,938 - mmdet - INFO - Epoch [3][150/4665]	lr: 5.000e-03, eta: 0:50:11, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2156, acc: 92.1621, loss_bbox: 0.2701, loss: 0.4857, grad_norm: 6.6566
2025-08-05 15:40:13,235 - mmdet - INFO - Epoch [3][200/4665]	lr: 5.000e-03, eta: 0:49:54, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1981, acc: 92.9688, loss_bbox: 0.2316, loss: 0.4298, grad_norm: 6.1999
2025-08-05 15:40:29,747 - mmdet - INFO - Epoch [3][250/4665]	lr: 5.000e-03, eta: 0:49:38, time: 0.330, data_time: 0.006, memory: 12189, loss_cls: 0.2083, acc: 92.8184, loss_bbox: 0.2525, loss: 0.4608, grad_norm: 6.3419
2025-08-05 15:40:46,035 - mmdet - INFO - Epoch [3][300/4665]	lr: 5.000e-03, eta: 0:49:22, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1837, acc: 93.2617, loss_bbox: 0.2380, loss: 0.4217, grad_norm: 5.8040
2025-08-05 15:41:02,298 - mmdet - INFO - Epoch [3][350/4665]	lr: 5.000e-03, eta: 0:49:05, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1656, acc: 94.0801, loss_bbox: 0.2068, loss: 0.3724, grad_norm: 5.4504
2025-08-05 15:41:18,528 - mmdet - INFO - Epoch [3][400/4665]	lr: 5.000e-03, eta: 0:48:49, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1882, acc: 93.5625, loss_bbox: 0.2282, loss: 0.4164, grad_norm: 5.9305
2025-08-05 15:41:34,868 - mmdet - INFO - Epoch [3][450/4665]	lr: 5.000e-03, eta: 0:48:32, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1892, acc: 93.4805, loss_bbox: 0.2359, loss: 0.4251, grad_norm: 5.8559
2025-08-05 15:41:51,084 - mmdet - INFO - Epoch [3][500/4665]	lr: 5.000e-03, eta: 0:48:16, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1906, acc: 93.4824, loss_bbox: 0.2277, loss: 0.4182, grad_norm: 5.8895
2025-08-05 15:42:07,233 - mmdet - INFO - Epoch [3][550/4665]	lr: 5.000e-03, eta: 0:47:59, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2307, acc: 91.9668, loss_bbox: 0.2881, loss: 0.5188, grad_norm: 6.6721
2025-08-05 15:42:23,384 - mmdet - INFO - Epoch [3][600/4665]	lr: 5.000e-03, eta: 0:47:42, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1910, acc: 92.9375, loss_bbox: 0.2507, loss: 0.4417, grad_norm: 6.0475
2025-08-05 15:42:39,671 - mmdet - INFO - Epoch [3][650/4665]	lr: 5.000e-03, eta: 0:47:26, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2004, acc: 92.9258, loss_bbox: 0.2697, loss: 0.4701, grad_norm: 6.2919
2025-08-05 15:42:55,903 - mmdet - INFO - Epoch [3][700/4665]	lr: 5.000e-03, eta: 0:47:09, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1994, acc: 92.9219, loss_bbox: 0.2536, loss: 0.4530, grad_norm: 6.1848
2025-08-05 15:43:12,245 - mmdet - INFO - Epoch [3][750/4665]	lr: 5.000e-03, eta: 0:46:53, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2183, acc: 92.2246, loss_bbox: 0.2628, loss: 0.4811, grad_norm: 6.7803
2025-08-05 15:43:28,463 - mmdet - INFO - Epoch [3][800/4665]	lr: 5.000e-03, eta: 0:46:36, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1982, acc: 93.0020, loss_bbox: 0.2755, loss: 0.4737, grad_norm: 6.7081
2025-08-05 15:43:44,694 - mmdet - INFO - Epoch [3][850/4665]	lr: 5.000e-03, eta: 0:46:20, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2343, acc: 91.7090, loss_bbox: 0.2699, loss: 0.5042, grad_norm: 6.7221
2025-08-05 15:44:01,034 - mmdet - INFO - Epoch [3][900/4665]	lr: 5.000e-03, eta: 0:46:03, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2025, acc: 92.9922, loss_bbox: 0.2447, loss: 0.4472, grad_norm: 6.0247
2025-08-05 15:44:17,260 - mmdet - INFO - Epoch [3][950/4665]	lr: 5.000e-03, eta: 0:45:47, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2350, acc: 92.2910, loss_bbox: 0.2720, loss: 0.5069, grad_norm: 6.7855
2025-08-05 15:44:33,557 - mmdet - INFO - Epoch [3][1000/4665]	lr: 5.000e-03, eta: 0:45:30, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1971, acc: 93.0742, loss_bbox: 0.2411, loss: 0.4382, grad_norm: 5.8430
2025-08-05 15:44:49,841 - mmdet - INFO - Epoch [3][1050/4665]	lr: 5.000e-03, eta: 0:45:14, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1785, acc: 93.4434, loss_bbox: 0.2362, loss: 0.4147, grad_norm: 6.0154
2025-08-05 15:45:06,108 - mmdet - INFO - Epoch [3][1100/4665]	lr: 5.000e-03, eta: 0:44:57, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1815, acc: 93.5996, loss_bbox: 0.2169, loss: 0.3984, grad_norm: 5.4833
2025-08-05 15:45:22,234 - mmdet - INFO - Epoch [3][1150/4665]	lr: 5.000e-03, eta: 0:44:41, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1977, acc: 92.9082, loss_bbox: 0.2505, loss: 0.4482, grad_norm: 5.6173
2025-08-05 15:45:38,505 - mmdet - INFO - Epoch [3][1200/4665]	lr: 5.000e-03, eta: 0:44:24, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2186, acc: 93.0117, loss_bbox: 0.2620, loss: 0.4806, grad_norm: 6.5218
2025-08-05 15:45:54,795 - mmdet - INFO - Epoch [3][1250/4665]	lr: 5.000e-03, eta: 0:44:08, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2055, acc: 92.6699, loss_bbox: 0.2549, loss: 0.4605, grad_norm: 6.7106
2025-08-05 15:46:11,040 - mmdet - INFO - Epoch [3][1300/4665]	lr: 5.000e-03, eta: 0:43:51, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2215, acc: 92.2871, loss_bbox: 0.2748, loss: 0.4963, grad_norm: 6.9359
2025-08-05 15:46:27,209 - mmdet - INFO - Epoch [3][1350/4665]	lr: 5.000e-03, eta: 0:43:35, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1923, acc: 92.9180, loss_bbox: 0.2377, loss: 0.4300, grad_norm: 5.6891
2025-08-05 15:46:43,393 - mmdet - INFO - Epoch [3][1400/4665]	lr: 5.000e-03, eta: 0:43:18, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1907, acc: 93.2773, loss_bbox: 0.2516, loss: 0.4423, grad_norm: 6.2079
2025-08-05 15:46:59,543 - mmdet - INFO - Epoch [3][1450/4665]	lr: 5.000e-03, eta: 0:43:02, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2117, acc: 92.4844, loss_bbox: 0.2640, loss: 0.4757, grad_norm: 6.7484
2025-08-05 15:47:15,801 - mmdet - INFO - Epoch [3][1500/4665]	lr: 5.000e-03, eta: 0:42:45, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1843, acc: 93.3691, loss_bbox: 0.2397, loss: 0.4241, grad_norm: 6.1585
2025-08-05 15:47:31,987 - mmdet - INFO - Epoch [3][1550/4665]	lr: 5.000e-03, eta: 0:42:29, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2130, acc: 92.4863, loss_bbox: 0.2452, loss: 0.4582, grad_norm: 6.2860
2025-08-05 15:47:48,146 - mmdet - INFO - Epoch [3][1600/4665]	lr: 5.000e-03, eta: 0:42:12, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1883, acc: 93.2344, loss_bbox: 0.2276, loss: 0.4159, grad_norm: 5.7159
2025-08-05 15:48:04,381 - mmdet - INFO - Epoch [3][1650/4665]	lr: 5.000e-03, eta: 0:41:56, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1715, acc: 93.9766, loss_bbox: 0.2162, loss: 0.3877, grad_norm: 5.9587
2025-08-05 15:48:20,633 - mmdet - INFO - Epoch [3][1700/4665]	lr: 5.000e-03, eta: 0:41:39, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2151, acc: 92.7422, loss_bbox: 0.2489, loss: 0.4640, grad_norm: 6.4728
2025-08-05 15:48:36,907 - mmdet - INFO - Epoch [3][1750/4665]	lr: 5.000e-03, eta: 0:41:23, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1878, acc: 93.2422, loss_bbox: 0.2410, loss: 0.4288, grad_norm: 5.7816
2025-08-05 15:48:53,176 - mmdet - INFO - Epoch [3][1800/4665]	lr: 5.000e-03, eta: 0:41:06, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1911, acc: 93.3418, loss_bbox: 0.2304, loss: 0.4214, grad_norm: 6.0281
2025-08-05 15:49:09,519 - mmdet - INFO - Epoch [3][1850/4665]	lr: 5.000e-03, eta: 0:40:50, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2257, acc: 92.3984, loss_bbox: 0.2573, loss: 0.4830, grad_norm: 7.1336
2025-08-05 15:49:25,854 - mmdet - INFO - Epoch [3][1900/4665]	lr: 5.000e-03, eta: 0:40:33, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2270, acc: 92.4766, loss_bbox: 0.2460, loss: 0.4730, grad_norm: 6.5509
2025-08-05 15:49:42,113 - mmdet - INFO - Epoch [3][1950/4665]	lr: 5.000e-03, eta: 0:40:17, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2011, acc: 92.9434, loss_bbox: 0.2433, loss: 0.4444, grad_norm: 5.9684
2025-08-05 15:49:58,289 - mmdet - INFO - Epoch [3][2000/4665]	lr: 5.000e-03, eta: 0:40:00, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2089, acc: 92.8965, loss_bbox: 0.2366, loss: 0.4455, grad_norm: 6.3233
2025-08-05 15:50:14,386 - mmdet - INFO - Epoch [3][2050/4665]	lr: 5.000e-03, eta: 0:39:44, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2073, acc: 92.6270, loss_bbox: 0.2485, loss: 0.4558, grad_norm: 6.2951
2025-08-05 15:50:30,460 - mmdet - INFO - Epoch [3][2100/4665]	lr: 5.000e-03, eta: 0:39:27, time: 0.321, data_time: 0.006, memory: 12189, loss_cls: 0.2072, acc: 92.5332, loss_bbox: 0.2588, loss: 0.4660, grad_norm: 6.6443
2025-08-05 15:50:46,749 - mmdet - INFO - Epoch [3][2150/4665]	lr: 5.000e-03, eta: 0:39:11, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2150, acc: 92.4746, loss_bbox: 0.2702, loss: 0.4852, grad_norm: 6.7804
2025-08-05 15:51:02,857 - mmdet - INFO - Epoch [3][2200/4665]	lr: 5.000e-03, eta: 0:38:54, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.1875, acc: 93.8672, loss_bbox: 0.2240, loss: 0.4115, grad_norm: 6.3301
2025-08-05 15:51:19,107 - mmdet - INFO - Epoch [3][2250/4665]	lr: 5.000e-03, eta: 0:38:38, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1909, acc: 93.2480, loss_bbox: 0.2315, loss: 0.4225, grad_norm: 6.1423
2025-08-05 15:51:35,245 - mmdet - INFO - Epoch [3][2300/4665]	lr: 5.000e-03, eta: 0:38:21, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1980, acc: 93.0410, loss_bbox: 0.2312, loss: 0.4292, grad_norm: 6.1855
2025-08-05 15:51:51,644 - mmdet - INFO - Epoch [3][2350/4665]	lr: 5.000e-03, eta: 0:38:05, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2013, acc: 92.5020, loss_bbox: 0.2418, loss: 0.4431, grad_norm: 6.5047
2025-08-05 15:52:07,657 - mmdet - INFO - Epoch [3][2400/4665]	lr: 5.000e-03, eta: 0:37:48, time: 0.320, data_time: 0.005, memory: 12189, loss_cls: 0.2082, acc: 92.6055, loss_bbox: 0.2444, loss: 0.4526, grad_norm: 6.1515
2025-08-05 15:52:23,852 - mmdet - INFO - Epoch [3][2450/4665]	lr: 5.000e-03, eta: 0:37:32, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2012, acc: 93.0625, loss_bbox: 0.2321, loss: 0.4333, grad_norm: 6.1632
2025-08-05 15:52:40,236 - mmdet - INFO - Epoch [3][2500/4665]	lr: 5.000e-03, eta: 0:37:16, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.1940, acc: 93.1660, loss_bbox: 0.2447, loss: 0.4387, grad_norm: 6.5805
2025-08-05 15:52:56,447 - mmdet - INFO - Epoch [3][2550/4665]	lr: 5.000e-03, eta: 0:36:59, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2189, acc: 92.0039, loss_bbox: 0.2591, loss: 0.4780, grad_norm: 6.8289
2025-08-05 15:53:12,629 - mmdet - INFO - Epoch [3][2600/4665]	lr: 5.000e-03, eta: 0:36:43, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1879, acc: 93.2949, loss_bbox: 0.2296, loss: 0.4174, grad_norm: 6.2404
2025-08-05 15:53:28,787 - mmdet - INFO - Epoch [3][2650/4665]	lr: 5.000e-03, eta: 0:36:26, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2018, acc: 93.2773, loss_bbox: 0.2397, loss: 0.4415, grad_norm: 6.8314
2025-08-05 15:53:45,108 - mmdet - INFO - Epoch [3][2700/4665]	lr: 5.000e-03, eta: 0:36:10, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2114, acc: 92.8477, loss_bbox: 0.2185, loss: 0.4299, grad_norm: 7.3207
2025-08-05 15:54:01,208 - mmdet - INFO - Epoch [3][2750/4665]	lr: 5.000e-03, eta: 0:35:53, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.1949, acc: 93.3516, loss_bbox: 0.2283, loss: 0.4231, grad_norm: 6.2295
2025-08-05 15:54:17,397 - mmdet - INFO - Epoch [3][2800/4665]	lr: 5.000e-03, eta: 0:35:37, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1884, acc: 93.2148, loss_bbox: 0.2401, loss: 0.4285, grad_norm: 6.3196
2025-08-05 15:54:33,548 - mmdet - INFO - Epoch [3][2850/4665]	lr: 5.000e-03, eta: 0:35:20, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1935, acc: 93.0410, loss_bbox: 0.2514, loss: 0.4449, grad_norm: 6.3074
2025-08-05 15:54:49,748 - mmdet - INFO - Epoch [3][2900/4665]	lr: 5.000e-03, eta: 0:35:04, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2064, acc: 93.0039, loss_bbox: 0.2531, loss: 0.4596, grad_norm: 6.6069
2025-08-05 15:55:05,962 - mmdet - INFO - Epoch [3][2950/4665]	lr: 5.000e-03, eta: 0:34:47, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1921, acc: 92.8711, loss_bbox: 0.2312, loss: 0.4233, grad_norm: 6.2989
2025-08-05 15:55:22,127 - mmdet - INFO - Epoch [3][3000/4665]	lr: 5.000e-03, eta: 0:34:31, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1941, acc: 93.2480, loss_bbox: 0.2227, loss: 0.4169, grad_norm: 6.4968
2025-08-05 15:55:38,323 - mmdet - INFO - Epoch [3][3050/4665]	lr: 5.000e-03, eta: 0:34:15, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2351, acc: 92.3984, loss_bbox: 0.2376, loss: 0.4728, grad_norm: 6.9571
2025-08-05 15:55:54,665 - mmdet - INFO - Epoch [3][3100/4665]	lr: 5.000e-03, eta: 0:33:58, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2314, acc: 91.8281, loss_bbox: 0.2538, loss: 0.4852, grad_norm: 6.9882
2025-08-05 15:56:10,886 - mmdet - INFO - Epoch [3][3150/4665]	lr: 5.000e-03, eta: 0:33:42, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2219, acc: 92.4668, loss_bbox: 0.2553, loss: 0.4772, grad_norm: 6.8762
2025-08-05 15:56:27,162 - mmdet - INFO - Epoch [3][3200/4665]	lr: 5.000e-03, eta: 0:33:25, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2200, acc: 92.5957, loss_bbox: 0.2399, loss: 0.4598, grad_norm: 6.3254
2025-08-05 15:56:43,440 - mmdet - INFO - Epoch [3][3250/4665]	lr: 5.000e-03, eta: 0:33:09, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1876, acc: 93.5332, loss_bbox: 0.2028, loss: 0.3904, grad_norm: 5.5530
2025-08-05 15:56:59,526 - mmdet - INFO - Epoch [3][3300/4665]	lr: 5.000e-03, eta: 0:32:52, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.1939, acc: 93.1816, loss_bbox: 0.2444, loss: 0.4383, grad_norm: 6.2233
2025-08-05 15:57:15,918 - mmdet - INFO - Epoch [3][3350/4665]	lr: 5.000e-03, eta: 0:32:36, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.2104, acc: 92.4023, loss_bbox: 0.2497, loss: 0.4601, grad_norm: 6.7452
2025-08-05 15:57:32,187 - mmdet - INFO - Epoch [3][3400/4665]	lr: 5.000e-03, eta: 0:32:20, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2001, acc: 92.2910, loss_bbox: 0.2587, loss: 0.4588, grad_norm: 6.7165
2025-08-05 15:57:48,323 - mmdet - INFO - Epoch [3][3450/4665]	lr: 5.000e-03, eta: 0:32:03, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1852, acc: 93.6973, loss_bbox: 0.2231, loss: 0.4083, grad_norm: 5.8534
2025-08-05 15:58:04,397 - mmdet - INFO - Epoch [3][3500/4665]	lr: 5.000e-03, eta: 0:31:47, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.2185, acc: 92.4004, loss_bbox: 0.2518, loss: 0.4703, grad_norm: 6.4766
2025-08-05 15:58:20,651 - mmdet - INFO - Epoch [3][3550/4665]	lr: 5.000e-03, eta: 0:31:30, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2052, acc: 93.2363, loss_bbox: 0.2230, loss: 0.4283, grad_norm: 6.2998
2025-08-05 15:58:36,783 - mmdet - INFO - Epoch [3][3600/4665]	lr: 5.000e-03, eta: 0:31:14, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.2242, acc: 92.2285, loss_bbox: 0.2513, loss: 0.4756, grad_norm: 7.0525
2025-08-05 15:58:53,044 - mmdet - INFO - Epoch [3][3650/4665]	lr: 5.000e-03, eta: 0:30:58, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2271, acc: 92.3457, loss_bbox: 0.2490, loss: 0.4762, grad_norm: 7.1040
2025-08-05 15:59:09,200 - mmdet - INFO - Epoch [3][3700/4665]	lr: 5.000e-03, eta: 0:30:41, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2127, acc: 92.5684, loss_bbox: 0.2345, loss: 0.4472, grad_norm: 7.3203
2025-08-05 15:59:25,343 - mmdet - INFO - Epoch [3][3750/4665]	lr: 5.000e-03, eta: 0:30:25, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.2088, acc: 92.9180, loss_bbox: 0.2483, loss: 0.4571, grad_norm: 7.0229
2025-08-05 15:59:41,602 - mmdet - INFO - Epoch [3][3800/4665]	lr: 5.000e-03, eta: 0:30:08, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.2345, acc: 91.3613, loss_bbox: 0.2791, loss: 0.5136, grad_norm: 7.7445
2025-08-05 15:59:57,832 - mmdet - INFO - Epoch [3][3850/4665]	lr: 5.000e-03, eta: 0:29:52, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1807, acc: 93.7402, loss_bbox: 0.1886, loss: 0.3694, grad_norm: 5.9185
2025-08-05 16:00:13,947 - mmdet - INFO - Epoch [3][3900/4665]	lr: 5.000e-03, eta: 0:29:35, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2045, acc: 92.6836, loss_bbox: 0.2430, loss: 0.4475, grad_norm: 6.3863
2025-08-05 16:00:30,262 - mmdet - INFO - Epoch [3][3950/4665]	lr: 5.000e-03, eta: 0:29:19, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2016, acc: 93.1191, loss_bbox: 0.2233, loss: 0.4248, grad_norm: 6.2730
2025-08-05 16:00:46,615 - mmdet - INFO - Epoch [3][4000/4665]	lr: 5.000e-03, eta: 0:29:03, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2187, acc: 92.7773, loss_bbox: 0.2298, loss: 0.4485, grad_norm: 6.4733
2025-08-05 16:01:02,775 - mmdet - INFO - Epoch [3][4050/4665]	lr: 5.000e-03, eta: 0:28:46, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1769, acc: 93.4297, loss_bbox: 0.2061, loss: 0.3829, grad_norm: 6.0897
2025-08-05 16:01:18,985 - mmdet - INFO - Epoch [3][4100/4665]	lr: 5.000e-03, eta: 0:28:30, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1958, acc: 93.1191, loss_bbox: 0.2308, loss: 0.4266, grad_norm: 6.9058
2025-08-05 16:01:35,274 - mmdet - INFO - Epoch [3][4150/4665]	lr: 5.000e-03, eta: 0:28:13, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.2294, acc: 92.0137, loss_bbox: 0.2763, loss: 0.5058, grad_norm: 6.8832
2025-08-05 16:01:51,427 - mmdet - INFO - Epoch [3][4200/4665]	lr: 5.000e-03, eta: 0:27:57, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1802, acc: 93.6230, loss_bbox: 0.2036, loss: 0.3839, grad_norm: 6.0434
2025-08-05 16:02:07,514 - mmdet - INFO - Epoch [3][4250/4665]	lr: 5.000e-03, eta: 0:27:41, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2118, acc: 92.3379, loss_bbox: 0.2467, loss: 0.4585, grad_norm: 6.7213
2025-08-05 16:02:23,755 - mmdet - INFO - Epoch [3][4300/4665]	lr: 5.000e-03, eta: 0:27:24, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2409, acc: 91.9844, loss_bbox: 0.2730, loss: 0.5139, grad_norm: 7.2907
2025-08-05 16:02:39,971 - mmdet - INFO - Epoch [3][4350/4665]	lr: 5.000e-03, eta: 0:27:08, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.2021, acc: 92.9648, loss_bbox: 0.2415, loss: 0.4436, grad_norm: 6.0474
2025-08-05 16:02:56,157 - mmdet - INFO - Epoch [3][4400/4665]	lr: 5.000e-03, eta: 0:26:51, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1766, acc: 93.7461, loss_bbox: 0.2093, loss: 0.3859, grad_norm: 5.8808
2025-08-05 16:03:12,261 - mmdet - INFO - Epoch [3][4450/4665]	lr: 5.000e-03, eta: 0:26:35, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.2039, acc: 93.4219, loss_bbox: 0.2194, loss: 0.4234, grad_norm: 6.0996
2025-08-05 16:03:28,354 - mmdet - INFO - Epoch [3][4500/4665]	lr: 5.000e-03, eta: 0:26:19, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.2165, acc: 91.8398, loss_bbox: 0.2317, loss: 0.4481, grad_norm: 6.7834
2025-08-05 16:03:44,599 - mmdet - INFO - Epoch [3][4550/4665]	lr: 5.000e-03, eta: 0:26:02, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.2121, acc: 92.8379, loss_bbox: 0.2361, loss: 0.4482, grad_norm: 6.7134
2025-08-05 16:04:00,718 - mmdet - INFO - Epoch [3][4600/4665]	lr: 5.000e-03, eta: 0:25:46, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.1941, acc: 92.7441, loss_bbox: 0.2268, loss: 0.4208, grad_norm: 6.1407
2025-08-05 16:04:16,955 - mmdet - INFO - Epoch [3][4650/4665]	lr: 5.000e-03, eta: 0:25:29, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.2254, acc: 91.7676, loss_bbox: 0.2713, loss: 0.4967, grad_norm: 7.0488
2025-08-05 16:04:54,358 - mmdet - INFO - Epoch [4][50/4665]	lr: 5.000e-04, eta: 0:25:12, time: 0.634, data_time: 0.316, memory: 12189, loss_cls: 0.1656, acc: 93.5059, loss_bbox: 0.1916, loss: 0.3572, grad_norm: 5.4728
2025-08-05 16:05:10,505 - mmdet - INFO - Epoch [4][100/4665]	lr: 5.000e-04, eta: 0:24:55, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1852, acc: 93.3613, loss_bbox: 0.2222, loss: 0.4074, grad_norm: 5.9719
2025-08-05 16:05:26,677 - mmdet - INFO - Epoch [4][150/4665]	lr: 5.000e-04, eta: 0:24:39, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1917, acc: 92.5410, loss_bbox: 0.2274, loss: 0.4191, grad_norm: 5.9904
2025-08-05 16:05:43,042 - mmdet - INFO - Epoch [4][200/4665]	lr: 5.000e-04, eta: 0:24:22, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.2064, acc: 92.5664, loss_bbox: 0.2293, loss: 0.4358, grad_norm: 6.0965
2025-08-05 16:05:59,247 - mmdet - INFO - Epoch [4][250/4665]	lr: 5.000e-04, eta: 0:24:06, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1784, acc: 92.9648, loss_bbox: 0.2216, loss: 0.4000, grad_norm: 5.4915
2025-08-05 16:06:15,601 - mmdet - INFO - Epoch [4][300/4665]	lr: 5.000e-04, eta: 0:23:49, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1664, acc: 93.9297, loss_bbox: 0.2238, loss: 0.3902, grad_norm: 5.5835
2025-08-05 16:06:31,795 - mmdet - INFO - Epoch [4][350/4665]	lr: 5.000e-04, eta: 0:23:33, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1858, acc: 93.0566, loss_bbox: 0.2279, loss: 0.4137, grad_norm: 5.7531
2025-08-05 16:06:48,123 - mmdet - INFO - Epoch [4][400/4665]	lr: 5.000e-04, eta: 0:23:17, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1807, acc: 92.7285, loss_bbox: 0.2303, loss: 0.4110, grad_norm: 5.5200
2025-08-05 16:07:04,313 - mmdet - INFO - Epoch [4][450/4665]	lr: 5.000e-04, eta: 0:23:00, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1768, acc: 93.6660, loss_bbox: 0.2281, loss: 0.4049, grad_norm: 5.6359
2025-08-05 16:07:20,510 - mmdet - INFO - Epoch [4][500/4665]	lr: 5.000e-04, eta: 0:22:44, time: 0.324, data_time: 0.005, memory: 12189, loss_cls: 0.1807, acc: 93.4199, loss_bbox: 0.2351, loss: 0.4157, grad_norm: 5.8479
2025-08-05 16:07:36,679 - mmdet - INFO - Epoch [4][550/4665]	lr: 5.000e-04, eta: 0:22:27, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1579, acc: 94.0996, loss_bbox: 0.1847, loss: 0.3426, grad_norm: 5.2161
2025-08-05 16:07:52,904 - mmdet - INFO - Epoch [4][600/4665]	lr: 5.000e-04, eta: 0:22:11, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1774, acc: 93.0332, loss_bbox: 0.2368, loss: 0.4143, grad_norm: 5.7537
2025-08-05 16:08:09,168 - mmdet - INFO - Epoch [4][650/4665]	lr: 5.000e-04, eta: 0:21:54, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1692, acc: 93.6016, loss_bbox: 0.2307, loss: 0.3999, grad_norm: 5.7651
2025-08-05 16:08:25,398 - mmdet - INFO - Epoch [4][700/4665]	lr: 5.000e-04, eta: 0:21:38, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.1682, acc: 93.5801, loss_bbox: 0.2270, loss: 0.3952, grad_norm: 5.6482
2025-08-05 16:08:41,745 - mmdet - INFO - Epoch [4][750/4665]	lr: 5.000e-04, eta: 0:21:22, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1301, acc: 94.8047, loss_bbox: 0.1744, loss: 0.3045, grad_norm: 5.0955
2025-08-05 16:08:57,864 - mmdet - INFO - Epoch [4][800/4665]	lr: 5.000e-04, eta: 0:21:05, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.1740, acc: 93.5957, loss_bbox: 0.2118, loss: 0.3858, grad_norm: 5.8500
2025-08-05 16:09:14,206 - mmdet - INFO - Epoch [4][850/4665]	lr: 5.000e-04, eta: 0:20:49, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1491, acc: 94.0605, loss_bbox: 0.1951, loss: 0.3443, grad_norm: 4.9980
2025-08-05 16:09:30,353 - mmdet - INFO - Epoch [4][900/4665]	lr: 5.000e-04, eta: 0:20:32, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1726, acc: 93.7734, loss_bbox: 0.2067, loss: 0.3794, grad_norm: 5.5795
2025-08-05 16:09:46,511 - mmdet - INFO - Epoch [4][950/4665]	lr: 5.000e-04, eta: 0:20:16, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1512, acc: 94.3887, loss_bbox: 0.1989, loss: 0.3502, grad_norm: 4.9546
2025-08-05 16:10:02,816 - mmdet - INFO - Epoch [4][1000/4665]	lr: 5.000e-04, eta: 0:20:00, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1776, acc: 93.4062, loss_bbox: 0.2316, loss: 0.4092, grad_norm: 5.8899
2025-08-05 16:10:18,971 - mmdet - INFO - Epoch [4][1050/4665]	lr: 5.000e-04, eta: 0:19:43, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1719, acc: 93.7773, loss_bbox: 0.2082, loss: 0.3801, grad_norm: 5.7103
2025-08-05 16:10:35,172 - mmdet - INFO - Epoch [4][1100/4665]	lr: 5.000e-04, eta: 0:19:27, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1658, acc: 93.5840, loss_bbox: 0.2225, loss: 0.3883, grad_norm: 5.7404
2025-08-05 16:10:51,375 - mmdet - INFO - Epoch [4][1150/4665]	lr: 5.000e-04, eta: 0:19:10, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1606, acc: 93.9121, loss_bbox: 0.2157, loss: 0.3764, grad_norm: 5.6819
2025-08-05 16:11:07,510 - mmdet - INFO - Epoch [4][1200/4665]	lr: 5.000e-04, eta: 0:18:54, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1792, acc: 93.0254, loss_bbox: 0.2556, loss: 0.4347, grad_norm: 5.7381
2025-08-05 16:11:23,743 - mmdet - INFO - Epoch [4][1250/4665]	lr: 5.000e-04, eta: 0:18:38, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1649, acc: 93.6152, loss_bbox: 0.2005, loss: 0.3654, grad_norm: 5.3762
2025-08-05 16:11:39,975 - mmdet - INFO - Epoch [4][1300/4665]	lr: 5.000e-04, eta: 0:18:21, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1728, acc: 93.8105, loss_bbox: 0.2180, loss: 0.3909, grad_norm: 5.6839
2025-08-05 16:11:56,244 - mmdet - INFO - Epoch [4][1350/4665]	lr: 5.000e-04, eta: 0:18:05, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1963, acc: 92.7051, loss_bbox: 0.2423, loss: 0.4386, grad_norm: 6.4225
2025-08-05 16:12:12,377 - mmdet - INFO - Epoch [4][1400/4665]	lr: 5.000e-04, eta: 0:17:48, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1671, acc: 93.8516, loss_bbox: 0.2065, loss: 0.3736, grad_norm: 5.6871
2025-08-05 16:12:28,631 - mmdet - INFO - Epoch [4][1450/4665]	lr: 5.000e-04, eta: 0:17:32, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1754, acc: 93.7520, loss_bbox: 0.2250, loss: 0.4004, grad_norm: 5.5564
2025-08-05 16:12:44,893 - mmdet - INFO - Epoch [4][1500/4665]	lr: 5.000e-04, eta: 0:17:16, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1888, acc: 92.6016, loss_bbox: 0.2722, loss: 0.4610, grad_norm: 6.1005
2025-08-05 16:13:01,059 - mmdet - INFO - Epoch [4][1550/4665]	lr: 5.000e-04, eta: 0:16:59, time: 0.323, data_time: 0.005, memory: 12189, loss_cls: 0.1552, acc: 93.7754, loss_bbox: 0.2073, loss: 0.3626, grad_norm: 5.4330
2025-08-05 16:13:17,261 - mmdet - INFO - Epoch [4][1600/4665]	lr: 5.000e-04, eta: 0:16:43, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1572, acc: 93.8809, loss_bbox: 0.2299, loss: 0.3872, grad_norm: 5.7110
2025-08-05 16:13:33,545 - mmdet - INFO - Epoch [4][1650/4665]	lr: 5.000e-04, eta: 0:16:26, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1461, acc: 94.2598, loss_bbox: 0.1848, loss: 0.3309, grad_norm: 5.2423
2025-08-05 16:13:49,771 - mmdet - INFO - Epoch [4][1700/4665]	lr: 5.000e-04, eta: 0:16:10, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1586, acc: 93.8477, loss_bbox: 0.1855, loss: 0.3442, grad_norm: 5.2570
2025-08-05 16:14:05,870 - mmdet - INFO - Epoch [4][1750/4665]	lr: 5.000e-04, eta: 0:15:54, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.1735, acc: 93.5723, loss_bbox: 0.2252, loss: 0.3987, grad_norm: 5.6695
2025-08-05 16:14:22,183 - mmdet - INFO - Epoch [4][1800/4665]	lr: 5.000e-04, eta: 0:15:37, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1542, acc: 94.1016, loss_bbox: 0.2017, loss: 0.3560, grad_norm: 5.3800
2025-08-05 16:14:38,401 - mmdet - INFO - Epoch [4][1850/4665]	lr: 5.000e-04, eta: 0:15:21, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1744, acc: 93.7246, loss_bbox: 0.2102, loss: 0.3846, grad_norm: 5.4420
2025-08-05 16:14:54,461 - mmdet - INFO - Epoch [4][1900/4665]	lr: 5.000e-04, eta: 0:15:04, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.1617, acc: 94.2500, loss_bbox: 0.1980, loss: 0.3597, grad_norm: 5.6595
2025-08-05 16:15:10,623 - mmdet - INFO - Epoch [4][1950/4665]	lr: 5.000e-04, eta: 0:14:48, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1586, acc: 94.1367, loss_bbox: 0.2127, loss: 0.3713, grad_norm: 5.6446
2025-08-05 16:15:26,715 - mmdet - INFO - Epoch [4][2000/4665]	lr: 5.000e-04, eta: 0:14:32, time: 0.322, data_time: 0.006, memory: 12189, loss_cls: 0.1582, acc: 93.5684, loss_bbox: 0.2157, loss: 0.3739, grad_norm: 5.6449
2025-08-05 16:15:42,698 - mmdet - INFO - Epoch [4][2050/4665]	lr: 5.000e-04, eta: 0:14:15, time: 0.320, data_time: 0.005, memory: 12189, loss_cls: 0.1600, acc: 93.8633, loss_bbox: 0.2061, loss: 0.3661, grad_norm: 5.2397
2025-08-05 16:15:58,887 - mmdet - INFO - Epoch [4][2100/4665]	lr: 5.000e-04, eta: 0:13:59, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1781, acc: 93.1523, loss_bbox: 0.2286, loss: 0.4067, grad_norm: 6.0033
2025-08-05 16:16:15,057 - mmdet - INFO - Epoch [4][2150/4665]	lr: 5.000e-04, eta: 0:13:42, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1514, acc: 93.9375, loss_bbox: 0.2088, loss: 0.3602, grad_norm: 5.2693
2025-08-05 16:16:31,353 - mmdet - INFO - Epoch [4][2200/4665]	lr: 5.000e-04, eta: 0:13:26, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1630, acc: 94.2344, loss_bbox: 0.2149, loss: 0.3778, grad_norm: 5.5865
2025-08-05 16:16:47,636 - mmdet - INFO - Epoch [4][2250/4665]	lr: 5.000e-04, eta: 0:13:10, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1657, acc: 93.7266, loss_bbox: 0.2028, loss: 0.3685, grad_norm: 5.6328
2025-08-05 16:17:03,858 - mmdet - INFO - Epoch [4][2300/4665]	lr: 5.000e-04, eta: 0:12:53, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1659, acc: 93.7207, loss_bbox: 0.2162, loss: 0.3821, grad_norm: 5.5528
2025-08-05 16:17:20,035 - mmdet - INFO - Epoch [4][2350/4665]	lr: 5.000e-04, eta: 0:12:37, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.2027, acc: 92.3301, loss_bbox: 0.2593, loss: 0.4620, grad_norm: 6.2527
2025-08-05 16:17:36,218 - mmdet - INFO - Epoch [4][2400/4665]	lr: 5.000e-04, eta: 0:12:20, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1695, acc: 93.6289, loss_bbox: 0.2212, loss: 0.3907, grad_norm: 5.9050
2025-08-05 16:17:52,418 - mmdet - INFO - Epoch [4][2450/4665]	lr: 5.000e-04, eta: 0:12:04, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1660, acc: 93.5879, loss_bbox: 0.2226, loss: 0.3886, grad_norm: 5.8275
2025-08-05 16:18:08,751 - mmdet - INFO - Epoch [4][2500/4665]	lr: 5.000e-04, eta: 0:11:48, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1598, acc: 94.2148, loss_bbox: 0.2063, loss: 0.3661, grad_norm: 5.4274
2025-08-05 16:18:25,042 - mmdet - INFO - Epoch [4][2550/4665]	lr: 5.000e-04, eta: 0:11:31, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1647, acc: 93.7090, loss_bbox: 0.2291, loss: 0.3938, grad_norm: 5.6300
2025-08-05 16:18:41,292 - mmdet - INFO - Epoch [4][2600/4665]	lr: 5.000e-04, eta: 0:11:15, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1461, acc: 94.4727, loss_bbox: 0.1928, loss: 0.3389, grad_norm: 5.0301
2025-08-05 16:18:57,486 - mmdet - INFO - Epoch [4][2650/4665]	lr: 5.000e-04, eta: 0:10:59, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1942, acc: 93.1602, loss_bbox: 0.2396, loss: 0.4338, grad_norm: 6.1271
2025-08-05 16:19:13,648 - mmdet - INFO - Epoch [4][2700/4665]	lr: 5.000e-04, eta: 0:10:42, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1927, acc: 93.1309, loss_bbox: 0.2451, loss: 0.4377, grad_norm: 5.9664
2025-08-05 16:19:29,910 - mmdet - INFO - Epoch [4][2750/4665]	lr: 5.000e-04, eta: 0:10:26, time: 0.325, data_time: 0.005, memory: 12189, loss_cls: 0.2002, acc: 92.6816, loss_bbox: 0.2492, loss: 0.4493, grad_norm: 6.2784
2025-08-05 16:19:46,093 - mmdet - INFO - Epoch [4][2800/4665]	lr: 5.000e-04, eta: 0:10:09, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1679, acc: 93.4102, loss_bbox: 0.2227, loss: 0.3906, grad_norm: 5.9217
2025-08-05 16:20:02,321 - mmdet - INFO - Epoch [4][2850/4665]	lr: 5.000e-04, eta: 0:09:53, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1754, acc: 93.4414, loss_bbox: 0.2112, loss: 0.3865, grad_norm: 5.9582
2025-08-05 16:20:18,466 - mmdet - INFO - Epoch [4][2900/4665]	lr: 5.000e-04, eta: 0:09:37, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1638, acc: 93.7793, loss_bbox: 0.2172, loss: 0.3810, grad_norm: 5.5419
2025-08-05 16:20:34,773 - mmdet - INFO - Epoch [4][2950/4665]	lr: 5.000e-04, eta: 0:09:20, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1724, acc: 93.6934, loss_bbox: 0.2265, loss: 0.3988, grad_norm: 6.2713
2025-08-05 16:20:50,990 - mmdet - INFO - Epoch [4][3000/4665]	lr: 5.000e-04, eta: 0:09:04, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1535, acc: 94.2559, loss_bbox: 0.2079, loss: 0.3614, grad_norm: 5.2768
2025-08-05 16:21:07,080 - mmdet - INFO - Epoch [4][3050/4665]	lr: 5.000e-04, eta: 0:08:48, time: 0.322, data_time: 0.005, memory: 12189, loss_cls: 0.1793, acc: 93.5430, loss_bbox: 0.2200, loss: 0.3993, grad_norm: 5.7558
2025-08-05 16:21:23,214 - mmdet - INFO - Epoch [4][3100/4665]	lr: 5.000e-04, eta: 0:08:31, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1813, acc: 93.5781, loss_bbox: 0.2190, loss: 0.4003, grad_norm: 6.1780
2025-08-05 16:21:39,447 - mmdet - INFO - Epoch [4][3150/4665]	lr: 5.000e-04, eta: 0:08:15, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1601, acc: 93.5957, loss_bbox: 0.2104, loss: 0.3704, grad_norm: 5.5231
2025-08-05 16:21:55,705 - mmdet - INFO - Epoch [4][3200/4665]	lr: 5.000e-04, eta: 0:07:59, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1703, acc: 93.5137, loss_bbox: 0.2178, loss: 0.3882, grad_norm: 5.8362
2025-08-05 16:22:11,977 - mmdet - INFO - Epoch [4][3250/4665]	lr: 5.000e-04, eta: 0:07:42, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1761, acc: 93.5781, loss_bbox: 0.2267, loss: 0.4029, grad_norm: 6.1103
2025-08-05 16:22:27,961 - mmdet - INFO - Epoch [4][3300/4665]	lr: 5.000e-04, eta: 0:07:26, time: 0.320, data_time: 0.006, memory: 12189, loss_cls: 0.1823, acc: 93.0742, loss_bbox: 0.2299, loss: 0.4121, grad_norm: 5.7935
2025-08-05 16:22:44,224 - mmdet - INFO - Epoch [4][3350/4665]	lr: 5.000e-04, eta: 0:07:09, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1532, acc: 93.9473, loss_bbox: 0.1955, loss: 0.3487, grad_norm: 5.7439
2025-08-05 16:23:00,474 - mmdet - INFO - Epoch [4][3400/4665]	lr: 5.000e-04, eta: 0:06:53, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1555, acc: 94.1641, loss_bbox: 0.2140, loss: 0.3694, grad_norm: 5.7783
2025-08-05 16:23:16,639 - mmdet - INFO - Epoch [4][3450/4665]	lr: 5.000e-04, eta: 0:06:37, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1624, acc: 93.7480, loss_bbox: 0.2080, loss: 0.3705, grad_norm: 5.3926
2025-08-05 16:23:32,867 - mmdet - INFO - Epoch [4][3500/4665]	lr: 5.000e-04, eta: 0:06:20, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1694, acc: 93.5039, loss_bbox: 0.2326, loss: 0.4020, grad_norm: 5.8958
2025-08-05 16:23:49,128 - mmdet - INFO - Epoch [4][3550/4665]	lr: 5.000e-04, eta: 0:06:04, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1515, acc: 94.5293, loss_bbox: 0.1860, loss: 0.3375, grad_norm: 5.5575
2025-08-05 16:24:05,292 - mmdet - INFO - Epoch [4][3600/4665]	lr: 5.000e-04, eta: 0:05:48, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1551, acc: 93.8242, loss_bbox: 0.2286, loss: 0.3836, grad_norm: 5.7371
2025-08-05 16:24:21,447 - mmdet - INFO - Epoch [4][3650/4665]	lr: 5.000e-04, eta: 0:05:31, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1747, acc: 93.1934, loss_bbox: 0.2295, loss: 0.4042, grad_norm: 5.7451
2025-08-05 16:24:37,758 - mmdet - INFO - Epoch [4][3700/4665]	lr: 5.000e-04, eta: 0:05:15, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1547, acc: 94.0625, loss_bbox: 0.1899, loss: 0.3446, grad_norm: 5.1392
2025-08-05 16:24:53,917 - mmdet - INFO - Epoch [4][3750/4665]	lr: 5.000e-04, eta: 0:04:59, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1951, acc: 93.0898, loss_bbox: 0.2377, loss: 0.4328, grad_norm: 6.2955
2025-08-05 16:25:10,095 - mmdet - INFO - Epoch [4][3800/4665]	lr: 5.000e-04, eta: 0:04:42, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1664, acc: 93.6230, loss_bbox: 0.2298, loss: 0.3962, grad_norm: 5.9319
2025-08-05 16:25:26,325 - mmdet - INFO - Epoch [4][3850/4665]	lr: 5.000e-04, eta: 0:04:26, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1462, acc: 94.3496, loss_bbox: 0.1967, loss: 0.3428, grad_norm: 5.2510
2025-08-05 16:25:42,638 - mmdet - INFO - Epoch [4][3900/4665]	lr: 5.000e-04, eta: 0:04:10, time: 0.326, data_time: 0.006, memory: 12189, loss_cls: 0.1931, acc: 92.7129, loss_bbox: 0.2420, loss: 0.4351, grad_norm: 6.3116
2025-08-05 16:25:58,996 - mmdet - INFO - Epoch [4][3950/4665]	lr: 5.000e-04, eta: 0:03:53, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1922, acc: 92.5039, loss_bbox: 0.2468, loss: 0.4389, grad_norm: 6.1280
2025-08-05 16:26:15,249 - mmdet - INFO - Epoch [4][4000/4665]	lr: 5.000e-04, eta: 0:03:37, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1556, acc: 94.0977, loss_bbox: 0.2110, loss: 0.3666, grad_norm: 5.4683
2025-08-05 16:26:31,514 - mmdet - INFO - Epoch [4][4050/4665]	lr: 5.000e-04, eta: 0:03:21, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1479, acc: 94.4434, loss_bbox: 0.2023, loss: 0.3502, grad_norm: 5.4325
2025-08-05 16:26:47,557 - mmdet - INFO - Epoch [4][4100/4665]	lr: 5.000e-04, eta: 0:03:04, time: 0.321, data_time: 0.005, memory: 12189, loss_cls: 0.1669, acc: 93.3887, loss_bbox: 0.2188, loss: 0.3857, grad_norm: 5.7512
2025-08-05 16:27:03,782 - mmdet - INFO - Epoch [4][4150/4665]	lr: 5.000e-04, eta: 0:02:48, time: 0.324, data_time: 0.006, memory: 12189, loss_cls: 0.1551, acc: 94.0273, loss_bbox: 0.2138, loss: 0.3689, grad_norm: 5.5987
2025-08-05 16:27:20,010 - mmdet - INFO - Epoch [4][4200/4665]	lr: 5.000e-04, eta: 0:02:31, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1825, acc: 93.1816, loss_bbox: 0.2245, loss: 0.4070, grad_norm: 6.0273
2025-08-05 16:27:36,277 - mmdet - INFO - Epoch [4][4250/4665]	lr: 5.000e-04, eta: 0:02:15, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1673, acc: 93.5645, loss_bbox: 0.2014, loss: 0.3687, grad_norm: 5.8337
2025-08-05 16:27:52,447 - mmdet - INFO - Epoch [4][4300/4665]	lr: 5.000e-04, eta: 0:01:59, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1627, acc: 93.9941, loss_bbox: 0.2025, loss: 0.3652, grad_norm: 6.0738
2025-08-05 16:28:08,604 - mmdet - INFO - Epoch [4][4350/4665]	lr: 5.000e-04, eta: 0:01:42, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1592, acc: 93.6953, loss_bbox: 0.2150, loss: 0.3741, grad_norm: 5.8212
2025-08-05 16:28:25,004 - mmdet - INFO - Epoch [4][4400/4665]	lr: 5.000e-04, eta: 0:01:26, time: 0.328, data_time: 0.006, memory: 12189, loss_cls: 0.1799, acc: 93.0176, loss_bbox: 0.2324, loss: 0.4123, grad_norm: 5.8154
2025-08-05 16:28:41,151 - mmdet - INFO - Epoch [4][4450/4665]	lr: 5.000e-04, eta: 0:01:10, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1670, acc: 93.5098, loss_bbox: 0.2238, loss: 0.3908, grad_norm: 5.6744
2025-08-05 16:28:57,504 - mmdet - INFO - Epoch [4][4500/4665]	lr: 5.000e-04, eta: 0:00:53, time: 0.327, data_time: 0.006, memory: 12189, loss_cls: 0.1648, acc: 93.6152, loss_bbox: 0.2254, loss: 0.3903, grad_norm: 5.9586
2025-08-05 16:29:13,572 - mmdet - INFO - Epoch [4][4550/4665]	lr: 5.000e-04, eta: 0:00:37, time: 0.321, data_time: 0.006, memory: 12189, loss_cls: 0.1785, acc: 93.4922, loss_bbox: 0.2224, loss: 0.4009, grad_norm: 6.0285
2025-08-05 16:29:29,837 - mmdet - INFO - Epoch [4][4600/4665]	lr: 5.000e-04, eta: 0:00:21, time: 0.325, data_time: 0.006, memory: 12189, loss_cls: 0.1429, acc: 94.6543, loss_bbox: 0.2079, loss: 0.3509, grad_norm: 5.1909
2025-08-05 16:29:45,978 - mmdet - INFO - Epoch [4][4650/4665]	lr: 5.000e-04, eta: 0:00:04, time: 0.323, data_time: 0.006, memory: 12189, loss_cls: 0.1408, acc: 94.8906, loss_bbox: 0.1716, loss: 0.3124, grad_norm: 5.1939
2025-08-05 16:29:51,739 - mmdet - INFO - Saving checkpoint at 4 epochs
2025-08-05 16:32:27,885 - mmdet - INFO - Evaluating bbox...
2025-08-05 16:32:37,050 - mmdet - INFO - Exp name: clip_decouple_faster_rcnn_r50_c4_1x_objcoco_2ndstage.py
2025-08-05 16:32:37,051 - mmdet - INFO - Epoch(val) [4][850]	bbox_mAP: 0.1030, bbox_mAP_50: 0.2300, bbox_mAP_75: 0.0830, bbox_mAP_s: 0.0160, bbox_mAP_m: 0.0860, bbox_mAP_l: 0.2140, bbox_mAP_copypaste: 0.103 0.230 0.083 0.016 0.086 0.214
