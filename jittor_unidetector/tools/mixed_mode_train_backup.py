#!/usr/bin/env python3
"""
æ··åˆæ¨¡å¼è®­ç»ƒè„šæœ¬ - å®Œå…¨å…¼å®¹Jittorå’ŒMMDetection
è§£å†³æ‰€æœ‰å…¼å®¹æ€§é—®é¢˜ï¼Œåˆ›å»ºçœŸæ­£å¯å·¥ä½œçš„è®­ç»ƒå™¨
"""

import argparse
import copy
import os
import os.path as osp
import time
import warnings
import sys
import numpy as np

import jittor as jt
import mmcv
from mmcv import Config, DictAction
from mmcv.runner import get_dist_info, init_dist
from mmcv.utils import get_git_hash

from mmdet import __version__
from mmdet.apis import set_random_seed
from mmdet.datasets import build_dataset
from mmdet.models import build_detector
from mmdet.utils import collect_env, get_root_logger


def parse_args():
    parser = argparse.ArgumentParser(description='æ··åˆæ¨¡å¼è®­ç»ƒæ£€æµ‹å™¨')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='ä¿å­˜æ—¥å¿—å’Œæ¨¡å‹çš„ç›®å½•')
    parser.add_argument(
        '--resume-from', help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹æ–‡ä»¶')
    parser.add_argument(
        '--no-validate',
        action='store_true',
        help='è®­ç»ƒæœŸé—´ä¸è¯„ä¼°æ£€æŸ¥ç‚¹')
    parser.add_argument(
        '--epochs', type=int, default=4, help='è®­ç»ƒè½®æ•°')
    parser.add_argument(
        '--batch-size', type=int, default=2, help='æ‰¹æ¬¡å¤§å°')
    group_gpus = parser.add_mutually_exclusive_group()
    group_gpus.add_argument(
        '--gpus',
        type=int,
        help='ä½¿ç”¨çš„GPUæ•°é‡ '
        '(ä»…é€‚ç”¨äºéåˆ†å¸ƒå¼è®­ç»ƒ)')
    group_gpus.add_argument(
        '--gpu-ids',
        type=int,
        nargs='+',
        help='ä½¿ç”¨çš„GPU ID '
        '(ä»…é€‚ç”¨äºéåˆ†å¸ƒå¼è®­ç»ƒ)')
    parser.add_argument('--seed', type=int, default=None, help='éšæœºç§å­')
    parser.add_argument(
        '--deterministic',
        action='store_true',
        help='æ˜¯å¦ä¸ºCUDNNåç«¯è®¾ç½®ç¡®å®šæ€§é€‰é¡¹')
    parser.add_argument(
        '--options',
        nargs='+',
        action=DictAction,
        help='è¦†ç›–ä½¿ç”¨é…ç½®ä¸­çš„æŸäº›è®¾ç½®ï¼Œxxx=yyyæ ¼å¼çš„é”®å€¼å¯¹ '
        'å°†åˆå¹¶åˆ°é…ç½®æ–‡ä»¶ä¸­ (å·²å¼ƒç”¨)ï¼Œè¯·æ”¹ç”¨ --cfg-options')
    parser.add_argument(
        '--cfg-options',
        nargs='+',
        action=DictAction,
        help='è¦†ç›–ä½¿ç”¨é…ç½®ä¸­çš„æŸäº›è®¾ç½®ï¼Œxxx=yyyæ ¼å¼çš„é”®å€¼å¯¹ '
        'å°†åˆå¹¶åˆ°é…ç½®æ–‡ä»¶ã€‚å¦‚æœè¦è¦†ç›–çš„å€¼æ˜¯åˆ—è¡¨ï¼Œåº”è¯¥åƒ '
        'key="[a,b]" æˆ– key=a,b è¿™æ ·ã€‚å®ƒè¿˜å…è®¸åµŒå¥—çš„åˆ—è¡¨/å…ƒç»„å€¼ï¼Œ'
        'ä¾‹å¦‚ key="[(a,b),(c,d)]"ã€‚æ³¨æ„å¼•å·æ˜¯å¿…éœ€çš„ï¼Œä¸å…è®¸æœ‰ç©ºæ ¼ã€‚')
    parser.add_argument(
        '--launcher',
        choices=['none', 'pytorch', 'slurm', 'mpi'],
        default='none',
        help='ä½œä¸šå¯åŠ¨å™¨')
    parser.add_argument('--local_rank', type=int, default=0)
    args = parser.parse_args()
    if 'LOCAL_RANK' not in os.environ:
        os.environ['LOCAL_RANK'] = str(args.local_rank)

    if args.options and args.cfg_options:
        raise ValueError(
            '--options å’Œ --cfg-options ä¸èƒ½åŒæ—¶æŒ‡å®šï¼Œ'
            '--options å·²è¢«å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --cfg-options')
    if args.options:
        warnings.warn('--options å·²è¢«å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --cfg-options')
        args.cfg_options = args.options

    return args


def load_custom_components():
    """åŠ è½½è‡ªå®šä¹‰ç»„ä»¶"""
    print("ğŸ“¦ åŠ è½½è‡ªå®šä¹‰ç»„ä»¶...")
    
    # æ·»åŠ é¡¹ç›®è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, project_root)
    
    # å¯¼å…¥è‡ªå®šä¹‰ç»„ä»¶
    try:
        from models.backbones.clip_backbone import CLIPResNet
        from models.roi_heads.oln_roi_head import OlnRoIHead
        from models.roi_heads.bbox_heads.bbox_head_clip_partitioned import BBoxHeadCLIPPartitioned
        from models.roi_heads.bbox_heads.bbox_head_clip_inference import BBoxHeadCLIPInference
        print("âœ… è‡ªå®šä¹‰ç»„ä»¶åŠ è½½æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ è‡ªå®šä¹‰ç»„ä»¶åŠ è½½å¤±è´¥: {e}")
        return False


def setup_jittor():
    """è®¾ç½®Jittor"""
    print("âš™ï¸ è®¾ç½®Jittor...")
    
    # è®¾ç½®Jittor
    jt.flags.use_cuda = 1
    jt.flags.amp_level = 3  # è‡ªåŠ¨æ··åˆç²¾åº¦
    print("âœ… Jittorè®¾ç½®å®Œæˆ")


def safe_convert_to_jittor(data):
    """å®‰å…¨åœ°å°†æ•°æ®è½¬æ¢ä¸ºJittoræ ¼å¼ï¼Œå¤„ç†æ‰€æœ‰å…¼å®¹æ€§é—®é¢˜"""
    if isinstance(data, (list, tuple)):
        return [safe_convert_to_jittor(item) for item in data]
    elif isinstance(data, dict):
        return {key: safe_convert_to_jittor(value) for key, value in data.items()}
    elif hasattr(data, 'data'):  # DataContainer
        return safe_convert_to_jittor(data.data)
    elif hasattr(data, 'cpu') and hasattr(data, 'numpy'):
        # PyTorchå¼ é‡
        try:
            return jt.array(data.cpu().numpy())
        except:
            return data
    elif hasattr(data, 'shape') and hasattr(data, 'dtype'):
        # numpyæ•°ç»„
        try:
            return jt.array(data)
        except:
            return data
    elif isinstance(data, memoryview):
        # memoryviewç±»å‹
        try:
            return jt.array(np.array(data))
        except:
            return data
    else:
        # å…¶ä»–ç±»å‹ç›´æ¥è¿”å›
        return data


def create_jittor_compatible_model(cfg):
    """åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹"""
    print("ğŸ”§ åˆ›å»ºJittorå…¼å®¹æ¨¡å‹...")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®ä¿¡æ¯:")
    print(f"   - æ¨¡å‹ç±»å‹: {cfg.model.type}")
    print(f"   - Backboneç±»å‹: {cfg.model.backbone.type}")
    print(f"   - Neckç±»å‹: {cfg.model.neck.type}")
    print(f"   - RPN Headç±»å‹: {cfg.model.rpn_head.type}")
    print(f"   - ROI Headç±»å‹: {cfg.model.roi_head.type}")
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ–‡ä»¶
    if hasattr(cfg.model.backbone, 'pretrained'):
        pretrained_path = cfg.model.backbone.pretrained
        print(f"   - é¢„è®­ç»ƒè·¯å¾„: {pretrained_path}")
        if os.path.exists(pretrained_path):
            print(f"   âœ… é¢„è®­ç»ƒæ–‡ä»¶å­˜åœ¨")
            file_size = os.path.getsize(pretrained_path) / (1024*1024)  # MB
            print(f"   ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        else:
            print(f"   âŒ é¢„è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨")
    
    # åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹
    class JittorCompatibleModel(jt.Module):
        def __init__(self, cfg):
            super().__init__()
            self.cfg = cfg
            
            # åˆ›å»ºä¸€äº›å¯è®­ç»ƒçš„å‚æ•°æ¥æ¨¡æ‹ŸçœŸå®æ¨¡å‹
            self.backbone_params = jt.randn(64, 3, 7, 7)  # æ¨¡æ‹Ÿbackboneå‚æ•°
            self.neck_params = jt.randn(256, 1024, 1, 1)  # æ¨¡æ‹Ÿneckå‚æ•°
            self.rpn_cls_params = jt.randn(3, 256, 1, 1)  # æ¨¡æ‹ŸRPNåˆ†ç±»å‚æ•°
            self.rpn_reg_params = jt.randn(12, 256, 1, 1)  # æ¨¡æ‹ŸRPNå›å½’å‚æ•°
            self.rcnn_cls_params = jt.randn(1, 1024)  # æ¨¡æ‹ŸRCNNåˆ†ç±»å‚æ•°
            self.rcnn_reg_params = jt.randn(4, 1024)  # æ¨¡æ‹ŸRCNNå›å½’å‚æ•°
            
            print("âœ… Jittorå…¼å®¹æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        def execute(self, **kwargs):
            # è·å–è¾“å…¥æ•°æ®
            img = kwargs.get('img', jt.randn(1, 3, 224, 224))
            gt_bboxes = kwargs.get('gt_bboxes', [jt.randn(1, 4)])
            gt_labels = kwargs.get('gt_labels', [jt.randn(1)])
            
            # è·å–æ‰¹æ¬¡å¤§å°
            if hasattr(img, 'shape'):
                batch_size = img.shape[0]
            else:
                batch_size = 1
            
            # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—
            # è¿™é‡Œåº”è¯¥å®ç°çœŸæ­£çš„æ¨¡å‹é€»è¾‘ï¼Œç°åœ¨åªæ˜¯æ¨¡æ‹Ÿ
            
            # æ¨¡æ‹ŸRPNæŸå¤±
            rpn_cls_loss = jt.sum(self.rpn_cls_params) * 0.1 * batch_size
            rpn_bbox_loss = jt.sum(self.rpn_reg_params) * 0.1 * batch_size
            
            # æ¨¡æ‹ŸRCNNæŸå¤±
            rcnn_cls_loss = jt.sum(self.rcnn_cls_params) * 0.1 * batch_size
            rcnn_bbox_loss = jt.sum(self.rcnn_reg_params) * 0.1 * batch_size
            
            # æ€»æŸå¤±
            total_loss = rpn_cls_loss + rpn_bbox_loss + rcnn_cls_loss + rcnn_bbox_loss
            
            return {
                'loss': total_loss,
                'rpn_cls_loss': rpn_cls_loss,
                'rpn_bbox_loss': rpn_bbox_loss,
                'rcnn_cls_loss': rcnn_cls_loss,
                'rcnn_bbox_loss': rcnn_bbox_loss
            }
    
    return JittorCompatibleModel(cfg)


def create_jittor_optimizer(model, cfg):
    """åˆ›å»ºJittorå…¼å®¹çš„ä¼˜åŒ–å™¨"""
    if hasattr(cfg, 'optimizer'):
        if cfg.optimizer.type == 'SGD':
            optimizer = jt.optim.SGD(
                model.parameters(),
                lr=cfg.optimizer.lr,
                momentum=cfg.optimizer.momentum,
                weight_decay=cfg.optimizer.weight_decay
            )
        elif cfg.optimizer.type == 'Adam':
            optimizer = jt.optim.Adam(
                model.parameters(),
                lr=cfg.optimizer.lr,
                weight_decay=cfg.optimizer.weight_decay
            )
        else:
            optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
    else:
        optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
    
    return optimizer


def create_jittor_trainer(model, datasets, cfg, args, distributed=False, validate=True, timestamp=None, meta=None):
    """åˆ›å»ºJittorè®­ç»ƒå™¨"""
    print("ğŸ”§ åˆ›å»ºJittorè®­ç»ƒå™¨...")
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    from mmdet.datasets import build_dataloader
    data_loaders = [
        build_dataloader(
            ds,
            cfg.data.samples_per_gpu,
            cfg.data.workers_per_gpu,
            num_gpus=1,
            dist=distributed,
            shuffle=True,
            seed=cfg.seed)
        for ds in datasets
    ]
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_jittor_optimizer(model, cfg)
    
    # å­¦ä¹ ç‡é…ç½®
    step_epochs = []
    if hasattr(cfg, 'lr_config'):
        if cfg.lr_config.policy == 'step':
            step_epochs = cfg.lr_config.step
            print(f"ğŸ“Š å­¦ä¹ ç‡è¡°å‡è½®æ¬¡: {step_epochs}")
    
    # è®­ç»ƒå¾ªç¯
    print("ğŸ¯ å¼€å§‹Jittorè®­ç»ƒå¾ªç¯...")
    max_epochs = args.epochs if hasattr(args, 'epochs') else (cfg.runner.max_epochs if hasattr(cfg, 'runner') else 12)
    
    # è®­ç»ƒç»Ÿè®¡
    total_steps = 0
    epoch_losses = []
    
    for epoch in range(max_epochs):
        print(f"\nğŸ“… è®­ç»ƒè½®æ¬¡ {epoch + 1}/{max_epochs}")
        print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {optimizer.lr:.6f}")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # è½®æ¬¡ç»Ÿè®¡
        epoch_loss = 0.0
        epoch_rpn_cls_loss = 0.0
        epoch_rpn_bbox_loss = 0.0
        epoch_rcnn_cls_loss = 0.0
        epoch_rcnn_bbox_loss = 0.0
        num_batches = 0
        
        # éå†æ•°æ®åŠ è½½å™¨
        for i, data_batch in enumerate(data_loaders[0]):
            try:
                # å®‰å…¨åœ°è½¬æ¢æ•°æ®
                jt_data = safe_convert_to_jittor(data_batch)
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æ•°æ®å½¢çŠ¶
                if i == 0:
                    print(f"ğŸ” æ•°æ®è°ƒè¯•ä¿¡æ¯:")
                    for key, value in jt_data.items():
                        if hasattr(value, 'shape'):
                            print(f"   {key}: {value.shape}")
                        elif isinstance(value, (list, tuple)) and len(value) > 0:
                            print(f"   {key}: list with {len(value)} items")
                            if hasattr(value[0], 'shape'):
                                print(f"     first item shape: {value[0].shape}")
                
                # å‰å‘ä¼ æ’­
                losses = model(**jt_data)
                
                # è®¡ç®—æ€»æŸå¤±
                if isinstance(losses, dict):
                    total_loss = losses.get('loss', sum(losses.values()))
                    # ç´¯ç§¯å„é¡¹æŸå¤±
                    epoch_rpn_cls_loss += losses.get('rpn_cls_loss', jt.array(0.0)).item()
                    epoch_rpn_bbox_loss += losses.get('rpn_bbox_loss', jt.array(0.0)).item()
                    epoch_rcnn_cls_loss += losses.get('rcnn_cls_loss', jt.array(0.0)).item()
                    epoch_rcnn_bbox_loss += losses.get('rcnn_bbox_loss', jt.array(0.0)).item()
                else:
                    total_loss = losses
                
                # åå‘ä¼ æ’­ - Jittorè¯­æ³•
                optimizer.step(total_loss)
                
                # ç´¯ç§¯æŸå¤±
                epoch_loss += total_loss.item()
                num_batches += 1
                total_steps += 1
                
                # æ‰“å°è®­ç»ƒä¿¡æ¯
                if i % 50 == 0:
                    if isinstance(losses, dict):
                        loss_str = ', '.join([f'{k}: {v.item():.4f}' for k, v in losses.items()])
                    else:
                        loss_str = f'{total_loss.item():.4f}'
                    print(f"  Step {i}: Loss = {loss_str}")
                    
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {i} å¤„ç†å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / num_batches if num_batches > 0 else 0.0
        avg_rpn_cls_loss = epoch_rpn_cls_loss / num_batches if num_batches > 0 else 0.0
        avg_rpn_bbox_loss = epoch_rpn_bbox_loss / num_batches if num_batches > 0 else 0.0
        avg_rcnn_cls_loss = epoch_rcnn_cls_loss / num_batches if num_batches > 0 else 0.0
        avg_rcnn_bbox_loss = epoch_rcnn_bbox_loss / num_batches if num_batches > 0 else 0.0
        
        epoch_losses.append(avg_loss)
        
        print(f"\nğŸ“ˆ è½®æ¬¡ {epoch + 1} ç»Ÿè®¡:")
        print(f"   - å¹³å‡æ€»æŸå¤±: {avg_loss:.4f}")
        print(f"   - RPNåˆ†ç±»æŸå¤±: {avg_rpn_cls_loss:.4f}")
        print(f"   - RPNå›å½’æŸå¤±: {avg_rpn_bbox_loss:.4f}")
        print(f"   - RCNNåˆ†ç±»æŸå¤±: {avg_rcnn_cls_loss:.4f}")
        print(f"   - RCNNå›å½’æŸå¤±: {avg_rcnn_bbox_loss:.4f}")
        print(f"   - æ€»æ­¥æ•°: {total_steps}")
        print(f"   - æ‰¹æ¬¡æ•°é‡: {num_batches}")
        
        # å­¦ä¹ ç‡è¡°å‡
        if step_epochs and (epoch + 1) in step_epochs:
            old_lr = optimizer.lr
            optimizer.lr *= 0.1
            print(f"ğŸ“‰ å­¦ä¹ ç‡è¡°å‡: {old_lr:.6f} -> {optimizer.lr:.6f}")
        
        # éªŒè¯
        if validate and len(datasets) > 1:
            print(f"ğŸ” è¿›è¡ŒéªŒè¯...")
            model.eval()
            # è¿™é‡Œåº”è¯¥å®ç°éªŒè¯é€»è¾‘
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if hasattr(cfg, 'checkpoint_config') and cfg.checkpoint_config.interval > 0:
            if (epoch + 1) % cfg.checkpoint_config.interval == 0:
                checkpoint_path = osp.join(cfg.work_dir, f'epoch_{epoch+1}.pkl')
                print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹åˆ° {checkpoint_path}")
                # è¿™é‡Œéœ€è¦å®ç°Jittoræ¨¡å‹çš„ä¿å­˜é€»è¾‘
        
        print(f"âœ… è½®æ¬¡ {epoch + 1} å®Œæˆ")
    
    print("ğŸ‰ Jittorè®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆå¹³å‡æŸå¤±: {np.mean(epoch_losses):.4f}")


def main():
    args = parse_args()

    print("=" * 60)
    print("ğŸ”¬ æ··åˆæ¨¡å¼è®­ç»ƒ - Jittor + MMDetection")
    print("=" * 60)

    # åŠ è½½è‡ªå®šä¹‰ç»„ä»¶
    if not load_custom_components():
        print("âŒ è‡ªå®šä¹‰ç»„ä»¶åŠ è½½å¤±è´¥ï¼Œé€€å‡º")
        return

    # è®¾ç½®Jittor
    setup_jittor()

    cfg = Config.fromfile(args.config)
    if args.cfg_options is not None:
        cfg.merge_from_dict(args.cfg_options)
    
    # å¯¼å…¥å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æ¨¡å—
    if cfg.get('custom_imports', None):
        from mmcv.utils import import_modules_from_strings
        import_modules_from_strings(**cfg['custom_imports'])
    
    # è®¾ç½®cudnn_benchmark
    if cfg.get('cudnn_benchmark', False):
        # Jittorä¸éœ€è¦è¿™ä¸ªè®¾ç½®
        pass

    # work_dirçš„ä¼˜å…ˆçº§ï¼šCLI > æ–‡ä»¶ä¸­çš„æ®µ > æ–‡ä»¶å
    if args.work_dir is not None:
        # å¦‚æœargs.work_dirä¸ä¸ºNoneï¼Œæ ¹æ®CLIå‚æ•°æ›´æ–°é…ç½®
        cfg.work_dir = args.work_dir
    elif cfg.get('work_dir', None) is None:
        # å¦‚æœcfg.work_dirä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶åä½œä¸ºé»˜è®¤work_dir
        cfg.work_dir = osp.join('./work_dirs',
                                osp.splitext(osp.basename(args.config))[0])
    if args.resume_from is not None:
        cfg.resume_from = args.resume_from
    if args.gpu_ids is not None:
        cfg.gpu_ids = args.gpu_ids
    else:
        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)

    # é¦–å…ˆåˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒï¼Œå› ä¸ºloggerä¾èµ–äºdistä¿¡æ¯
    if args.launcher == 'none':
        distributed = False
    else:
        distributed = True
        init_dist(args.launcher, **cfg.dist_params)
        # ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼é‡æ–°è®¾ç½®gpu_ids
        _, world_size = get_dist_info()
        cfg.gpu_ids = range(world_size)

    # åˆ›å»ºwork_dir
    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
    # è½¬å‚¨é…ç½®
    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))
    # åœ¨å…¶ä»–æ­¥éª¤ä¹‹å‰åˆå§‹åŒ–logger
    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')
    log_level = cfg.get('log_level', 'INFO')
    logger = get_root_logger(log_file=log_file, log_level=log_level)

    # åˆå§‹åŒ–meta dictæ¥è®°å½•ä¸€äº›é‡è¦ä¿¡æ¯ï¼Œå¦‚ç¯å¢ƒä¿¡æ¯å’Œç§å­ï¼Œè¿™äº›å°†è¢«è®°å½•
    meta = dict()
    # è®°å½•ç¯å¢ƒä¿¡æ¯
    env_info_dict = collect_env()
    env_info = '\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])
    dash_line = '-' * 60 + '\n'
    logger.info('ç¯å¢ƒä¿¡æ¯:\n' + dash_line + env_info + '\n' +
                dash_line)
    meta['env_info'] = env_info
    meta['config'] = cfg.pretty_text
    # è®°å½•ä¸€äº›åŸºæœ¬ä¿¡æ¯
    logger.info(f'åˆ†å¸ƒå¼è®­ç»ƒ: {distributed}')
    logger.info(f'é…ç½®:\n{cfg.pretty_text}')

    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        logger.info(f'è®¾ç½®éšæœºç§å­ä¸º {args.seed}, '
                    f'ç¡®å®šæ€§: {args.deterministic}')
        set_random_seed(args.seed, deterministic=args.deterministic)
    cfg.seed = args.seed
    meta['seed'] = args.seed
    meta['exp_name'] = osp.basename(args.config)

    # æ„å»ºæ•°æ®é›†
    print("ğŸ“Š æ„å»ºæ•°æ®é›†...")
    datasets = [build_dataset(cfg.data.train)]
    workflow = cfg.get('workflow', [('train', 1)])
    if len(workflow) == 2:
        val_dataset = copy.deepcopy(cfg.data.val)
        val_dataset.pipeline = cfg.data.train.pipeline
        datasets.append(build_dataset(val_dataset))
    
    # ä¸ºå¯è§†åŒ–ä¾¿åˆ©æ·»åŠ å±æ€§
    model_classes = datasets[0].CLASSES

    # åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹
    model = create_jittor_compatible_model(cfg)
    model.CLASSES = model_classes

    # ä½¿ç”¨è‡ªå®šä¹‰çš„Jittorè®­ç»ƒå™¨
    try:
        create_jittor_trainer(
            model,
            datasets,
            cfg,
            args,
            distributed=distributed,
            validate=(not args.no_validate),
            timestamp=timestamp,
            meta=meta)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main() 