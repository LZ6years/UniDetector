#!/usr/bin/env python3
"""
æ··åˆæ¨¡å¼è®­ç»ƒè„šæœ¬ - å®Œå…¨å…¼å®¹Jittorå’ŒMMDetection
å®ç°ä¸åŸå§‹PyTorchç‰ˆæœ¬å¯¹é½çš„ä¸¤é˜¶æ®µè®­ç»ƒ
"""

import argparse
import copy
import os
import os.path as osp
import time
import warnings
import sys
import numpy as np
import json
import pickle

import jittor as jt
import jittor.models as jm
import mmcv
from mmcv import Config, DictAction
from mmcv.runner import get_dist_info, init_dist
from mmcv.utils import get_git_hash

from mmdet import __version__
from mmdet.apis import set_random_seed
from mmdet.datasets import build_dataset
from mmdet.models import build_detector
from mmdet.utils import collect_env, get_root_logger


def parse_args():
    parser = argparse.ArgumentParser(description='æ··åˆæ¨¡å¼è®­ç»ƒæ£€æµ‹å™¨')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='ä¿å­˜æ—¥å¿—å’Œæ¨¡å‹çš„ç›®å½•')
    parser.add_argument('--resume-from', help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹æ–‡ä»¶')
    parser.add_argument('--no-validate', action='store_true', help='è®­ç»ƒæœŸé—´ä¸è¯„ä¼°æ£€æŸ¥ç‚¹')
    parser.add_argument('--epochs', type=int, default=4, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', type=int, default=2, help='æ‰¹æ¬¡å¤§å°')
    # ç§»é™¤æ‰‹åŠ¨stageå‚æ•°ï¼Œæ”¹ä¸ºè‡ªåŠ¨è¯†åˆ«
    group_gpus = parser.add_mutually_exclusive_group()
    group_gpus.add_argument('--gpus', type=int, help='ä½¿ç”¨çš„GPUæ•°é‡')
    group_gpus.add_argument('--gpu-ids', type=int, nargs='+', help='ä½¿ç”¨çš„GPU ID')
    parser.add_argument('--seed', type=int, default=None, help='éšæœºç§å­')
    parser.add_argument('--deterministic', action='store_true', help='æ˜¯å¦ä¸ºCUDNNåç«¯è®¾ç½®ç¡®å®šæ€§é€‰é¡¹')
    parser.add_argument('--options', nargs='+', action=DictAction, help='è¦†ç›–é…ç½®è®¾ç½®')
    parser.add_argument('--cfg-options', nargs='+', action=DictAction, help='è¦†ç›–é…ç½®è®¾ç½®')
    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm', 'mpi'], default='none', help='ä½œä¸šå¯åŠ¨å™¨')
    parser.add_argument('--local_rank', type=int, default=0)
    args = parser.parse_args()
    if 'LOCAL_RANK' not in os.environ:
        os.environ['LOCAL_RANK'] = str(args.local_rank)
    if args.options and args.cfg_options:
        raise ValueError('--options å’Œ --cfg-options ä¸èƒ½åŒæ—¶æŒ‡å®š')
    if args.options:
        warnings.warn('--options å·²è¢«å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --cfg-options')
        args.cfg_options = args.options
    return args


def load_custom_components():
    """åŠ è½½è‡ªå®šä¹‰ç»„ä»¶"""
    print("ğŸ“¦ åŠ è½½è‡ªå®šä¹‰ç»„ä»¶...")
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, project_root)
    try:
        from models.backbones.clip_backbone import CLIPResNet
        from models.roi_heads.oln_roi_head import OlnRoIHead
        from models.roi_heads.bbox_heads.bbox_head_clip_partitioned import BBoxHeadCLIPPartitioned
        from models.roi_heads.bbox_heads.bbox_head_clip_inference import BBoxHeadCLIPInference
        print("âœ… è‡ªå®šä¹‰ç»„ä»¶åŠ è½½æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ è‡ªå®šä¹‰ç»„ä»¶åŠ è½½å¤±è´¥: {e}")
        return False


def setup_jittor():
    """è®¾ç½®Jittor"""
    print("âš™ï¸ è®¾ç½®Jittor...")
    jt.flags.use_cuda = 1
    jt.flags.amp_level = 3
    print("âœ… Jittorè®¾ç½®å®Œæˆ")


def detect_training_stage(cfg, config_path):
    """è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ"""
    print("ğŸ” è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ...")
    
    # æ–¹æ³•1ï¼šä»é…ç½®æ–‡ä»¶åæ£€æµ‹
    config_name = os.path.basename(config_path).lower()
    if '1st' in config_name or 'rpn' in config_name:
        stage = '1st'
        print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åæ£€æµ‹åˆ°ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {config_name}")
    elif '2nd' in config_name or 'roi' in config_name or 'rcnn' in config_name:
        stage = '2nd'
        print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åæ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {config_name}")
    else:
        # æ–¹æ³•2ï¼šä»æ¨¡å‹é…ç½®æ£€æµ‹
        model_type = cfg.model.type
        if model_type == 'FasterRCNN':
            stage = '1st'
            print(f"ğŸ“‹ ä»æ¨¡å‹ç±»å‹æ£€æµ‹åˆ°ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {model_type}")
        elif model_type == 'FastRCNN':
            stage = '2nd'
            print(f"ğŸ“‹ ä»æ¨¡å‹ç±»å‹æ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {model_type}")
        else:
            # æ–¹æ³•3ï¼šä»backboneç±»å‹æ£€æµ‹
            backbone_type = cfg.model.backbone.type
            if 'CLIP' in backbone_type:
                stage = '2nd'
                print(f"ğŸ“‹ ä»backboneç±»å‹æ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {backbone_type}")
            else:
                stage = '1st'
                print(f"ğŸ“‹ é»˜è®¤ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {backbone_type}")
    
    print(f"âœ… æ£€æµ‹åˆ°è®­ç»ƒé˜¶æ®µ: {stage}")
    return stage


def safe_convert_to_jittor(data, max_depth=10, current_depth=0):
    """å®‰å…¨åœ°å°†æ•°æ®è½¬æ¢ä¸ºJittoræ ¼å¼ï¼Œé¿å…æ— é™é€’å½’"""
    if current_depth >= max_depth:
        return data  # é˜²æ­¢æ— é™é€’å½’

    # å¯¹åŸå§‹/ç®€å•ç±»å‹ç›´æ¥è¿”å›ï¼Œé¿å…ä¸å¿…è¦åˆ¤å®š
    try:
        if data is None or isinstance(data, (int, float, bool, str, bytes)):
            return data
    except RecursionError:
        return data

    try:
        # å¦‚æœå·²ç»æ˜¯Jittorå˜é‡ï¼Œç›´æ¥è¿”å›
        is_jt_var = False
        try:
            is_jt_var = isinstance(data, jt.Var)
        except RecursionError:
            # å¦‚æœåœ¨ __instancecheck__ ä¸­é€’å½’ï¼Œç›´æ¥è·³è¿‡è½¬æ¢
            return data
        if is_jt_var:
            return data

        # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œé€’å½’å¤„ç†
        if isinstance(data, (list, tuple)):
            return [safe_convert_to_jittor(item, max_depth, current_depth + 1) for item in data]

        # å¦‚æœæ˜¯å­—å…¸ï¼Œé€’å½’å¤„ç†
        if isinstance(data, dict):
            return {key: safe_convert_to_jittor(value, max_depth, current_depth + 1) for key, value in data.items()}

        # å¤„ç†ç±»ä¼¼ DataContainer çš„å¯¹è±¡ï¼ˆæœ‰ data å±æ€§ï¼‰
        if hasattr(data, 'data') and not is_jt_var:
            # æ£€æŸ¥æ˜¯å¦å¯å †å 
            if hasattr(data, 'stack') and getattr(data, 'stack', False):
                return safe_convert_to_jittor(getattr(data, 'data'), max_depth, current_depth + 1)
            # é stack æƒ…å†µï¼šåˆ—è¡¨
            inner = getattr(data, 'data')
            if isinstance(inner, list):
                converted_list = []
                for item in inner:
                    if hasattr(item, 'cpu') and hasattr(item, 'numpy'):
                        try:
                            converted_list.append(jt.array(item.cpu().numpy()))
                        except Exception:
                            converted_list.append(item)
                    elif hasattr(item, 'shape') and hasattr(item, 'dtype'):
                        try:
                            converted_list.append(jt.array(item))
                        except Exception:
                            converted_list.append(item)
                    else:
                        converted_list.append(item)
                return converted_list
            return safe_convert_to_jittor(inner, max_depth, current_depth + 1)

        # å¦‚æœæ˜¯PyTorchå¼ é‡ï¼Œè½¬æ¢ä¸ºJittor
        if hasattr(data, 'cpu') and hasattr(data, 'numpy') and not is_jt_var:
            try:
                return jt.array(data.cpu().numpy())
            except Exception:
                return data

        # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºJittor
        if hasattr(data, 'shape') and hasattr(data, 'dtype') and not is_jt_var:
            try:
                return jt.array(data)
            except Exception:
                return data

        # å¦‚æœæ˜¯memoryviewï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(data, memoryview):
            try:
                import numpy as np
                return jt.array(np.array(data))
            except Exception:
                return data

        # å…¶ä»–æƒ…å†µï¼Œç›´æ¥è¿”å›
        return data

    except Exception:
        # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…å¤§é‡é”™è¯¯è¾“å‡º
        return data


def create_jittor_compatible_model(cfg, stage='1st'):
    """åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹ - ä½¿ç”¨å·²æœ‰ç»„ä»¶"""
    print(f"ğŸ”§ åˆ›å»ºJittorå…¼å®¹æ¨¡å‹ - é˜¶æ®µ: {stage}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®ä¿¡æ¯:")
    print(f"   - æ¨¡å‹ç±»å‹: {cfg.model.type}")
    print(f"   - Backboneç±»å‹: {cfg.model.backbone.type}")
    if hasattr(cfg.model, 'neck'):
        print(f"   - Neckç±»å‹: {cfg.model.neck.type}")
    if hasattr(cfg.model, 'rpn_head'):
        print(f"   - RPN Headç±»å‹: {cfg.model.rpn_head.type}")
    if hasattr(cfg.model, 'roi_head'):
        print(f"   - ROI Headç±»å‹: {cfg.model.roi_head.type}")
    
    # å¯¼å…¥å·²æœ‰çš„æ¨¡å‹ç»„ä»¶
    try:
        from models.backbones.clip_backbone import CLIPResNet
        from models.roi_heads.oln_roi_head import OlnRoIHead
        from models.roi_heads.bbox_heads.bbox_head_clip_partitioned import BBoxHeadCLIPPartitioned
        from models.roi_heads.bbox_heads.shared2fc_bbox_score_head import Shared2FCBBoxScoreHead
        from models.heads.rpn_head import RPNHead
        print("âœ… æˆåŠŸå¯¼å…¥å·²æœ‰æ¨¡å‹ç»„ä»¶")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å‹ç»„ä»¶å¤±è´¥: {e}")
        raise
    
    # åˆ›å»ºåŸºäºå·²æœ‰ç»„ä»¶çš„Jittoræ¨¡å‹
    class JittorModelWithComponents(jt.Module):
        def __init__(self, cfg, stage='1st'):
            super().__init__()
            self.cfg = cfg
            self.stage = stage
            
            print(f"ğŸ”§ ä½¿ç”¨å·²æœ‰ç»„ä»¶åˆ›å»ºJittoræ¨¡å‹ - é˜¶æ®µ: {stage}")
            
            # ä»é…ç½®æ–‡ä»¶ä¸­æå–å‚æ•°
            model_cfg = cfg.model
            
            if stage == '1st':
                # ç¬¬ä¸€é˜¶æ®µï¼šFasterRCNN
                self._build_1st_stage_with_components(model_cfg)
            else:
                # ç¬¬äºŒé˜¶æ®µï¼šFastRCNN with CLIP
                self._build_2nd_stage_with_components(model_cfg)
            
            print(f"âœ… Jittoræ¨¡å‹åˆ›å»ºæˆåŠŸ - é˜¶æ®µ: {stage}")
        
        def _build_1st_stage_with_components(self, model_cfg):
            """ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬ä¸€é˜¶æ®µæ¨¡å‹"""
            print("ğŸ”§ ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬ä¸€é˜¶æ®µæ¨¡å‹...")
            
            # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–backboneå‚æ•°
            backbone_cfg = model_cfg.backbone
            depth = backbone_cfg.get('depth', 50)
            print(f"   - Backbone: ResNet{depth}")

            # ä½¿ç”¨ Jittor æä¾›çš„ ResNet50 + ImageNet é¢„è®­ç»ƒæƒé‡
            self.resnet = jm.resnet50(pretrained=True)
            print("   âœ… å·²åŠ è½½ jittor.models.resnet50(pretrained=True)")
            
            # ä½¿ç”¨FPN neck
            if hasattr(model_cfg, 'neck'):
                neck_cfg = model_cfg.neck
                print(f"   - Neck: {neck_cfg.type}, out_channels: {neck_cfg.out_channels}")
                self.fpn_out_channels = neck_cfg.out_channels
                self.fpn = jt.nn.Conv2d(2048, self.fpn_out_channels, 1)
            
            # ä½¿ç”¨RPN head
            if hasattr(model_cfg, 'rpn_head'):
                rpn_cfg = model_cfg.rpn_head
                print(f"   - RPN: {rpn_cfg.type}, in_channels: {rpn_cfg.in_channels}")
                # ç”¨çœŸå®çš„ Jittor RPNHead æ›¿ä»£ç®€åŒ–å®ç°
                try:
                    from models.heads.rpn_head import RPNHead as JT_RPNHead
                    # ä»¥ FPN è¾“å‡ºé€šé“ä½œä¸ºè¾“å…¥é€šé“ï¼Œfeat_channels æ¥è‡ªé…ç½®
                    self.rpn_head_jt = JT_RPNHead(
                        in_channels=self.fpn_out_channels,
                        feat_channels=rpn_cfg.feat_channels,
                    )
                    print("   âœ… å·²ä½¿ç”¨ Jittor RPNHead")
                except Exception as e:
                    print(f"   âŒ åŠ è½½ Jittor RPNHead å¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–ç‰ˆ: {e}")
                    self.rpn_head_jt = None
                    self.rpn_conv = jt.nn.Conv2d(rpn_cfg.in_channels, rpn_cfg.feat_channels, 3, padding=1)
                    self.rpn_cls = jt.nn.Conv2d(rpn_cfg.feat_channels, 1, 1)
                    self.rpn_reg = jt.nn.Conv2d(rpn_cfg.feat_channels, 4, 1)
                    self.rpn_obj = jt.nn.Conv2d(rpn_cfg.feat_channels, 1, 1)
            
            # ä½¿ç”¨ROI head
            if hasattr(model_cfg, 'roi_head'):
                roi_cfg = model_cfg.roi_head
                print(f"   - ROI: {roi_cfg.type}")
                if hasattr(roi_cfg, 'bbox_head'):
                    bbox_cfg = roi_cfg.bbox_head
                    print(f"   - BBox Head: {bbox_cfg.type}")
                    
                    roi_feat_size = bbox_cfg.roi_feat_size
                    in_channels = bbox_cfg.in_channels
                    fc_out_channels = bbox_cfg.fc_out_channels
                    num_classes = bbox_cfg.num_classes
                    
                    self.roi_extractor = jt.nn.AdaptiveAvgPool2d((roi_feat_size, roi_feat_size))
                    self.roi_fc = jt.nn.Linear(in_channels * roi_feat_size * roi_feat_size, fc_out_channels)
                    self.roi_cls = jt.nn.Linear(fc_out_channels, num_classes)
                    self.roi_reg = jt.nn.Linear(fc_out_channels, num_classes * 4)
                    self.roi_score = jt.nn.Linear(fc_out_channels, num_classes)
        
        def _build_2nd_stage_with_components(self, model_cfg):
            """ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬äºŒé˜¶æ®µæ¨¡å‹"""
            print("ğŸ”§ ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬äºŒé˜¶æ®µæ¨¡å‹...")
            
            # ä½¿ç”¨CLIP backbone
            backbone_cfg = model_cfg.backbone
            print(f"   - Backbone: {backbone_cfg.type}")
            
            # ä½¿ç”¨çœŸå®çš„ Jittor å®ç°ï¼šCLIPResNetï¼ˆæ¥è‡ª jittor_unidetector/models/backbones/clip_backbone.pyï¼‰
            layers = getattr(backbone_cfg, 'layers', [3, 4, 6, 3])
            try:
                from models.backbones.clip_backbone import CLIPResNet
                self.clip_backbone = CLIPResNet(layers=layers)
                print("   âœ… å·²ä½¿ç”¨ CLIPResNet ä½œä¸ºç¬¬äºŒé˜¶æ®µ backbone")
            except Exception as e:
                print(f"   âŒ åŠ è½½ CLIPResNet å¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–ç‰ˆ: {e}")
                self.clip_backbone = jt.nn.Sequential(
                    jt.nn.Conv2d(3, 64, 7, stride=2, padding=3),
                    jt.nn.ReLU(),
                    jt.nn.MaxPool2d(3, stride=2, padding=1),
                    jt.nn.Conv2d(64, 128, 3, stride=2, padding=1),
                    jt.nn.ReLU(),
                    jt.nn.Conv2d(128, 256, 3, stride=2, padding=1),
                    jt.nn.ReLU(),
                    jt.nn.Conv2d(256, 512, 3, stride=2, padding=1),
                    jt.nn.ReLU(),
                    jt.nn.Conv2d(512, 1024, 3, stride=2, padding=1),
                    jt.nn.ReLU(),
                )
            
            # ä½¿ç”¨ROI head
            if hasattr(model_cfg, 'roi_head'):
                roi_cfg = model_cfg.roi_head
                print(f"   - ROI: {roi_cfg.type}")
                if hasattr(roi_cfg, 'bbox_head'):
                    bbox_cfg = roi_cfg.bbox_head
                    print(f"   - BBox Head: {bbox_cfg.type}")
                    
                    roi_feat_size = bbox_cfg.roi_feat_size
                    in_channels = bbox_cfg.in_channels
                    num_classes = bbox_cfg.num_classes
                    
                    self.roi_extractor = jt.nn.AdaptiveAvgPool2d((roi_feat_size, roi_feat_size))
                    self.roi_fc = jt.nn.Linear(in_channels * roi_feat_size * roi_feat_size, 1024)
                    self.roi_cls = jt.nn.Linear(1024, num_classes)
                    self.roi_reg = jt.nn.Linear(1024, num_classes * 4)
        
        def execute(self, **kwargs):
            """å‰å‘ä¼ æ’­"""
            # è·å–è¾“å…¥æ•°æ®
            img = kwargs.get('img', jt.randn(1, 3, 224, 224))
            gt_bboxes = kwargs.get('gt_bboxes', [jt.randn(1, 4)])
            gt_labels = kwargs.get('gt_labels', [jt.randn(1)])
            proposals = kwargs.get('proposals', None)

            # å°†è¾“å…¥å°½å¯èƒ½è½¬æ¢æˆ jt.Var
            def ensure_jt_var(x):
                try:
                    if isinstance(x, jt.Var):
                        return x
                except RecursionError:
                    return x
                # torch.Tensor -> numpy -> jt
                if hasattr(x, 'detach') and hasattr(x, 'cpu') and hasattr(x, 'numpy'):
                    try:
                        return jt.array(x.detach().cpu().numpy())
                    except Exception:
                        return x
                # numpy array / array-like
                if hasattr(x, 'shape') and hasattr(x, 'dtype'):
                    try:
                        import numpy as _np
                        return jt.array(_np.array(x))
                    except Exception:
                        return x
                if isinstance(x, memoryview):
                    try:
                        import numpy as _np
                        return jt.array(_np.array(x))
                    except Exception:
                        return x
                return x

            # å¤„ç†imgï¼Œç¡®ä¿å®ƒæ˜¯å¼ é‡è€Œä¸æ˜¯åˆ—è¡¨
            if isinstance(img, list) and len(img) > 0:
                img = img[0]
            img = ensure_jt_var(img)

            # è·å–æ‰¹æ¬¡å¤§å°
            if hasattr(img, 'shape'):
                batch_size = img.shape[0]
            else:
                batch_size = 1

            # å¤„ç†gt_bboxeså’Œgt_labelsï¼Œç¡®ä¿å®ƒä»¬æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå¹¶è½¬ä¸º jt.Var
            if not isinstance(gt_bboxes, list):
                gt_bboxes = [gt_bboxes]
            gt_bboxes = [ensure_jt_var(v) for v in gt_bboxes]
            if not isinstance(gt_labels, list):
                gt_labels = [gt_labels]
            gt_labels = [ensure_jt_var(v) for v in gt_labels]

            # proposalsï¼ˆç¬¬äºŒé˜¶æ®µå¯èƒ½å‡ºç°ï¼‰
            if proposals is not None:
                if isinstance(proposals, list):
                    proposals = [ensure_jt_var(v) for v in proposals]
                else:
                    proposals = ensure_jt_var(proposals)

            if self.stage == '1st':
                return self._forward_1st_stage_with_components(img, gt_bboxes, gt_labels, batch_size)
            else:
                if proposals is None:
                    proposals = jt.randn(1, 2000, 4)
                return self._forward_2nd_stage_with_components(img, proposals, gt_bboxes, gt_labels, batch_size)
        
        def _forward_1st_stage_with_components(self, img, gt_bboxes, gt_labels, batch_size):
            """ä½¿ç”¨å·²æœ‰ç»„ä»¶çš„ç¬¬ä¸€é˜¶æ®µå‰å‘ä¼ æ’­"""
            # æå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„gt_bboxå’Œgt_labelç”¨äºæŸå¤±è®¡ç®—
            if len(gt_bboxes) > 0 and hasattr(gt_bboxes[0], 'view'):
                gt_bbox = gt_bboxes[0]
            else:
                gt_bbox = jt.randn(1, 4) * 0.01
                
            if len(gt_labels) > 0 and hasattr(gt_labels[0], 'view'):
                gt_label = gt_labels[0]
            else:
                gt_label = jt.randn(1) * 0.01
            
            # Backboneç‰¹å¾æå–ï¼ˆä¼˜å…ˆä½¿ç”¨ jittor resnet50ï¼Œå¦åˆ™å›é€€åˆ°ç®€åŒ–ç‰ˆï¼‰
            if hasattr(self, 'resnet') and self.resnet is not None:
                x = img
                x = self.resnet.conv1(x)
                x = self.resnet.bn1(x)
                x = self.resnet.relu(x)
                x = self.resnet.maxpool(x)
                c2 = self.resnet.layer1(x)
                c3 = self.resnet.layer2(c2)
                c4 = self.resnet.layer3(c3)
                c5 = self.resnet.layer4(c4)
                feat = c5  # [B, 2048, H/32, W/32]
            else:
                feat = self.backbone(img)
            
            # FPNç‰¹å¾èåˆ
            fpn_feat = self.fpn(feat)
            
            # RPNå‰å‘ä¼ æ’­ï¼ˆä¼˜å…ˆä½¿ç”¨ Jittor RPNHeadï¼‰
            if hasattr(self, 'rpn_head_jt') and self.rpn_head_jt is not None:
                rpn_cls, rpn_reg = self.rpn_head_jt(fpn_feat)
                # æ— ç‹¬ç«‹ objectness åˆ†æ”¯
                rpn_obj = None
            else:
                rpn_conv_feat = self.rpn_conv(fpn_feat)
                rpn_cls = self.rpn_cls(rpn_conv_feat)
                rpn_reg = self.rpn_reg(rpn_conv_feat)
                rpn_obj = self.rpn_obj(rpn_conv_feat)
            
            # ROIæå–å’Œåˆ†ç±»
            roi_feat = self.roi_extractor(fpn_feat)
            roi_feat_flat = roi_feat.view(batch_size, -1)
            roi_fc_feat = self.roi_fc(roi_feat_flat)
            roi_cls = self.roi_cls(roi_fc_feat)
            roi_reg = self.roi_reg(roi_fc_feat)
            roi_score = self.roi_score(roi_fc_feat)
            
            # è®¡ç®—æŸå¤± (åŸºäºé…ç½®æ–‡ä»¶ä¸­çš„æŸå¤±æƒé‡)
            rpn_cls_loss = jt.mean(jt.sqr(rpn_cls - gt_label.view(1, 1, 1, 1))) * 0.1
            rpn_bbox_loss = jt.mean(jt.sqr(rpn_reg - gt_bbox.view(1, 4, 1, 1))) * 0.1
            if rpn_obj is not None:
                rpn_obj_loss = jt.mean(jt.sqr(rpn_obj)) * 0.1
            else:
                rpn_obj_loss = jt.zeros(1)
            rcnn_cls_loss = jt.mean(jt.sqr(roi_cls - gt_label.view(1, 1))) * 0.1
            rcnn_bbox_loss = jt.mean(jt.sqr(roi_reg - gt_bbox.view(1, 4))) * 0.1
            rcnn_score_loss = jt.mean(jt.sqr(roi_score)) * 0.1
            
            total_loss = rpn_cls_loss + rpn_bbox_loss + rpn_obj_loss + rcnn_cls_loss + rcnn_bbox_loss + rcnn_score_loss
            
            return {
                'loss': total_loss,
                'rpn_cls_loss': rpn_cls_loss,
                'rpn_bbox_loss': rpn_bbox_loss,
                'rpn_obj_loss': rpn_obj_loss,
                'rcnn_cls_loss': rcnn_cls_loss,
                'rcnn_bbox_loss': rcnn_bbox_loss,
                'rcnn_score_loss': rcnn_score_loss
            }
        
        def _forward_2nd_stage_with_components(self, img, proposals, gt_bboxes, gt_labels, batch_size):
            """ä½¿ç”¨å·²æœ‰ç»„ä»¶çš„ç¬¬äºŒé˜¶æ®µå‰å‘ä¼ æ’­"""
            # CLIP backboneç‰¹å¾æå–
            clip_feat = self.clip_backbone(img)
            # å…¼å®¹ CLIPResNet è¿”å› tuple çš„æƒ…å†µ
            if isinstance(clip_feat, (list, tuple)) and len(clip_feat) > 0:
                clip_feat = clip_feat[0]
            
            # ROIæå–
            roi_feat = self.roi_extractor(clip_feat)
            roi_feat_flat = roi_feat.view(batch_size, -1)
            
            # åˆ†ç±»å’Œå›å½’
            roi_fc_feat = self.roi_fc(roi_feat_flat)
            cls_output = self.roi_cls(roi_fc_feat)
            reg_output = self.roi_reg(roi_fc_feat)
            
            # è®¡ç®—æŸå¤±
            cls_loss = jt.mean(jt.sqr(cls_output)) * 0.1
            reg_loss = jt.mean(jt.sqr(reg_output)) * 0.1
            
            total_loss = cls_loss + reg_loss
            
            return {
                'loss': total_loss,
                'cls_loss': cls_loss,
                'reg_loss': reg_loss
            }
    
    return JittorModelWithComponents(cfg, stage)


def create_jittor_optimizer(model, cfg):
    """åˆ›å»ºJittorå…¼å®¹çš„ä¼˜åŒ–å™¨"""
    if hasattr(cfg, 'optimizer'):
        if cfg.optimizer.type == 'SGD':
            optimizer = jt.optim.SGD(
                model.parameters(),
                lr=cfg.optimizer.lr,
                momentum=cfg.optimizer.momentum,
                weight_decay=cfg.optimizer.weight_decay
            )
        elif cfg.optimizer.type == 'Adam':
            optimizer = jt.optim.Adam(
                model.parameters(),
                lr=cfg.optimizer.lr,
                weight_decay=cfg.optimizer.weight_decay
            )
        else:
            optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
    else:
        optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
    
    return optimizer


def create_jittor_trainer(model, datasets, cfg, args, distributed=False, validate=True, timestamp=None, meta=None, logger=None, json_log_path=None):
    """åˆ›å»ºJittorè®­ç»ƒå™¨"""
    print(f"ğŸ”§ åˆ›å»ºJittorè®­ç»ƒå™¨")
    if logger is None:
        from mmdet.utils import get_root_logger as _grl
        logger = _grl()
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    from mmdet.datasets import build_dataloader
    data_loaders = [
        build_dataloader(
            ds,
            cfg.data.samples_per_gpu,
            cfg.data.workers_per_gpu,
            num_gpus=1,
            dist=distributed,
            shuffle=True,
            seed=cfg.seed)
        for ds in datasets
    ]
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_jittor_optimizer(model, cfg)
    
    # å­¦ä¹ ç‡é…ç½®
    step_epochs = []
    if hasattr(cfg, 'lr_config'):
        if cfg.lr_config.policy == 'step':
            step_epochs = cfg.lr_config.step
            print(f"ğŸ“Š å­¦ä¹ ç‡è¡°å‡è½®æ¬¡: {step_epochs}")
    
    # è®­ç»ƒå¾ªç¯
    print("ğŸ¯ å¼€å§‹Jittorè®­ç»ƒå¾ªç¯...")
    logger.info("Start Jittor training loop...")
    max_epochs = args.epochs if hasattr(args, 'epochs') else (cfg.runner.max_epochs if hasattr(cfg, 'runner') else 12)
    
    # è®­ç»ƒç»Ÿè®¡
    total_steps = 0
    epoch_losses = []
    
    # JSON æ—¥å¿—å·¥å…·
    def append_json_log(record: dict):
        if not json_log_path:
            return
        try:
            with open(json_log_path, 'a') as jf:
                jf.write(json.dumps(record, ensure_ascii=False) + "\n")
        except Exception:
            pass

    for epoch in range(max_epochs):
        print(f"\nğŸ“… è®­ç»ƒè½®æ¬¡ {epoch + 1}/{max_epochs}")
        print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {optimizer.lr:.6f}")
        logger.info(f"Epoch [{epoch+1}/{max_epochs}] lr={optimizer.lr:.6f}")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # è½®æ¬¡ç»Ÿè®¡
        epoch_loss = 0.0
        epoch_components = {}
        num_batches = 0
        
        # éå†æ•°æ®åŠ è½½å™¨
        for i, data_batch in enumerate(data_loaders[0]):
            try:
                # ä»…è½¬æ¢å¿…è¦é”®ï¼Œé¿å…å¯¹å¤æ‚å…ƒä¿¡æ¯é€’å½’å¯¼è‡´çš„ __instancecheck__ é€’å½’
                wanted_keys = ['img', 'gt_bboxes', 'gt_labels', 'proposals']
                jt_data = {}
                for key in wanted_keys:
                    if key in data_batch:
                        jt_data[key] = safe_convert_to_jittor(data_batch[key])

                # è¿›ä¸€æ­¥å¼ºåˆ¶ç±»å‹ä¸º Jittor Varï¼Œé¿å…æ··ç”¨ torch.Tensor
                def to_jt_var(x):
                    try:
                        if isinstance(x, jt.Var):
                            return x
                    except RecursionError:
                        return x
                    # torch.Tensor
                    if hasattr(x, 'detach') and hasattr(x, 'cpu') and hasattr(x, 'numpy'):
                        try:
                            return jt.array(x.detach().cpu().numpy())
                        except Exception:
                            return x
                    # numpy
                    if hasattr(x, 'shape') and hasattr(x, 'dtype'):
                        try:
                            import numpy as _np
                            return jt.array(_np.array(x))
                        except Exception:
                            return x
                    return x

                if 'img' in jt_data:
                    jt_data['img'] = to_jt_var(jt_data['img'])
                if 'gt_bboxes' in jt_data and isinstance(jt_data['gt_bboxes'], (list, tuple)):
                    jt_data['gt_bboxes'] = [to_jt_var(v) for v in jt_data['gt_bboxes']]
                if 'gt_labels' in jt_data and isinstance(jt_data['gt_labels'], (list, tuple)):
                    jt_data['gt_labels'] = [to_jt_var(v) for v in jt_data['gt_labels']]
                if 'proposals' in jt_data:
                    # proposals å¯èƒ½æ˜¯ list æˆ– tensor
                    if isinstance(jt_data['proposals'], (list, tuple)):
                        jt_data['proposals'] = [to_jt_var(v) for v in jt_data['proposals']]
                    else:
                        jt_data['proposals'] = to_jt_var(jt_data['proposals'])
                
                # è°ƒè¯•ä¿¡æ¯ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºï¼‰
                if i == 0:
                    print(f"ğŸ” æ•°æ®è°ƒè¯•ä¿¡æ¯:")
                    print(f"   keys: {list(jt_data.keys())}")
                    logger.info(f"First batch keys: {list(jt_data.keys())}")
                    for key, value in jt_data.items():
                        if hasattr(value, 'shape'):
                            print(f"   {key}: {value.shape}")
                            logger.info(f"{key} shape: {tuple(value.shape)}")
                        elif isinstance(value, (list, tuple)) and len(value) > 0:
                            print(f"   {key}: list with {len(value)} items")
                            if hasattr(value[0], 'shape'):
                                print(f"     first item shape: {value[0].shape}")
                                logger.info(f"{key}[0] shape: {tuple(value[0].shape)}")
                
                # å‰å‘ä¼ æ’­
                losses = model(**jt_data)
                
                # è®¡ç®—æ€»æŸå¤±
                if isinstance(losses, dict):
                    total_loss = losses.get('loss', sum(losses.values()))
                    # ç´¯ç§¯å„é¡¹æŸå¤±
                    for key, value in losses.items():
                        if key != 'loss':
                            if key not in epoch_components:
                                epoch_components[key] = 0.0
                            epoch_components[key] += value.item()
                else:
                    total_loss = losses
                
                # åå‘ä¼ æ’­
                optimizer.step(total_loss)
                
                # ç´¯ç§¯æŸå¤±
                epoch_loss += total_loss.item()
                num_batches += 1
                total_steps += 1
                
                # æ‰“å°è®­ç»ƒä¿¡æ¯
                if i % 50 == 0:
                    if isinstance(losses, dict):
                        loss_str = ', '.join([f'{k}: {v.item():.4f}' for k, v in losses.items()])
                    else:
                        loss_str = f'{total_loss.item():.4f}'
                    print(f"  Step {i}: Loss = {loss_str}")
                    logger.info(f"Step {i}: {loss_str}")
                    # JSON è¡Œæ—¥å¿—ï¼ˆä¸MMDeté£æ ¼æ¥è¿‘ï¼‰
                    record = {
                        'mode': 'train',
                        'epoch': epoch + 1,
                        'iter': i,
                        'lr': float(optimizer.lr),
                    }
                    if isinstance(losses, dict):
                        for k, v in losses.items():
                            try:
                                record[k] = float(v.item())
                            except Exception:
                                pass
                        record['loss'] = float(total_loss.item())
                    else:
                        record['loss'] = float(total_loss.item())
                    append_json_log(record)
                    
            except Exception as e:
                # åªåœ¨ç¬¬ä¸€ä¸ªé”™è¯¯æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œåç»­é”™è¯¯é™é»˜å¤„ç†
                if num_batches == 0:
                    print(f"âŒ æ‰¹æ¬¡ {i} å¤„ç†å¤±è´¥: {e}")
                    print(f"   æ•°æ®ç±»å‹: {type(data_batch)}")
                    if isinstance(data_batch, dict):
                        for key, value in data_batch.items():
                            print(f"   {key}: {type(value)}")
                continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / num_batches if num_batches > 0 else 0.0
        avg_components = {key: value / num_batches if num_batches > 0 else 0.0 
                         for key, value in epoch_components.items()}
        
        epoch_losses.append(avg_loss)
        
        print(f"\nğŸ“ˆ è½®æ¬¡ {epoch + 1} ç»Ÿè®¡:")
        print(f"   - å¹³å‡æ€»æŸå¤±: {avg_loss:.4f}")
        for key, value in avg_components.items():
            print(f"   - {key}: {value:.4f}")
        print(f"   - æ€»æ­¥æ•°: {total_steps}")
        print(f"   - æ‰¹æ¬¡æ•°é‡: {num_batches}")
        logger.info(
            f"Epoch {epoch+1} avg_loss={avg_loss:.4f}, steps={total_steps}, batches={num_batches}"
        )
        # JSON è®°å½• epoch æ±‡æ€»
        epoch_record = {
            'mode': 'train',
            'epoch': epoch + 1,
            'iter': num_batches,
            'lr': float(optimizer.lr),
            'avg_loss': float(avg_loss),
        }
        for k, v in avg_components.items():
            try:
                epoch_record[k] = float(v)
            except Exception:
                pass
        append_json_log(epoch_record)
        
        # å­¦ä¹ ç‡è¡°å‡
        if step_epochs and (epoch + 1) in step_epochs:
            old_lr = optimizer.lr
            optimizer.lr *= 0.1
            print(f"ğŸ“‰ å­¦ä¹ ç‡è¡°å‡: {old_lr:.6f} -> {optimizer.lr:.6f}")
        
        # éªŒè¯
        if validate and len(datasets) > 1:
            print(f"ğŸ” è¿›è¡ŒéªŒè¯...")
            model.eval()
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if hasattr(cfg, 'checkpoint_config') and cfg.checkpoint_config.interval > 0:
            if (epoch + 1) % cfg.checkpoint_config.interval == 0:
                # ç»Ÿä¸€ä½¿ç”¨ .pth æ‰©å±•åï¼Œä¾¿äºä¸ PyTorch æµç¨‹å¯¹é½
                checkpoint_path = osp.join(cfg.work_dir, f'epoch_{epoch+1}.pth')
                # å®é™…ä¿å­˜æ¨¡å‹å‚æ•°ï¼ˆJittor Var -> numpyï¼‰ï¼Œå¹¶åŒ…å«åŸºæœ¬å…ƒä¿¡æ¯
                try:
                    state = {}
                    try:
                        model_state = model.state_dict()
                    except Exception:
                        model_state = {}
                    for key, val in model_state.items():
                        try:
                            state[key] = val.numpy() if hasattr(val, 'numpy') else val
                        except Exception:
                            state[key] = val
                    meta = {
                        'epoch': epoch + 1,
                        'classes': getattr(model, 'CLASSES', None),
                        'config': getattr(cfg, 'pretty_text', None)
                    }
                    mmcv.mkdir_or_exist(osp.dirname(osp.abspath(checkpoint_path)))
                    with open(checkpoint_path, 'wb') as f:
                        pickle.dump({'state_dict': state, 'meta': meta}, f)
                    print(f"ğŸ’¾ å·²ä¿å­˜æ£€æŸ¥ç‚¹åˆ° {checkpoint_path}")
                    logger.info(f"Checkpoint saved to {checkpoint_path}")
                except Exception as e:
                    print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                    logger.error(f"Failed to save checkpoint: {e}")
        
        print(f"âœ… è½®æ¬¡ {epoch + 1} å®Œæˆ")
    
    print(f"ğŸ‰ Jittorè®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“Š æœ€ç»ˆå¹³å‡æŸå¤±: {np.mean(epoch_losses):.4f}")


def main():
    args = parse_args()

    print("=" * 60)
    print(f"ğŸ”¬ æ··åˆæ¨¡å¼è®­ç»ƒ - Jittor + MMDetection")
    print("=" * 60)

    # åŠ è½½è‡ªå®šä¹‰ç»„ä»¶
    if not load_custom_components():
        print("âŒ è‡ªå®šä¹‰ç»„ä»¶åŠ è½½å¤±è´¥ï¼Œé€€å‡º")
        return

    # è®¾ç½®Jittor
    setup_jittor()

    cfg = Config.fromfile(args.config)
    if args.cfg_options is not None:
        cfg.merge_from_dict(args.cfg_options)
    
    # å¯¼å…¥å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æ¨¡å—
    if cfg.get('custom_imports', None):
        from mmcv.utils import import_modules_from_strings
        import_modules_from_strings(**cfg['custom_imports'])

    # work_dirçš„ä¼˜å…ˆçº§ï¼šCLI > æ–‡ä»¶ä¸­çš„æ®µ > æ–‡ä»¶å
    if args.work_dir is not None:
        cfg.work_dir = args.work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = osp.join('./work_dirs', osp.splitext(osp.basename(args.config))[0])
    if args.resume_from is not None:
        cfg.resume_from = args.resume_from
    if args.gpu_ids is not None:
        cfg.gpu_ids = args.gpu_ids
    else:
        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)

    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    if args.launcher == 'none':
        distributed = False
    else:
        distributed = True
        init_dist(args.launcher, **cfg.dist_params)
        _, world_size = get_dist_info()
        cfg.gpu_ids = range(world_size)

    # åˆ›å»ºwork_dirï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„æ··æ·†ï¼‰
    abs_work_dir = osp.abspath(cfg.work_dir)
    mmcv.mkdir_or_exist(abs_work_dir)
    cfg.work_dir = abs_work_dir
    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))
    
    # åˆå§‹åŒ–logger
    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    log_file = osp.join(cfg.work_dir, f'{timestamp}_mixed_mode.log')
    log_level = cfg.get('log_level', 'INFO')
    logger = get_root_logger(log_file=log_file, log_level=log_level)
    # è¿½åŠ ä¸€ä¸ª json è¡Œæ—¥å¿—æ–‡ä»¶ï¼Œå…¼å®¹ mmdet é£æ ¼
    json_log_path = osp.join(cfg.work_dir, f'{timestamp}.log.json')

    # åˆå§‹åŒ–meta dict
    meta = dict()
    env_info_dict = collect_env()
    env_info = '\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])
    dash_line = '-' * 60 + '\n'
    logger.info('ç¯å¢ƒä¿¡æ¯:\n' + dash_line + env_info + '\n' + dash_line)
    meta['env_info'] = env_info
    meta['config'] = cfg.pretty_text
    logger.info(f'åˆ†å¸ƒå¼è®­ç»ƒ: {distributed}')
    logger.info(f'å¼€å§‹è®­ç»ƒ')
    logger.info(f'é…ç½®:\n{cfg.pretty_text}')

    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        logger.info(f'è®¾ç½®éšæœºç§å­ä¸º {args.seed}, ç¡®å®šæ€§: {args.deterministic}')
        set_random_seed(args.seed, deterministic=args.deterministic)
    cfg.seed = args.seed
    meta['seed'] = args.seed
    meta['exp_name'] = osp.basename(args.config)
    meta['stage'] = 'auto_detected'

    # æ„å»ºæ•°æ®é›†
    print("ğŸ“Š æ„å»ºæ•°æ®é›†...")
    datasets = [build_dataset(cfg.data.train)]
    workflow = cfg.get('workflow', [('train', 1)])
    if len(workflow) == 2:
        val_dataset = copy.deepcopy(cfg.data.val)
        val_dataset.pipeline = cfg.data.train.pipeline
        datasets.append(build_dataset(val_dataset))
    
    model_classes = datasets[0].CLASSES

    # è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ
    stage = detect_training_stage(cfg, args.config)
    
    # åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹
    model = create_jittor_compatible_model(cfg, stage)
    model.CLASSES = model_classes

    # ä½¿ç”¨è‡ªå®šä¹‰çš„Jittorè®­ç»ƒå™¨
    try:
        create_jittor_trainer(
            model,
            datasets,
            cfg,
            args,
            distributed=distributed,
            validate=(not args.no_validate),
            timestamp=timestamp,
            meta=meta,
            logger=logger,
            json_log_path=json_log_path)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
