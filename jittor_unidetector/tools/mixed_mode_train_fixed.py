import argparse
import copy
import os
import os.path as osp
import time
import warnings
import sys
import numpy as np
import json
import pickle
import datetime
from tqdm import tqdm

import jittor as jt
import jittor.models as jm
import mmcv
from mmcv import Config, DictAction
from mmcv.runner import get_dist_info, init_dist
from mmcv.utils import get_git_hash

from mmdet import __version__
from mmdet.apis import set_random_seed
from mmdet.datasets import build_dataset

from mmdet.models.builder import build_head, build_roi_extractor, build_neck
from mmdet.utils import collect_env, get_root_logger

# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å†…å­˜ç®¡ç†å‡½æ•°
import gc
import os

def clear_jittor_cache():
    """æ¸…ç†Jittorç¼“å­˜"""
    try:
        if hasattr(jt, 'core') and hasattr(jt.core, 'clear_cache'):
            jt.core.clear_cache()
        gc.collect()
    except:
        pass

def parse_args():
    parser = argparse.ArgumentParser(description='æ··åˆæ¨¡å¼è®­ç»ƒæ£€æµ‹å™¨')
    parser.add_argument('config', help='è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--work-dir', help='ä¿å­˜æ—¥å¿—å’Œæ¨¡å‹çš„ç›®å½•')
    parser.add_argument('--resume-from', help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹æ–‡ä»¶')
    parser.add_argument('--no-validate', action='store_true', help='è®­ç»ƒæœŸé—´ä¸è¯„ä¼°æ£€æŸ¥ç‚¹')
    parser.add_argument('--epochs', type=int, default=4, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', type=int, default=2, help='æ‰¹æ¬¡å¤§å°')
    # ç§»é™¤æ‰‹åŠ¨stageå‚æ•°ï¼Œæ”¹ä¸ºè‡ªåŠ¨è¯†åˆ«
    group_gpus = parser.add_mutually_exclusive_group()
    group_gpus.add_argument('--gpus', type=int, help='ä½¿ç”¨çš„GPUæ•°é‡')
    group_gpus.add_argument('--gpu-ids', type=int, nargs='+', help='ä½¿ç”¨çš„GPU ID')
    parser.add_argument('--seed', type=int, default=None, help='éšæœºç§å­')
    parser.add_argument('--deterministic', action='store_true', help='æ˜¯å¦ä¸ºCUDNNåç«¯è®¾ç½®ç¡®å®šæ€§é€‰é¡¹')
    parser.add_argument('--options', nargs='+', action=DictAction, help='è¦†ç›–é…ç½®è®¾ç½®')
    parser.add_argument('--cfg-options', nargs='+', action=DictAction, help='è¦†ç›–é…ç½®è®¾ç½®')
    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm', 'mpi'], default='none', help='ä½œä¸šå¯åŠ¨å™¨')
    parser.add_argument('--local_rank', type=int, default=0)
    args = parser.parse_args()
    if 'LOCAL_RANK' not in os.environ:
        os.environ['LOCAL_RANK'] = str(args.local_rank)
    if args.options and args.cfg_options:
        raise ValueError('--options å’Œ --cfg-options ä¸èƒ½åŒæ—¶æŒ‡å®š')
    if args.options:
        warnings.warn('--options å·²è¢«å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --cfg-options')
        args.cfg_options = args.options
    return args


def setup_jittor():
    """è®¾ç½®Jittorç¯å¢ƒ"""
    try:
        import jittor as jt
        
        # è®¾ç½®JittoråŸºæœ¬é…ç½®
        jt.flags.use_cuda = 1  # å¯ç”¨CUDA
        
        # è®¾ç½®å†…å­˜ä¼˜åŒ–é€‰é¡¹ï¼ˆä½¿ç”¨æ”¯æŒçš„æ ‡å¿—ï¼‰
        if hasattr(jt.flags, 'amp_level'):
            jt.flags.amp_level = 0  # ç¦ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆå¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜ï¼‰
        
        if hasattr(jt.flags, 'lazy_execution'):
            jt.flags.lazy_execution = 0  # ç¦ç”¨å»¶è¿Ÿæ‰§è¡Œï¼ˆå¯èƒ½å¯¼è‡´å†…å­˜ç´¯ç§¯ï¼‰
        
        # è®¾ç½®å†…å­˜æ¸…ç†é¢‘ç‡ï¼ˆä½¿ç”¨æ”¯æŒçš„æ ‡å¿—ï¼‰
        if hasattr(jt.flags, 'gc_after_backward'):
            jt.flags.gc_after_backward = 1  # åå‘ä¼ æ’­åè‡ªåŠ¨åƒåœ¾å›æ”¶
        
        if hasattr(jt.flags, 'gc_after_forward'):
            jt.flags.gc_after_forward = 1  # å‰å‘ä¼ æ’­åä¹Ÿè‡ªåŠ¨åƒåœ¾å›æ”¶
        
        # è®¾ç½®å†…å­˜é™åˆ¶ï¼ˆé˜²æ­¢GPUå†…å­˜æº¢å‡ºï¼‰
        # æ³¨æ„ï¼šæŸäº›ç‰ˆæœ¬çš„Jittorå¯èƒ½ä¸æ”¯æŒmax_memoryæ ‡å¿—
        try:
            if hasattr(jt.flags, 'max_memory'):
                jt.flags.max_memory = "12GB"  # æ›´æ¿€è¿›åœ°é™åˆ¶æœ€å¤§å†…å­˜ä½¿ç”¨
                print(f"ğŸ’¾ è®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶: 12GB")
        except:
            print("âš ï¸  max_memoryæ ‡å¿—ä¸æ”¯æŒï¼Œä½¿ç”¨å…¶ä»–å†…å­˜ç®¡ç†ç­–ç•¥")
        
        # è®¾ç½®å…¶ä»–å†…å­˜ä¼˜åŒ–æ ‡å¿—
        try:
            if hasattr(jt.flags, 'memory_efficient'):
                jt.flags.memory_efficient = 1  # å¯ç”¨å†…å­˜æ•ˆç‡æ¨¡å¼
                print(f"ğŸ’¾ å¯ç”¨å†…å­˜æ•ˆç‡æ¨¡å¼")
        except:
            pass
        
        try:
            if hasattr(jt.flags, 'use_parallel_op'):
                jt.flags.use_parallel_op = 0  # ç¦ç”¨å¹¶è¡Œæ“ä½œä»¥å‡å°‘å†…å­˜ä½¿ç”¨
                print(f"ğŸ’¾ ç¦ç”¨å¹¶è¡Œæ“ä½œä»¥å‡å°‘å†…å­˜ä½¿ç”¨")
        except:
            pass
        
        print(f"âœ… Jittorè®¾ç½®å®Œæˆ")
        print(f"ğŸ® CUDA: {jt.flags.use_cuda}")
        print(f"ğŸ§¹ è‡ªåŠ¨æ¸…ç†: åå‘ä¼ æ’­å={jt.flags.gc_after_backward if hasattr(jt.flags, 'gc_after_backward') else 'N/A'}, å‰å‘ä¼ æ’­å={jt.flags.gc_after_forward if hasattr(jt.flags, 'gc_after_forward') else 'N/A'}")
        print(f"ğŸ’¾ å†…å­˜é™åˆ¶: {jt.flags.max_memory if hasattr(jt.flags, 'max_memory') else 'N/A'}")
        
        return jt
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥Jittorï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…")
        return None


def load_custom_components():
    """åŠ è½½è‡ªå®šä¹‰ç»„ä»¶"""
    print("ğŸ“¦ åŠ è½½è‡ªå®šä¹‰ç»„ä»¶...")
    try:
        # æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥modelsæ¨¡å—
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        if parent_dir not in sys.path:
            sys.path.insert(0, parent_dir)
        
        # å¯¼å…¥æ‰€æœ‰Jittoræ¨¡å‹ç»„ä»¶ï¼Œç¡®ä¿å®ƒä»¬è¢«æ³¨å†Œåˆ°mmdetæ³¨å†Œè¡¨ä¸­
        from models.backbones.clip_backbone import CLIPResNet, CLIPResNetFPN
        from models.roi_heads.oln_roi_head import OlnRoIHead
        from models.roi_heads.bbox_heads.bbox_head_clip_partitioned import BBoxHeadCLIPPartitioned
        from models.roi_heads.bbox_heads.shared2fc_bbox_score_head import Shared2FCBBoxScoreHead
        from models.heads.rpn_head import RPNHead
        from models.heads.oln_rpn_head import OlnRPNHead
        from models.necks.fpn import FPN
        from models.detectors.faster_rcnn import FasterRCNN
        from models.detectors.fast_rcnn import FastRCNN
        from models.roi_heads.roi_extractors.single_roi_extractor import SingleRoIExtractor
        
        print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰Jittoræ¨¡å‹ç»„ä»¶")
        return True
    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å‹ç»„ä»¶å¤±è´¥: {e}")
        return False

def detect_training_stage(cfg, config_path):
    """è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ"""
    print("ğŸ” è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ...")
    
    # æ–¹æ³•1ï¼šä»é…ç½®æ–‡ä»¶åæ£€æµ‹
    config_name = os.path.basename(config_path).lower()
    if '1st' in config_name or 'rpn' in config_name:
        stage = '1st'
        print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åæ£€æµ‹åˆ°ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {config_name}")
    elif '2nd' in config_name or 'roi' in config_name or 'rcnn' in config_name:
        stage = '2nd'
        print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åæ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {config_name}")
    else:
        # æ–¹æ³•2ï¼šä»æ¨¡å‹é…ç½®æ£€æµ‹
        model_type = cfg.model.type
        if model_type == 'FasterRCNN':
            stage = '1st'
            print(f"ğŸ“‹ ä»æ¨¡å‹ç±»å‹æ£€æµ‹åˆ°ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {model_type}")
        elif model_type == 'FastRCNN':
            stage = '2nd'
            print(f"ğŸ“‹ ä»æ¨¡å‹ç±»å‹æ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {model_type}")
        else:
            # æ–¹æ³•3ï¼šä»backboneç±»å‹æ£€æµ‹
            backbone_type = cfg.model.backbone.type
            if 'CLIP' in backbone_type:
                stage = '2nd'
                print(f"ğŸ“‹ ä»backboneç±»å‹æ£€æµ‹åˆ°ç¬¬äºŒé˜¶æ®µè®­ç»ƒ: {backbone_type}")
            else:
                stage = '1st'
                print(f"ğŸ“‹ é»˜è®¤ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ: {backbone_type}")
    
    print(f"âœ… æ£€æµ‹åˆ°è®­ç»ƒé˜¶æ®µ: {stage}")
    return stage


def safe_convert_to_jittor(data, max_depth=10, current_depth=0):
    """å®‰å…¨åœ°å°†æ•°æ®è½¬æ¢ä¸ºJittoræ ¼å¼ï¼Œé¿å…æ— é™é€’å½’"""
    if current_depth >= max_depth:
        return data  # é˜²æ­¢æ— é™é€’å½’

    # å¯¹åŸå§‹/ç®€å•ç±»å‹ç›´æ¥è¿”å›ï¼Œé¿å…ä¸å¿…è¦åˆ¤å®š
    try:
        if data is None or isinstance(data, (int, float, bool, str, bytes)):
            return data
    except RecursionError:
        return data

    try:
        # å¦‚æœå·²ç»æ˜¯Jittorå˜é‡ï¼Œç›´æ¥è¿”å›
        is_jt_var = False
        try:
            is_jt_var = isinstance(data, jt.Var)
        except RecursionError:
            # å¦‚æœåœ¨ __instancecheck__ ä¸­é€’å½’ï¼Œç›´æ¥è·³è¿‡è½¬æ¢
            return data
        if is_jt_var:
            return data

        # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œé€’å½’å¤„ç†
        if isinstance(data, (list, tuple)):
            return [safe_convert_to_jittor(item, max_depth, current_depth + 1) for item in data]

        # å¦‚æœæ˜¯å­—å…¸ï¼Œé€’å½’å¤„ç†
        if isinstance(data, dict):
            return {key: safe_convert_to_jittor(value, max_depth, current_depth + 1) for key, value in data.items()}

        # å¤„ç†ç±»ä¼¼ DataContainer çš„å¯¹è±¡ï¼ˆæœ‰ data å±æ€§ï¼‰
        if hasattr(data, 'data') and not is_jt_var:
            # æ£€æŸ¥æ˜¯å¦æ˜¯DataContainerç±»å‹
            if hasattr(data, 'stack') and hasattr(data, 'cpu_only'):
                # è¿™æ˜¯DataContainerï¼Œæå–å…¶dataå±æ€§
                inner = getattr(data, 'data')
                print(f"ğŸ” æ£€æµ‹åˆ°DataContainerï¼Œæå–data: {type(inner)}, shape: {getattr(inner, 'shape', 'unknown')}")
                # é€’å½’å¤„ç†å†…éƒ¨æ•°æ®
                return safe_convert_to_jittor(inner, max_depth, current_depth + 1)
            # å…¶ä»–æœ‰dataå±æ€§çš„å¯¹è±¡
            inner = getattr(data, 'data')
            if isinstance(inner, list):
                converted_list = []
                for item in inner:
                    try:
                        # é¿å…é€’å½’è°ƒç”¨ ensure_jittor_varï¼Œç›´æ¥å¤„ç†
                        if isinstance(item, jt.Var):
                            converted_list.append(item)
                        elif isinstance(item, np.ndarray):
                            converted_list.append(jt.array(item))
                        elif hasattr(item, 'cpu') and hasattr(item, 'numpy'):
                            converted_list.append(jt.array(item.detach().cpu().numpy()))
                        else:
                            converted_list.append(item)
                    except Exception:
                        converted_list.append(item)
                return converted_list
            elif isinstance(inner, np.ndarray):
                # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œç›´æ¥è½¬æ¢
                return jt.array(inner)
            return safe_convert_to_jittor(inner, max_depth, current_depth + 1)

        # å¦‚æœæ˜¯PyTorchå¼ é‡æˆ–numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºJittor
        if not is_jt_var:
            try:
                return ensure_jittor_var(data, "data")
            except Exception:
                return data

        # å¦‚æœæ˜¯memoryviewï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(data, memoryview):
            try:
                import numpy as np
                return jt.array(np.array(data))
            except Exception:
                return data

        # å…¶ä»–æƒ…å†µï¼Œç›´æ¥è¿”å›
        return data

    except Exception:
        # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…å¤§é‡é”™è¯¯è¾“å‡º
        return data


def ensure_jittor_var(data, name="data", default_shape=None):
    """ç¡®ä¿æ•°æ®æ˜¯Jittorå¼ é‡ï¼Œå¦‚æœä¸æ˜¯åˆ™è½¬æ¢ï¼Œè½¬æ¢å¤±è´¥åˆ™è¿”å›é»˜è®¤å€¼"""
    # åœ¨å‡½æ•°å¼€å¤´å¯¼å…¥numpy
    import numpy as np
    
    try:
        # é¦–å…ˆå¤„ç†DataContainerç±»å‹
        if hasattr(data, 'data') and not isinstance(data, jt.Var):
            # æ£€æŸ¥æ˜¯å¦æ˜¯DataContainerç±»å‹
            if hasattr(data, 'stack') and hasattr(data, 'cpu_only'):
                # è¿™æ˜¯DataContainerï¼Œæå–å…¶dataå±æ€§
                inner_data = data.data
                print(f"ğŸ” æ£€æµ‹åˆ°DataContainerï¼Œæå–data: {type(inner_data)}, shape: {getattr(inner_data, 'shape', 'unknown')}")
                # é€’å½’å¤„ç†å†…éƒ¨æ•°æ®
                return ensure_jittor_var(inner_data, name, default_shape)
        
        if isinstance(data, jt.Var):
            return data
        elif isinstance(data, (list, tuple)):
            # å¦‚æœæ˜¯åˆ—è¡¨/å…ƒç»„ï¼Œå°è¯•è½¬æ¢ä¸ºå¼ é‡
            if len(data) == 0:
                if default_shape:
                    return jt.zeros(default_shape, dtype='float32')
                else:
                    return jt.zeros((0,), dtype='float32')
            else:
                # å°è¯•å°†åˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡
                try:
                    # å…ˆæ£€æŸ¥åˆ—è¡¨ä¸­çš„å…ƒç´ ç±»å‹
                    if len(data) > 0:
                        first_item = data[0]
                        if isinstance(first_item, (list, tuple)):
                            # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                            try:
                                # å¯¹äºgt_bboxesï¼ŒæœŸæœ›æ ¼å¼æ˜¯ [[[x1,y1,x2,y2], ...], ...]
                                # å¯¹äºgt_labelsï¼ŒæœŸæœ›æ ¼å¼æ˜¯ [[label1, label2, ...], ...]
                                if name == "gt_bboxes":
                                    # å¤„ç†gt_bboxesï¼šå±•å¹³æ‰€æœ‰batchçš„è¾¹ç•Œæ¡†
                                    all_bboxes = []
                                    for batch_bboxes in data:
                                        if isinstance(batch_bboxes, (list, tuple)):
                                            for bbox in batch_bboxes:
                                                if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
                                                    all_bboxes.append(bbox)
                                    if all_bboxes:
                                        return jt.array(all_bboxes, dtype='float32')
                                    else:
                                        return jt.zeros((1, 4), dtype='float32')
                                elif name == "gt_labels":
                                    # å¤„ç†gt_labelsï¼šå±•å¹³æ‰€æœ‰batchçš„æ ‡ç­¾
                                    all_labels = []
                                    for batch_labels in data:
                                        if isinstance(batch_labels, (list, tuple)):
                                            for label in batch_labels:
                                                if isinstance(label, (int, float)):
                                                    all_labels.append(int(label))
                                    if all_labels:
                                        return jt.array(all_labels, dtype='int32')
                                    else:
                                        return jt.zeros((1,), dtype='int32')
                                else:
                                    # å…¶ä»–åµŒå¥—åˆ—è¡¨ï¼Œå°è¯•ç›´æ¥è½¬æ¢
                                    return jt.array(data)
                            except Exception as nested_error:
                                print(f"âš ï¸  åµŒå¥—åˆ—è¡¨å¤„ç†å¤±è´¥ {name}: {nested_error}")
                                # å¦‚æœåµŒå¥—å¤„ç†å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
                                if name == "gt_bboxes":
                                    return jt.zeros((1, 4), dtype='float32')
                                elif name == "gt_labels":
                                    return jt.zeros((1,), dtype='int32')
                                else:
                                    return jt.zeros((1,), dtype='float32')
                        else:
                            # å¦‚æœæ˜¯ç®€å•åˆ—è¡¨ï¼Œç›´æ¥è½¬æ¢
                            return jt.array(data)
                    else:
                        return jt.array(data)
                except Exception as e:
                    print(f"âš ï¸  åˆ—è¡¨è½¬å¼ é‡å¤±è´¥ {name}: {e}")
                    if default_shape:
                        return jt.zeros(default_shape, dtype='float32')
                    else:
                        return jt.zeros((1,), dtype='float32')
        elif hasattr(data, 'cpu') and hasattr(data, 'numpy'):
            # PyTorchå¼ é‡
            return jt.array(data.detach().cpu().numpy())
        elif isinstance(data, np.ndarray):
            # NumPyæ•°ç»„
            return jt.array(data)
        else:
            # å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºnumpyå†è½¬ä¸ºJittor
            try:
                np_data = np.array(data)
                return jt.array(np_data)
            except Exception as e:
                print(f"âš ï¸  ç±»å‹è½¬æ¢å¤±è´¥ {name}: {e}")
                if default_shape:
                    return jt.zeros(default_shape, dtype='float32')
                else:
                    return jt.zeros((1,), dtype='float32')
    except Exception as e:
        print(f"âš ï¸  ç¡®ä¿Jittorå¼ é‡å¤±è´¥ {name}: {e}")
        if default_shape:
            return jt.zeros(default_shape, dtype='float32')
        else:
            return jt.zeros((1,), dtype='float32')


def safe_sum(tensor, dim=None, name="tensor"):
    """å®‰å…¨çš„sumæ“ä½œï¼Œç¡®ä¿è¾“å…¥æ˜¯Jittorå¼ é‡"""
    try:
        safe_tensor = ensure_jittor_var(tensor, name)
        if dim is not None:
            return safe_tensor.sum(dim=dim)
        else:
            return safe_tensor.sum()
    except Exception as e:
        print(f"âš ï¸  sumæ“ä½œå¤±è´¥ {name}: {e}")
        # è¿”å›é›¶å¼ é‡
        if dim is not None:
            return jt.zeros((1,), dtype='float32')
        else:
            return jt.zeros((1,), dtype='float32')


def create_jittor_compatible_model(cfg, stage='1st'):
    """åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹ - ä½¿ç”¨å·²æœ‰ç»„ä»¶"""
    print(f"ğŸ”§ åˆ›å»ºJittorå…¼å®¹æ¨¡å‹ - é˜¶æ®µ: {stage}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å…³é”®ä¿¡æ¯
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®ä¿¡æ¯:")
    print(f"   - æ¨¡å‹ç±»å‹: {cfg.model.type}")
    print(f"   - Backboneç±»å‹: {cfg.model.backbone.type}")
    if hasattr(cfg.model, 'neck'):
        print(f"   - Neckç±»å‹: {cfg.model.neck.type}")
    if hasattr(cfg.model, 'rpn_head'):
        print(f"   - RPN Headç±»å‹: {cfg.model.rpn_head.type}")
    if hasattr(cfg.model, 'roi_head'):
        print(f"   - ROI Headç±»å‹: {cfg.model.roi_head.type}")
    
    # å¯¼å…¥å·²æœ‰çš„æ¨¡å‹ç»„ä»¶
    try:
        # å¯¼å…¥Jittorç‰ˆæœ¬çš„æ¨¡å‹ç»„ä»¶
        from models.backbones.clip_backbone import CLIPResNet
        from models.roi_heads.oln_roi_head import OlnRoIHead
        from models.roi_heads.bbox_heads.bbox_head_clip_partitioned import BBoxHeadCLIPPartitioned
        from models.roi_heads.bbox_heads.shared2fc_bbox_score_head import Shared2FCBBoxScoreHead
        from models.heads.rpn_head import RPNHead
        print("âœ… æˆåŠŸå¯¼å…¥å·²æœ‰æ¨¡å‹ç»„ä»¶")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å‹ç»„ä»¶å¤±è´¥: {e}")
        raise
    
    # åˆ›å»ºåŸºäºå·²æœ‰ç»„ä»¶çš„Jittoræ¨¡å‹
    class JittorModelWithComponents(jt.Module):
        def __init__(self, cfg, stage='1st'):
            super().__init__()
            self.cfg = cfg
            self.stage = stage
            
            # ä»é…ç½®æ–‡ä»¶ä¸­æå–å‚æ•°
            model_cfg = cfg.model
            
            if stage == '1st':
                # ç¬¬ä¸€é˜¶æ®µï¼šFasterRCNN
                self._build_1st_stage_with_components(model_cfg)

            
            print(f"âœ… Jittoræ¨¡å‹åˆ›å»ºæˆåŠŸ - é˜¶æ®µ: {stage}")
        
        def execute(self, img, gt_bboxes=None, gt_labels=None, **kwargs):
            """Jittoræ¨¡å‹çš„executeæ–¹æ³•ï¼Œå¤„ç†å‰å‘ä¼ æ’­"""
            if self.stage == '1st':
                # è·å–batch size
                try:
                    img_var = ensure_jittor_var(img, "img")
                    batch_size = img_var.shape[0]
                except Exception:
                    batch_size = 1
                
                return self._forward_1st_stage_with_components(img, gt_bboxes, gt_labels, batch_size)
            else:
                raise NotImplementedError(f"Stage {self.stage} not implemented")
        
        def _build_1st_stage_with_components(self, model_cfg):
            """ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬ä¸€é˜¶æ®µæ¨¡å‹"""
            print("ğŸ”§ ä½¿ç”¨å·²æœ‰ç»„ä»¶æ„å»ºç¬¬ä¸€é˜¶æ®µæ¨¡å‹...")
            
            # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–backboneå‚æ•°
            backbone_cfg = model_cfg.backbone
            depth = backbone_cfg.get('depth', 50)
            print(f"   - Backbone: ResNet{depth}")

            # ä½¿ç”¨ Jittor æä¾›çš„ ResNet50 + ImageNet é¢„è®­ç»ƒæƒé‡
            self.resnet = jm.resnet50(pretrained=True)
            print("å·²åŠ è½½ jittor.models.resnet50(pretrained=True)")

            # æ ¹æ®é…ç½®å†»ç»“å‰è‹¥å¹² stageï¼ˆconv1+bn1 è®°ä¸º stage 0ï¼Œlayer1 ä¸º stage 1ï¼‰
            frozen_stages = getattr(backbone_cfg, 'frozen_stages', 0)
            if isinstance(frozen_stages, int) and frozen_stages >= 0:
                def _stop_grad_module(mod):
                    for p in mod.parameters():
                        try:
                            p.stop_grad()
                        except Exception:
                            pass
                if frozen_stages >= 0:
                    for name in ['conv1', 'bn1']:
                        if hasattr(self.resnet, name):
                            _stop_grad_module(getattr(self.resnet, name))
                if frozen_stages >= 1 and hasattr(self.resnet, 'layer1'):
                    _stop_grad_module(self.resnet.layer1)
                if frozen_stages >= 2 and hasattr(self.resnet, 'layer2'):
                    _stop_grad_module(self.resnet.layer2)
                if frozen_stages >= 3 and hasattr(self.resnet, 'layer3'):
                    _stop_grad_module(self.resnet.layer3)
                if frozen_stages >= 4 and hasattr(self.resnet, 'layer4'):
                    _stop_grad_module(self.resnet.layer4)
                print(f"   ğŸ”’ å·²å†»ç»“å‰ {frozen_stages} ä¸ª stage")

            # norm_eval: å°† BN è®¾ä¸º eval æ¨¡å¼ï¼Œä¿æŒå‡å€¼æ–¹å·®ä¸æ›´æ–°
            norm_eval = bool(getattr(backbone_cfg, 'norm_eval', False))
            if norm_eval:
                try:
                    for m in self.resnet.modules():
                        # å…¼å®¹ä¸åŒ BN ç±»å
                        if m.__class__.__name__ in ("BatchNorm", "BatchNorm2d"):
                            try:
                                m.is_training = False
                            except Exception:
                                pass
                except Exception:
                    pass
                print("   ğŸ§Š å·²å°† BatchNorm ç½®ä¸º eval (norm_eval=True)")

            # ä¸ä½¿ç”¨åˆ†ç±» fcï¼Œç¦ç”¨å…¶æ¢¯åº¦ä»¥é¿å…æ— æ¢¯åº¦è­¦å‘Š
            try:
                if hasattr(self.resnet, 'fc'):
                    for p in self.resnet.fc.parameters():
                        p.stop_grad()
            except Exception:
                pass

            # ä½¿ç”¨FPN neck
            if hasattr(model_cfg, 'neck'):
                neck_cfg = model_cfg.neck
                print(f"   - Neck: {neck_cfg.type}, out_channels: {neck_cfg.out_channels}")
                self.fpn_out_channels = neck_cfg.out_channels
                self.neck = build_neck(neck_cfg)
                print("   âœ… å·²æ„å»º FPN")

            # ä½¿ç”¨RPN head
            if hasattr(model_cfg, 'rpn_head'):
                rpn_cfg = model_cfg.rpn_head
                # ä¼˜å…ˆå°è¯• OLN-RPNHead
                from models.heads.oln_rpn_head import OlnRPNHead as JT_RPNHead
                print("   âœ… ä½¿ç”¨ Jittor OlnRPNHead")
                # ä»¥ FPN è¾“å‡ºé€šé“ä½œä¸ºè¾“å…¥é€šé“ï¼Œfeat_channels æ¥è‡ªé…ç½®
                self.rpn_head_jt = JT_RPNHead(
                    in_channels=self.fpn_out_channels,
                    feat_channels=rpn_cfg.feat_channels,
                    anchor_generator=getattr(rpn_cfg, 'anchor_generator', None),
                )
            # è®°å½• FPN strides ä¾› proposals ç”Ÿæˆä½¿ç”¨
            self.fpn_strides = None
            if hasattr(rpn_cfg, 'anchor_generator') and hasattr(rpn_cfg.anchor_generator, 'strides'):
                self.fpn_strides = list(rpn_cfg.anchor_generator.strides)

            # ä½¿ç”¨ROI head
            if hasattr(model_cfg, 'roi_head'):
                roi_cfg = model_cfg.roi_head
                # print(f"   - ROI: {roi_cfg.type}")
                if hasattr(roi_cfg, 'bbox_head'):
                    bbox_cfg = roi_cfg.bbox_head
                    # print(f"   - BBox Head: {bbox_cfg.type}")
                    # æ„å»ºæ¨¡å—åŒ–çš„ RoIExtractor ä¸ BBoxHead
                    if hasattr(roi_cfg, 'bbox_roi_extractor'):
                        self.roi_extractor = build_roi_extractor(roi_cfg.bbox_roi_extractor)
                        print("   âœ… å·²æ„å»º SingleRoIExtractor")

                        self.bbox_head = build_head(bbox_cfg)
                        self.roi_feat_size = bbox_cfg.get('roi_feat_size', 7)
                        print("   âœ… å·²æ„å»º BBoxHead æ¨¡å—")

        def _forward_1st_stage_with_components(self, img, gt_bboxes, gt_labels, batch_size):
            """ç¬¬ä¸€é˜¶æ®µå‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨ç»„ä»¶åŒ–æ¶æ„ï¼‰"""
            try:
                print(f"ğŸ” å¼€å§‹ç¬¬ä¸€é˜¶æ®µå‰å‘ä¼ æ’­ï¼Œæ­¥éª¤ {getattr(self, '_step_count', 0)}")
                # æ‰“å°å†…å­˜ä½¿ç”¨æƒ…å†µ
                if hasattr(self, '_step_count'):
                    self._step_count += 1
                else:
                    self._step_count = 0
                
                # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå¦‚æœæ¥è¿‘æº¢å‡ºåˆ™æ¸…ç†
                try:
                    if jt.flags.use_cuda:
                        import pynvml
                        pynvml.nvmlInit()
                        handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                        info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                        memory_used = info.used / 1024**3  # GB
                        memory_total = info.total / 1024**3  # GB
                        
                        if memory_used / memory_total > 0.85:  # ä½¿ç”¨ç‡è¶…è¿‡85%å°±å¼€å§‹æ¸…ç†
                            print(f"âš ï¸  GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_used:.2f}GB/{memory_total:.2f}GB")
                            clear_jittor_cache()
                            jt.sync_all()  # åŒæ­¥æ‰€æœ‰æ“ä½œ
                            
                            # å¼ºåˆ¶åƒåœ¾å›æ”¶
                            import gc
                            gc.collect()
                            
                            # å¦‚æœå†…å­˜ä»ç„¶å¾ˆé«˜ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†
                            if memory_used / memory_total > 0.9:
                                print("ğŸš¨ å†…å­˜ä½¿ç”¨ç‡ä»ç„¶è¿‡é«˜ï¼Œè¿›è¡Œæ¿€è¿›æ¸…ç†...")
                                jt.gc()  # Jittoråƒåœ¾å›æ”¶
                                jt.sync_all()
                except:
                    pass  # å¦‚æœæ— æ³•è·å–GPUä¿¡æ¯ï¼Œå¿½ç•¥
                    
                # Backboneç‰¹å¾æå–ï¼ˆä¼˜å…ˆä½¿ç”¨ jittor resnet50ï¼Œå¦åˆ™å›é€€åˆ°ç®€åŒ–ç‰ˆï¼‰
                print("ğŸ” æ­¥éª¤1: Backboneç‰¹å¾æå–")
                if hasattr(self, 'resnet') and self.resnet is not None:
                    try:
                        x = self.resnet.conv1(img)
                        x = self.resnet.bn1(x)
                        x = self.resnet.relu(x)
                        x = self.resnet.maxpool(x)
                        
                        c2 = self.resnet.layer1(x)
                        c3 = self.resnet.layer2(c2)
                        c4 = self.resnet.layer3(c3)
                        c5 = self.resnet.layer4(c4)
                        feat = c5  # [B, 2048, H/32, W/32]
                        print(f"âœ… Backboneç‰¹å¾æå–æˆåŠŸ: feat shape={feat.shape}")
                        
                        # æ¸…ç†ä¸­é—´ç‰¹å¾å›¾ä»¥èŠ‚çœå†…å­˜
                        del x
                        if self._step_count % 50 == 0:
                            clear_jittor_cache()
                    except Exception as e:
                        print(f"âš ï¸  Backboneç‰¹å¾æå–å¤±è´¥: {e}")
                        raise e

                # å¤„ç†imgå‚æ•°ï¼šå¦‚æœæ˜¯åˆ—è¡¨ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ å¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®
                if isinstance(img, (list, tuple)) and len(img) > 0:
                    img = img[0]  # æå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    print(f"ğŸ” ä»åˆ—è¡¨ä¸­æå–imgï¼Œç±»å‹: {type(img)}")
                
                # å¼ºåŒ–å›¾åƒå¼ é‡å¥å£®æ€§ï¼šç¡®ä¿ä¸º jt.Varã€float32ã€NCHW
                try:
                    img = ensure_jittor_var(img, "img", (1, 3, 224, 224))
                    if len(img.shape) == 3:
                        img = img.unsqueeze(0)
                except Exception as e:
                    print(f"âš ï¸  å›¾åƒè½¬æ¢å¤±è´¥: {e}")
                    # åˆ›å»ºé»˜è®¤å›¾åƒ
                    img = jt.randn(1, 3, 224, 224)
                try:
                    img = img.float32()
                except Exception:
                    pass
                
                # æå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„gt_bboxå’Œgt_labelç”¨äºæŸå¤±è®¡ç®—
                # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç®€åŒ–ç±»å‹è½¬æ¢
                try:
                    if isinstance(gt_bboxes, jt.Var) and gt_bboxes.shape[0] > 0:
                        # æ•°æ®æ ¼å¼: [batch_size, max_objects, 4]
                        gt_bbox = gt_bboxes[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
                        # è¿‡æ»¤æ‰ç©ºçš„bboxï¼ˆå…¨é›¶çš„ï¼‰
                        gt_bbox = ensure_jittor_var(gt_bbox, "gt_bbox", (1, 4))
                        if len(gt_bbox.shape) == 2 and gt_bbox.shape[1] == 4:
                            # ç¡®ä¿ gt_bbox æ˜¯ Jittor å¼ é‡
                            gt_bbox = ensure_jittor_var(gt_bbox, "gt_bbox")
                            # è®¡ç®—æ¯ä¸ªbboxçš„æœ‰æ•ˆæ€§ï¼ˆéé›¶ï¼‰
                            valid_mask = gt_bbox.sum(dim=1) != 0
                            valid_count = valid_mask.sum()
                            if valid_count.item() > 0:
                                gt_bbox = gt_bbox[valid_mask]
                            else:
                                gt_bbox = jt.randn(1, 4) * 0.01
                        else:
                            gt_bbox = jt.randn(1, 4) * 0.01
                    else:
                        gt_bbox = jt.randn(1, 4) * 0.01
                except Exception as e:
                    print(f"âš ï¸  gt_bboxeså¤„ç†å¤±è´¥: {e}")
                    gt_bbox = jt.randn(1, 4) * 0.01

                        # å¤„ç†gt_labels
                try:
                    if isinstance(gt_labels, jt.Var) and gt_labels.shape[0] > 0:
                        gt_label = gt_labels[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
                        gt_label = ensure_jittor_var(gt_label, "gt_label", (1,))
                        if len(gt_label.shape) == 1:
                            # è¿‡æ»¤æ‰æ— æ•ˆçš„æ ‡ç­¾
                            valid_mask = gt_label >= 0
                            valid_count = valid_mask.sum()
                            if valid_count.item() > 0:
                                gt_label = gt_label[valid_mask]
                            else:
                                gt_label = jt.zeros(1, dtype='int32')
                        else:
                            gt_label = jt.zeros(1, dtype='int32')
                    else:
                        gt_label = jt.zeros(1, dtype='int32')
                except Exception as e:
                    print(f"âš ï¸  gt_labelså¤„ç†å¤±è´¥: {e}")
                    gt_label = jt.zeros(1, dtype='int32')

                # æ­¥éª¤2: FPNç‰¹å¾èåˆ
                print("ğŸ” æ­¥éª¤2: FPNç‰¹å¾èåˆ")
                try:
                    if hasattr(self, 'fpn') and self.fpn is not None:
                        # ä½¿ç”¨çœŸå®çš„FPN
                        fpn_feats = self.fpn([c2, c3, c4, c5])
                        print(f"âœ… FPNç‰¹å¾èåˆæˆåŠŸ: {len(fpn_feats)} å±‚")
                    else:
                        # ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨c5ä½œä¸ºå•å±‚ç‰¹å¾
                        fpn_feats = [feat]
                        print(f"âœ… ä½¿ç”¨ç®€åŒ–FPN: å•å±‚ç‰¹å¾ {feat.shape}")
                except Exception as e:
                    print(f"âš ï¸  FPNç‰¹å¾èåˆå¤±è´¥: {e}")
                    # å›é€€åˆ°å•å±‚ç‰¹å¾
                    fpn_feats = [feat]
                    print(f"âš ï¸  å›é€€åˆ°å•å±‚ç‰¹å¾: {feat.shape}")

                # æ­¥éª¤3: RPNå‰å‘ä¼ æ’­
                print("ğŸ” æ­¥éª¤3: RPNå‰å‘ä¼ æ’­")
                try:
                    if hasattr(self, 'rpn_head_jt') and self.rpn_head_jt is not None:
                        # ä¼ å…¥å…¨éƒ¨ FPN å±‚ï¼ŒRPNHead å†…éƒ¨æ”¯æŒå¤šå±‚
                        rpn_out = self.rpn_head_jt(fpn_feats if 'fpn_feats' in locals() else fpn_rpn)
                        print(f"ğŸ” RPNè¾“å‡ºè°ƒè¯•: ç±»å‹={type(rpn_out)}, é•¿åº¦={len(rpn_out) if isinstance(rpn_out, (list, tuple)) else 'N/A'}")
                        
                        # å®‰å…¨åœ°è§£åŒ…RPNè¾“å‡º
                        try:
                            if isinstance(rpn_out, (list, tuple)):
                                if len(rpn_out) == 3:
                                    rpn_cls, rpn_reg, rpn_obj = rpn_out
                                    print("âœ… RPNè¾“å‡ºè§£åŒ…æˆåŠŸ: 3ä¸ªå€¼")
                                elif len(rpn_out) == 2:
                                    rpn_cls, rpn_reg = rpn_out
                                    rpn_obj = None
                                    print("âœ… RPNè¾“å‡ºè§£åŒ…æˆåŠŸ: 2ä¸ªå€¼")
                                else:
                                    print(f"âš ï¸ RPNè¾“å‡ºé•¿åº¦å¼‚å¸¸: {len(rpn_out)}")
                                    rpn_cls = rpn_out[0] if len(rpn_out) > 0 else None
                                    rpn_reg = rpn_out[1] if len(rpn_out) > 1 else None
                                    rpn_obj = None
                            else:
                                # å¦‚æœrpn_outä¸æ˜¯åˆ—è¡¨/å…ƒç»„ï¼Œå¯èƒ½æ˜¯å•ä¸ªå¼ é‡
                                print(f"âš ï¸ RPNè¾“å‡ºä¸æ˜¯åˆ—è¡¨/å…ƒç»„: {type(rpn_out)}")
                                rpn_cls = rpn_out
                                rpn_reg = None
                                rpn_obj = None
                        except Exception as e:
                            print(f"âš ï¸ RPNè¾“å‡ºè§£åŒ…å¤±è´¥: {e}")
                            # åˆ›å»ºé»˜è®¤å€¼
                            rpn_cls = jt.randn(1, 1, 64, 64)
                            rpn_reg = jt.randn(1, 4, 64, 64)
                            rpn_obj = None
                        
                        print(f"âœ… RPNå‰å‘ä¼ æ’­æˆåŠŸ")
                    else:
                        print("âš ï¸  RPN headä¸å­˜åœ¨ï¼Œè·³è¿‡RPNå‰å‘ä¼ æ’­")
                        rpn_cls = jt.randn(1, 1, 64, 64)
                        rpn_reg = jt.randn(1, 4, 64, 64)
                        rpn_obj = None
                except Exception as e:
                    print(f"âš ï¸  RPNå‰å‘ä¼ æ’­å¤±è´¥: {e}")
                    # åˆ›å»ºé»˜è®¤å€¼
                    rpn_cls = jt.randn(1, 1, 64, 64)
                    rpn_reg = jt.randn(1, 4, 64, 64)
                    rpn_obj = None

                # æ­¥éª¤4: ROI Headå¤„ç†
                print("ğŸ” æ­¥éª¤4: ROI Headå¤„ç†")
                try:
                    # ç”Ÿæˆç®€å•çš„proposalsï¼ˆç®€åŒ–ç‰ˆï¼‰
                    if hasattr(self, 'bbox_head') and self.bbox_head is not None:
                        # ä½¿ç”¨çœŸå®çš„bbox_head
                        try:
                            # ç”Ÿæˆç®€å•çš„proposals
                            rois = self._generate_simple_proposals(
                                rpn_cls, fpn_feats, [32, 16, 8, 4], 
                                nms_pre=1000, max_num=1000, nms_thr=0.7, 
                                img_shape=img.shape
                            )
                            
                            # æ„å»º ROI è®­ç»ƒç›®æ ‡ï¼ˆç®€åŒ–çœŸå®ç‰ˆï¼‰
                            try:
                                targets_result = self.bbox_head.build_targets_minimal(
                                    rois,
                                    gt_bboxes,
                                    img_shape=img.shape,
                                    pos_iou_thr=getattr(self.cfg.train_cfg.rcnn.assigner, 'pos_iou_thr', 0.5) if hasattr(self.cfg, 'train_cfg') else 0.5,
                                    neg_iou_thr=getattr(self.cfg.train_cfg.rcnn.assigner, 'neg_iou_thr', 0.5) if hasattr(self.cfg, 'train_cfg') else 0.5,
                                    num_samples=getattr(self.cfg.train_cfg.rcnn.sampler, 'num', 256) if hasattr(self.cfg, 'train_cfg') else 256,
                                    pos_fraction=getattr(self.cfg.train_cfg.rcnn.sampler, 'pos_fraction', 0.25) if hasattr(self.cfg, 'train_cfg') else 0.25,
                                )
                                
                                # å®‰å…¨åœ°è§£åŒ…è¿”å›å€¼
                                if isinstance(targets_result, (list, tuple)) and len(targets_result) == 6:
                                    labels, label_weights, bbox_targets, bbox_weights, bbox_score_targets, bbox_score_weights = targets_result
                                elif isinstance(targets_result, (list, tuple)) and len(targets_result) == 1:
                                    # å¦‚æœåªè¿”å›1ä¸ªå€¼ï¼Œåˆ›å»ºé»˜è®¤å€¼
                                    print(f"âš ï¸  build_targets_minimalåªè¿”å›1ä¸ªå€¼: {targets_result}")
                                    labels = targets_result[0]
                                    label_weights = jt.ones_like(labels) if hasattr(labels, 'shape') else jt.ones(1)
                                    bbox_targets = jt.zeros((labels.shape[0], 4)) if hasattr(labels, 'shape') else jt.zeros((1, 4))
                                    bbox_weights = jt.zeros((labels.shape[0], 4)) if hasattr(labels, 'shape') else jt.zeros((1, 4))
                                    bbox_score_targets = jt.zeros_like(labels) if hasattr(labels, 'shape') else jt.zeros(1)
                                    bbox_score_weights = jt.ones_like(labels) if hasattr(labels, 'shape') else jt.ones(1)
                                else:
                                    # å…¶ä»–æƒ…å†µï¼Œåˆ›å»ºé»˜è®¤å€¼
                                    print(f"âš ï¸  build_targets_minimalè¿”å›å¼‚å¸¸å€¼: {type(targets_result)}, {targets_result}")
                                    labels = jt.zeros(1, dtype='int32')
                                    label_weights = jt.ones(1)
                                    bbox_targets = jt.zeros((1, 4))
                                    bbox_weights = jt.zeros((1, 4))
                                    bbox_score_targets = jt.zeros(1)
                                    bbox_score_weights = jt.ones(1)
                            except Exception as e:
                                print(f"âš ï¸  build_targets_minimalè°ƒç”¨å¤±è´¥: {e}")
                                # åˆ›å»ºé»˜è®¤å€¼
                                labels = jt.zeros(1, dtype='int32')
                                label_weights = jt.ones(1)
                                bbox_targets = jt.zeros((1, 4))
                                bbox_weights = jt.zeros((1, 4))
                                bbox_score_targets = jt.zeros(1)
                                bbox_score_weights = jt.ones(1)
                            
                            # è®¡ç®—ROIæŸå¤±
                            roi_losses = self.bbox_head.loss(
                                cls_score=roi_cls if 'roi_cls' in locals() else jt.randn(1, 1),
                                bbox_pred=roi_reg if 'roi_reg' in locals() else jt.randn(1, 4),
                                bbox_score_pred=roi_score if 'roi_score' in locals() else jt.randn(1, 1),
                                rois=rois,
                                labels=labels,
                                label_weights=label_weights,
                                bbox_targets=bbox_targets,
                                bbox_weights=bbox_weights,
                                bbox_score_targets=bbox_score_targets,
                                bbox_score_weights=bbox_score_weights,
                                reduction_override=None
                            )
                            print(f"âœ… ROI Headå¤„ç†æˆåŠŸ")
                        except Exception as e:
                            print(f"âš ï¸  ROI Headå¤„ç†å¤±è´¥: {e}")
                            # åˆ›å»ºé»˜è®¤çš„roi_losses
                            roi_losses = {
                                'loss_cls': jt.zeros(1),
                                'loss_bbox': jt.zeros(1),
                                'loss_bbox_score': jt.zeros(1)
                            }
                    else:
                        print("âš ï¸  bbox_headä¸å­˜åœ¨ï¼Œè·³è¿‡ROI Headå¤„ç†")
                        roi_losses = {
                            'loss_cls': jt.zeros(1),
                            'loss_bbox': jt.zeros(1),
                            'loss_bbox_score': jt.zeros(1)
                        }
                except Exception as e:
                    print(f"âš ï¸  ROI Headå¤„ç†å¤±è´¥: {e}")
                    # åˆ›å»ºé»˜è®¤çš„roi_losses
                    roi_losses = {
                        'loss_cls': jt.zeros(1),
                        'loss_bbox': jt.zeros(1),
                        'loss_bbox_score': jt.zeros(1)
                    }

                # è®¡ç®—æŸå¤± (çœŸå® RPN è®­ç»ƒ)
                if hasattr(self, 'rpn_head_jt') and self.rpn_head_jt is not None and rpn_obj is not None and hasattr(self.rpn_head_jt, 'loss'):
                    try:
                        # ä½¿ç”¨è¾…åŠ©å‡½æ•°ç®€åŒ–gt_bboxesæ ¼å¼è½¬æ¢
                        gt_bboxes_tensor = ensure_jittor_var(gt_bboxes, "gt_bboxes", (1, 0, 4))
                        
                        print(f"ğŸ” RPN lossè°ƒç”¨å‰ï¼Œgt_bboxesæ ¼å¼: {type(gt_bboxes_tensor)}, shape: {gt_bboxes_tensor.shape}")
                        
                        # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°è°ƒç”¨RPN losså‡½æ•°
                        # æ³¨æ„ï¼šrpn_cls, rpn_reg, rpn_obj å·²ç»æ˜¯å¤šå±‚çº§åˆ—è¡¨æ ¼å¼
                        rpn_losses = self.rpn_head_jt.loss(
                            rpn_cls, rpn_reg, rpn_obj,  # ç›´æ¥ä¼ é€’ï¼Œä¸è¦åŒ…è£…æˆåˆ—è¡¨
                            gt_bboxes_list=gt_bboxes_tensor,
                            img_shape=img.shape  # ä¼ é€’å®Œæ•´çš„img_shape (B, C, H, W)
                        )
                        rpn_cls_loss = rpn_losses.get('loss_rpn_cls', jt.zeros(1))
                        rpn_bbox_loss = rpn_losses.get('loss_rpn_bbox', jt.zeros(1))
                        rpn_obj_loss = rpn_losses.get('loss_rpn_obj', jt.zeros(1))
                    except Exception as e:
                        print(f"âš ï¸  RPNæŸå¤±è®¡ç®—å¤±è´¥: {e}")
                        import traceback as _tb
                        _tb.print_exc()
                        # å›é€€åˆ°ç®€åŒ–æŸå¤±ï¼Œä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                        rpn_cls_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_cls, "rpn_cls"))) * 0.0  # æŒ‰é…ç½®æƒé‡ä¸º0
                        rpn_bbox_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_reg, "rpn_reg"))) * 10.0  # loss_weight=10.0
                        
                        rpn_obj_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_obj, "rpn_obj"))) * 1.0   # loss_weight=1.0
                else:
                    # æŒ‰é…ç½®æ–‡ä»¶æƒé‡è®¡ç®—æŸå¤±ï¼Œä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                    rpn_cls_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_cls, "rpn_cls"))) * 0.0  # loss_weight=0.0
                    rpn_bbox_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_reg, "rpn_reg"))) * 10.0  # loss_weight=10.0
                    rpn_obj_loss = jt.mean(jt.sqr(ensure_jittor_var(rpn_obj, "rpn_obj"))) * 1.0   # loss_weight=1.0
                
                # ROI æŸå¤±è®¡ç®—
                if 'roi_losses' in locals() and isinstance(roi_losses, dict) and len(roi_losses) > 0:
                    # ä½¿ç”¨çœŸå®çš„ROIæŸå¤±
                    rcnn_cls_loss = roi_losses.get('loss_cls', jt.zeros(1)) * 1.0  # loss_weight=1.0
                    rcnn_bbox_loss = roi_losses.get('loss_bbox', jt.zeros(1)) * 1.0  # loss_weight=1.0
                    rcnn_score_loss = roi_losses.get('loss_bbox_score', jt.zeros(1)) * 1.0  # loss_weight=1.0
                else:
                    # å ä½æŸå¤±ï¼Œä½¿ç”¨é…ç½®æƒé‡ï¼Œä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                    rcnn_cls_loss = jt.mean(jt.sqr(ensure_jittor_var(roi_cls, "roi_cls"))) * 1.0  # loss_weight=1.0
                    rcnn_bbox_loss = jt.mean(jt.sqr(ensure_jittor_var(roi_reg, "roi_reg"))) * 1.0  # loss_weight=1.0
                    rcnn_score_loss = jt.mean(jt.sqr(ensure_jittor_var(roi_score, "roi_score"))) * 1.0  # loss_weight=1.0
                    
                # æ±‡æ€»æ€»æŸå¤±
                total_loss = rpn_cls_loss + rpn_bbox_loss + rpn_obj_loss + rcnn_cls_loss + rcnn_bbox_loss + rcnn_score_loss
                
                # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç¡®ä¿total_lossæ˜¯å•ä¸ªJittorå¼ é‡
                total_loss = ensure_jittor_var(total_loss, "total_loss", (1,))
                
                print(f"âœ… ROI Headå¤„ç†æˆåŠŸ: total_loss={total_loss.item():.4f}")
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æŸå¤±å€¼
                if self._step_count % 10 == 0:  # æ¯10æ­¥æ‰“å°ä¸€æ¬¡
                    print(f"ğŸ” æ­¥éª¤ {self._step_count} æŸå¤±å€¼:")
                    print(f"   RPN: cls={ensure_jittor_var(rpn_cls_loss, 'rpn_cls_loss').item():.6f}, bbox={ensure_jittor_var(rpn_bbox_loss, 'rpn_bbox_loss').item():.6f}, obj={ensure_jittor_var(rpn_obj_loss, 'rpn_obj_loss').item():.6f}")
                    print(f"   RCNN: cls={ensure_jittor_var(rcnn_cls_loss, 'rcnn_cls_loss').item():.6f}, bbox={ensure_jittor_var(rcnn_bbox_loss, 'rcnn_bbox_loss').item():.6f}, score={ensure_jittor_var(rcnn_score_loss, 'rcnn_score_loss').item():.6f}")
                    print(f"   æ€»æŸå¤±: {ensure_jittor_var(total_loss, 'total_loss').item():.6f}")
                
                return {
                    'loss': total_loss,
                    'rpn_cls_loss': rpn_cls_loss,
                    'rpn_bbox_loss': rpn_bbox_loss,
                    'rpn_obj_loss': rpn_obj_loss,
                    'rcnn_cls_loss': rcnn_cls_loss,
                    'rcnn_bbox_loss': rcnn_bbox_loss,
                    'rcnn_score_loss': rcnn_score_loss
                }

            except Exception as e:
                print(f"âš ï¸  å‰å‘ä¼ æ’­æ­¥éª¤ {self._step_count} å¤±è´¥: {e}")
                return {
                    'loss': jt.array(0.0),
                    'rpn_cls_loss': jt.array(0.0),
                    'rpn_bbox_loss': jt.array(0.0),
                    'rpn_obj_loss': jt.array(0.0),
                    'rcnn_cls_loss': jt.array(0.0),
                    'rcnn_bbox_loss': jt.array(0.0),
                    'rcnn_score_loss': jt.array(0.0)
                }

        def _roi_align_first_gt(self, feat, gt_bboxes_list, output_size=7, stride=32):
            """åœ¨å•å±‚ç‰¹å¾å›¾ä¸Šï¼Œç”¨æ¯å¼ å›¾çš„é¦–ä¸ª GT æ¡†åšç®€æ˜“ RoIAlignã€‚
            - feat: [B, C, H, W]
            - gt_bboxes_list: List[Var[N, 4]] in image coords
            è¿”å›: [B, C, output_size, output_size]
            """
            B, C, H, W = feat.shape
            pooled = []
            for n in range(B):
                # å–ç¬¬ n å¼ å›¾çš„é¦–ä¸ª gt æ¡†
                box = None
                if isinstance(gt_bboxes_list, (list, tuple)) and len(gt_bboxes_list) > n:
                    b = ensure_jittor_var(gt_bboxes_list[n], f"gt_bboxes_list[{n}]")
                    if b.shape[0] > 0:
                        box = b[0]
                if box is None:
                    # è‹¥æ—  gtï¼Œé€€åŒ–ä¸ºæ•´å›¾æ± åŒ–
                    crop = feat[n:n+1, :, :, :]
                else:
                    x1, y1, x2, y2 = box[0], box[1], box[2], box[3]
                    # è½¬åˆ°ç‰¹å¾åæ ‡å¹¶è£å‰ªåˆ°è¾¹ç•Œ
                    xs1 = jt.maximum((x1 / stride).floor().int32(), jt.int32(0))
                    ys1 = jt.maximum((y1 / stride).floor().int32(), jt.int32(0))
                    xs2 = jt.minimum((x2 / stride).ceil().int32(), jt.int32(W-1))
                    ys2 = jt.minimum((y2 / stride).ceil().int32(), jt.int32(H-1))
                    # é˜²æ­¢ç©ºåŒºåŸŸ
                    xs2 = jt.maximum(xs2, xs1 + 1)
                    ys2 = jt.maximum(ys2, ys1 + 1)
                    crop = feat[n:n+1, :, ys1:ys2, xs1:xs2]
                pooled.append(jt.nn.AdaptiveAvgPool2d((output_size, output_size))(crop))
            return jt.concat(pooled, dim=0)

        def _nms_numpy(self, boxes_np, scores_np, iou_thr=0.7, max_num=1000):
            # boxes: [N,4] (x1,y1,x2,y2) in numpy
            import numpy as np
            x1 = boxes_np[:, 0]
            y1 = boxes_np[:, 1]
            x2 = boxes_np[:, 2]
            y2 = boxes_np[:, 3]
            areas = (x2 - x1 + 1) * (y2 - y1 + 1)
            order = scores_np.argsort()[::-1]
            keep = []
            while order.size > 0 and len(keep) < max_num:
                i = order[0]
                keep.append(i)
                xx1 = np.maximum(x1[i], x1[order[1:]])
                yy1 = np.maximum(y1[i], y1[order[1:]])
                xx2 = np.minimum(x2[i], x2[order[1:]])
                yy2 = np.minimum(y2[i], y2[order[1:]])
                w = np.maximum(0.0, xx2 - xx1 + 1)
                h = np.maximum(0.0, yy2 - yy1 + 1)
                inter = w * h
                iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)
                inds = np.where(iou <= iou_thr)[0]
                order = order[inds + 1]
            return keep

        def _generate_simple_proposals(self, rpn_cls, fpn_feats, strides, nms_pre=1000, max_num=1000, nms_thr=0.7, img_shape=None):
            # è¿”å› rois Var [N,5] (b,x1,y1,x2,y2) åˆå¹¶æ‰€æœ‰ batch
            import numpy as _np
            if not isinstance(fpn_feats, (list, tuple)):
                fpn_feats = [fpn_feats]
            if isinstance(rpn_cls, (list, tuple)):
                cls_list = rpn_cls
            else:
                cls_list = [rpn_cls]

            B = int(img_shape[0]) if img_shape is not None else 1
            rois_concat = []
            
            try:
                for b in range(B):
                    boxes_all = []
                    scores_all = []
                    for lvl, cls_map in enumerate(cls_list):
                        stride = strides[lvl] if lvl < len(strides) else strides[-1]
                        # cls_map: [B, A*2, H, W] -> å‰æ™¯åˆ†æ•° [H*W*A]
                        H, W = int(cls_map.shape[2]), int(cls_map.shape[3])
                        A2 = int(cls_map.shape[1])
                        A = max(1, A2 // 2)
                        
                        # å®‰å…¨åœ°è·å–æ‰¹æ¬¡æ•°æ®
                        if b < cls_map.shape[0]:
                            logits = cls_map[b:b+1, :, :, :]
                        else:
                            continue
                            
                        # ç¡®ä¿å¼ é‡å½¢çŠ¶æ­£ç¡®
                        if logits.shape[1] != A2:
                            continue
                            
                        logits = logits.reshape(1, A, 2, H, W)
                        probs = jt.softmax(logits, dim=2)  # softmax over class dim
                        fg = probs[:, :, 1, :, :].reshape(-1)
                        
                        # ç”Ÿæˆä¸­å¿ƒç‚¹ boxesï¼ˆç®€åŒ–ï¼‰ï¼šä»¥ stride ä¸ºè¾¹é•¿çš„æ­£æ–¹å½¢ï¼Œä¹˜ä»¥æ¯”ä¾‹ 8
                        scale = 8.0
                        # ç½‘æ ¼ä¸­å¿ƒ - ä½¿ç”¨numpyé¿å…Jittorå¼ é‡æ“ä½œé—®é¢˜
                        yy, xx = _np.meshgrid(_np.arange(H), _np.arange(W), indexing='ij')
                        xx = (xx + 0.5) * stride
                        yy = (yy + 0.5) * stride
                        
                        # è½¬æ¢ä¸ºJittorå¼ é‡
                        xx = jt.array(xx.astype(_np.float32))
                        yy = jt.array(yy.astype(_np.float32))
                        
                        # æ‰©å±•ç»´åº¦
                        xx = xx.unsqueeze(0).unsqueeze(0).expand(A, 1, H, W)
                        yy = yy.unsqueeze(0).unsqueeze(0).expand(A, 1, H, W)
                        
                        half = (stride * scale) / 2.0
                        x1 = (xx - half).clamp(0, float(img_shape[3]-1))
                        y1 = (yy - half).clamp(0, float(img_shape[2]-1))
                        x2 = (xx + half).clamp(0, float(img_shape[3]-1))
                        y2 = (yy + half).clamp(0, float(img_shape[2]-1))
                        
                        # é‡å¡‘å¹¶è½¬ç½®
                        boxes = jt.stack([x1, y1, x2, y2], dim=1).reshape(4, -1).transpose(1, 0)
                        
                        # é€‰ top-k
                        k = int(min(nms_pre, boxes.shape[0]))
                        if k <= 0:
                            continue
                            
                        # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpy
                        try:
                            scores_np = ensure_jittor_var(fg, "fg").numpy()
                            boxes_np = ensure_jittor_var(boxes, "boxes").numpy()
                        except Exception as e:
                            print(f"âš ï¸  å¼ é‡è½¬æ¢å¤±è´¥: {e}")
                            continue
                            
                        if len(scores_np) == 0 or len(boxes_np) == 0:
                            continue
                            
                        order = _np.argsort(-scores_np)[:k]
                        boxes_np = boxes_np[order]
                        scores_np = scores_np[order]
                        
                        # NMS
                        keep = self._nms_numpy(boxes_np, scores_np, iou_thr=nms_thr, max_num=max_num)
                        if len(keep) > 0:
                            boxes_np = boxes_np[keep]
                            scores_np = scores_np[keep]
                            boxes_all.append(boxes_np)
                            scores_all.append(scores_np)
                            
                    if len(boxes_all) == 0:
                        continue
                        
                    boxes_all = _np.concatenate(boxes_all, axis=0)
                    scores_all = _np.concatenate(scores_all, axis=0)
                    
                    # å†æ¬¡å…¨å±€ top-k
                    if len(boxes_all) > 0:
                        order = _np.argsort(-scores_all)[:max_num]
                        boxes_all = boxes_all[order]
                        b_col = _np.full((boxes_all.shape[0], 1), float(b), dtype=_np.float32)
                        rois_b = _np.concatenate([b_col, boxes_all.astype(_np.float32)], axis=1)
                        rois_concat.append(rois_b)
                        
            except Exception as e:
                print(f"âš ï¸  ç”Ÿæˆæè®®å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                
            if len(rois_concat) == 0:
                return jt.zeros((0, 5), dtype='float32')
                
            try:
                rois_np = _np.concatenate(rois_concat, axis=0)
                return jt.array(rois_np)
            except Exception as e:
                print(f"âš ï¸  æœ€ç»ˆæè®®åˆå¹¶å¤±è´¥: {e}")
                return jt.zeros((0, 5), dtype='float32')
        
        
    
    return JittorModelWithComponents(cfg, stage)


def create_jittor_optimizer(model, cfg):
    """åˆ›å»ºJittorä¼˜åŒ–å™¨"""
    print("ğŸ”§ åˆ›å»ºJittorä¼˜åŒ–å™¨...")
    
    # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–ä¼˜åŒ–å™¨è®¾ç½®
    optimizer_cfg = cfg.optimizer
    
    # ä½¿ç”¨ç”¨æˆ·é…ç½®çš„å­¦ä¹ ç‡ï¼Œä¸å†å¼ºåˆ¶é™ä½
    base_lr = optimizer_cfg.get('lr', 0.02)
    
    print(f"ğŸ“Š ä½¿ç”¨å­¦ä¹ ç‡: {base_lr}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = None
    if optimizer_cfg.type == 'SGD':
        optimizer = jt.optim.SGD(
            model.parameters(),
            lr=base_lr,  # ç›´æ¥ä½¿ç”¨é…ç½®çš„å­¦ä¹ ç‡
            momentum=optimizer_cfg.get('momentum', 0.9),
            weight_decay=optimizer_cfg.get('weight_decay', 0.0001),
            nesterov=optimizer_cfg.get('nesterov', False)
        )
        print(f"âœ… åˆ›å»ºSGDä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {base_lr}")
    else:
        print(f"âš ï¸  ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨ç±»å‹: {optimizer_cfg.type}ï¼Œä½¿ç”¨é»˜è®¤SGD")
        optimizer = jt.optim.SGD(
            model.parameters(),
            lr=base_lr,
            momentum=0.9,
            weight_decay=0.0001
        )

    # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = None  # é»˜è®¤å€¼
    if hasattr(cfg, 'lr_config') and cfg.lr_config is not None:
        lr_config = cfg.lr_config
        print(f"ğŸ“Š å­¦ä¹ ç‡é…ç½®: {lr_config}")
        
        # å¤„ç†stepç­–ç•¥ï¼ˆè¿™æ˜¯é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨çš„ç­–ç•¥ï¼‰
        if hasattr(lr_config, 'policy') and lr_config.policy == 'step':
            step = lr_config.get('step', [3, 4])
            gamma = lr_config.get('gamma', 0.1)
            if isinstance(step, list):
                milestones = step
            else:
                milestones = [step]
            
            scheduler = jt.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)
            print(f"âœ… è®¾ç½®StepLRè°ƒåº¦å™¨: milestones={milestones}, gamma={gamma}")
            
        elif hasattr(lr_config, 'type') and lr_config.type == 'MultiStepLR':
            milestones = lr_config.get('milestones', [8, 11])
            gamma = lr_config.get('gamma', 0.1)
            scheduler = jt.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)
            print(f"âœ… è®¾ç½®MultiStepLRè°ƒåº¦å™¨: milestones={milestones}, gamma={gamma}")
            
        elif hasattr(lr_config, 'type') and lr_config.type == 'StepLR':
            step_size = lr_config.get('step', 8)
            if isinstance(step_size, list):
                step_size = step_size[0] if len(step_size) > 0 else 8
            gamma = lr_config.get('gamma', 0.1)
            scheduler = jt.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
            print(f"âœ… è®¾ç½®StepLRè°ƒåº¦å™¨: step_size={step_size}, gamma={gamma}")
            
        else:
            if hasattr(lr_config, 'type'):
                print(f"âš ï¸  ä¸æ”¯æŒçš„å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹: {lr_config.type}")
            elif hasattr(lr_config, 'policy'):
                print(f"âš ï¸  ä¸æ”¯æŒçš„å­¦ä¹ ç‡ç­–ç•¥: {lr_config.policy}")
            else:
                print("âš ï¸  lr_configæ²¡æœ‰typeæˆ–policyå±æ€§")
            print("âš ï¸  å­¦ä¹ ç‡è°ƒåº¦å™¨æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨å›ºå®šå­¦ä¹ ç‡")
    else:
        print("âš ï¸  é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å­¦ä¹ ç‡é…ç½®ï¼Œå°†ä½¿ç”¨å›ºå®šå­¦ä¹ ç‡")
    
    # ç¡®ä¿schedulerä¸ä¸ºNone
    if scheduler is None:
        print("ğŸ“Š åˆ›å»ºé»˜è®¤çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå›ºå®šå­¦ä¹ ç‡ï¼‰")
        scheduler = jt.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=1.0)  # å›ºå®šå­¦ä¹ ç‡
    
    return optimizer, scheduler


def create_jittor_trainer(model, datasets, cfg, args, distributed=False, validate=True, timestamp=None, meta=None, logger=None, json_log_path=None):
    """åˆ›å»ºJittorè®­ç»ƒå™¨"""
    print(f"ğŸ”§ åˆ›å»ºJittorè®­ç»ƒå™¨")
    if logger is None:
        from mmdet.utils import get_root_logger as _grl
        logger = _grl()
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    from mmdet.datasets import build_dataloader
    
    # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨åŒ…è£…å™¨ï¼Œå¤„ç†DataContainer
    def create_jittor_dataloader(dataset, samples_per_gpu, workers_per_gpu, **kwargs):
        """åˆ›å»ºJittorå…¼å®¹çš„æ•°æ®åŠ è½½å™¨"""
        dataloader = build_dataloader(
            dataset,
            samples_per_gpu,
            workers_per_gpu,
            num_gpus=1,
            dist=distributed,
            shuffle=True,
            seed=cfg.seed
        )
        
        # åŒ…è£…æ•°æ®åŠ è½½å™¨ï¼Œåœ¨è¿”å›æ•°æ®æ—¶å¤„ç†DataContainer
        class JittorDataLoaderWrapper:
            def __init__(self, original_loader):
                self.original_loader = original_loader
                self.dataset = original_loader.dataset
                self.batch_size = original_loader.batch_size
                self.num_workers = original_loader.num_workers
                self.sampler = original_loader.sampler
                self.pin_memory = getattr(original_loader, 'pin_memory', False)
                self.drop_last = getattr(original_loader, 'drop_last', False)
                self.timeout = getattr(original_loader, 'timeout', 0)
                self.worker_init_fn = getattr(original_loader, 'worker_init_fn', None)
                self.multiprocessing_context = getattr(original_loader, 'multiprocessing_context', None)
                self.generator = getattr(original_loader, 'generator', None)
                self.prefetch_factor = getattr(original_loader, 'prefetch_factor', 2)
                self.persistent_workers = getattr(original_loader, 'persistent_workers', False)
            
            def __iter__(self):
                for batch in self.original_loader:
                    # é¢„å¤„ç†æ•°æ®ï¼Œæå–DataContainerä¸­çš„æ•°æ®
                    processed_batch = {}
                    for key, value in batch.items():
                        if hasattr(value, 'data') and hasattr(value, 'stack') and hasattr(value, 'cpu_only'):
                            # è¿™æ˜¯DataContainerï¼Œæå–å…¶dataå±æ€§
                            processed_batch[key] = value.data
                        else:
                            processed_batch[key] = value
                    yield processed_batch
            
            def __len__(self):
                return len(self.original_loader)
        
        return JittorDataLoaderWrapper(dataloader)
    
    data_loaders = [
        create_jittor_dataloader(
            ds,
            cfg.data.samples_per_gpu,
            cfg.data.workers_per_gpu
        )
        for ds in datasets
    ]
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer, scheduler = create_jittor_optimizer(model, cfg)
    
    # æ£€æŸ¥æ¨¡å‹å‚æ•°ç¨³å®šæ€§
    print("ğŸ” æ£€æŸ¥æ¨¡å‹å‚æ•°ç¨³å®šæ€§...")
    try:
        param_stats = {}
        for name, param in model.named_parameters():
            if param.requires_grad:
                param_np = param.detach().numpy()
                param_stats[name] = {
                    'mean': float(np.mean(param_np)),
                    'std': float(np.std(param_np)),
                    'min': float(np.min(param_np)),
                    'max': float(np.max(param_np)),
                    'has_nan': np.any(np.isnan(param_np)),
                    'has_inf': np.any(np.isinf(param_np))
                }
                
                # æ£€æŸ¥å¼‚å¸¸å‚æ•°
                if param_stats[name]['has_nan']:
                    print(f"âš ï¸  å‚æ•° {name} åŒ…å« NaN å€¼")
                if param_stats[name]['has_inf']:
                    print(f"âš ï¸  å‚æ•° {name} åŒ…å« Inf å€¼")
                if abs(param_stats[name]['mean']) > 1000:
                    print(f"âš ï¸  å‚æ•° {name} å‡å€¼è¿‡å¤§: {param_stats[name]['mean']:.4f}")
        
        print(f"âœ… æ¨¡å‹å‚æ•°æ£€æŸ¥å®Œæˆï¼Œå…±æ£€æŸ¥ {len(param_stats)} ä¸ªå‚æ•°")
        
        # æ‰“å°å‰å‡ ä¸ªå‚æ•°çš„ç»Ÿè®¡ä¿¡æ¯
        print("ğŸ“Š å‰5ä¸ªå‚æ•°ç»Ÿè®¡:")
        for i, (name, stats) in enumerate(list(param_stats.items())[:5]):
            print(f"   {name}: mean={stats['mean']:.4f}, std={stats['std']:.4f}, range=[{stats['min']:.4f}, {stats['max']:.4f}]")
            
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹å‚æ•°æ£€æŸ¥å¤±è´¥: {e}")
    
    # æ¢¯åº¦è£å‰ªé…ç½®ï¼ˆæ¥è‡ª mmdet é…ç½®ï¼‰
    grad_clip_cfg = None
    try:
        if hasattr(cfg, 'optimizer_config') and cfg.optimizer_config is not None:
            grad_clip_cfg = getattr(cfg.optimizer_config, 'grad_clip', None)
    except Exception:
        grad_clip_cfg = None
    
    # å­¦ä¹ ç‡é…ç½®
    step_epochs = []
    if hasattr(cfg, 'lr_config'):
        lr_config = cfg.lr_config
        if hasattr(lr_config, 'type') and lr_config.type == 'MultiStepLR':
            step_epochs = lr_config.get('milestones', [])
            print(f"ğŸ“Š å­¦ä¹ ç‡è¡°å‡è½®æ¬¡: {step_epochs}")
        elif hasattr(lr_config, 'type') and lr_config.type == 'StepLR':
            step_size = lr_config.get('step', 8)
            if isinstance(step_size, list):
                step_epochs = step_size
            else:
                step_epochs = [step_size]
            print(f"ğŸ“Š å­¦ä¹ ç‡è¡°å‡è½®æ¬¡: {step_epochs}")
    
    # è®­ç»ƒå¾ªç¯
    # print("ğŸ¯ å¼€å§‹Jittorè®­ç»ƒå¾ªç¯...")
    logger.info("Start Jittor training loop...")
    max_epochs = args.epochs if hasattr(args, 'epochs') else (cfg.runner.max_epochs if hasattr(cfg, 'runner') else 12)
    
    # è®­ç»ƒç»Ÿè®¡
    total_steps = 0
    epoch_losses = []
    
    # JSON æ—¥å¿—å·¥å…·
    def append_json_log(record: dict):
        if not json_log_path:
            return
        try:
            with open(json_log_path, 'a') as jf:
                jf.write(json.dumps(record, ensure_ascii=False) + "\n")
        except Exception:
            pass

    # è®­ç»ƒå¼€å§‹æ—¥å¿—
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼")
    print(f"ğŸ“Š æ€»è½®æ¬¡: {max_epochs}")
    print(f"ğŸ“Š åˆå§‹å­¦ä¹ ç‡: {optimizer.lr:.6f}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {cfg.data.samples_per_gpu}")
    print(f"ğŸ“Š å·¥ä½œç›®å½•: {cfg.work_dir}")
    logger.info(f"Training started: epochs={max_epochs}, lr={optimizer.lr:.6f}")
    
    # åˆå§‹åŒ–è®­ç»ƒç»Ÿè®¡
    epoch_records = []
    
    for epoch in range(max_epochs):
        print(f"\nğŸ“… è®­ç»ƒè½®æ¬¡ {epoch + 1}/{max_epochs}")
        print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {optimizer.lr:.6f}")
        logger.info(f"Epoch [{epoch+1}/{max_epochs}] lr={optimizer.lr:.6f}")
        
        # æ¯ä¸ªepochå¼€å§‹æ—¶æ¸…ç†å†…å­˜
        if epoch > 0:  # ç¬¬ä¸€ä¸ªepochä¸éœ€è¦æ¸…ç†
            clear_jittor_cache()
            gc.collect()
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # è½®æ¬¡ç»Ÿè®¡
        epoch_loss = 0.0
        epoch_components = {}
        num_batches = 0
        
        # éå†æ•°æ®åŠ è½½å™¨
        total_batches = len(data_loaders[0])
        print(f"ğŸ“Š æœ¬è½®æ¬¡æ€»æ‰¹æ¬¡æ•°: {total_batches}")
        
        # æ·»åŠ æ‰¹æ¬¡è®¡æ•°å™¨ï¼Œç¡®ä¿å®é™…å¤„ç†äº†æ‰€æœ‰æ‰¹æ¬¡
        processed_batches = 0
        skipped_batches = 0
        
        # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(
            enumerate(data_loaders[0]), 
            total=total_batches,
            desc=f"Epoch {epoch+1}/{max_epochs}",
            leave=True,
            ncols=100
        )
        
        for i, data_batch in pbar:
            
            try:
                # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®æ‰¹æ¬¡çš„æ‰¹æ¬¡å¤§å°
                if i == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ˜¾ç¤º
                    print(f"ğŸ” æ•°æ®æ‰¹æ¬¡è°ƒè¯•ä¿¡æ¯:")
                    print(f"   data_batchç±»å‹: {type(data_batch)}")
                    if 'img' in data_batch:
                        img_data = data_batch['img']
                        print(f"   imgç±»å‹: {type(img_data)}")
                        try:
                            img_var = ensure_jittor_var(img_data, "img_data")
                            print(f"   imgå½¢çŠ¶: {img_var.shape}")
                        except Exception:
                            if isinstance(img_data, (list, tuple)) and len(img_data) > 0:
                                try:
                                    first_img = ensure_jittor_var(img_data[0], "img_data[0]")
                                    print(f"   ç¬¬ä¸€ä¸ªimgå½¢çŠ¶: {first_img.shape}")
                                except Exception:
                                    print(f"   ç¬¬ä¸€ä¸ªimgè½¬æ¢å¤±è´¥")
                            else:
                                print(f"   imgè½¬æ¢å¤±è´¥")
                    print(f"   data_batché”®: {list(data_batch.keys())}")
                
                # ä»…è½¬æ¢å¿…è¦é”®ï¼Œé¿å…å¯¹å¤æ‚å…ƒä¿¡æ¯é€’å½’å¯¼è‡´çš„ __instancecheck__ é€’å½’
                wanted_keys = ['img', 'gt_bboxes', 'gt_labels', 'proposals']
                jt_data = {}
                for key in wanted_keys:
                    if key in data_batch:
                        jt_data[key] = safe_convert_to_jittor(data_batch[key])

                # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç®€åŒ–ç±»å‹è½¬æ¢
                def to_jt_var(x):
                    """å®‰å…¨åœ°å°†å„ç§æ•°æ®ç±»å‹è½¬æ¢ä¸ºJittor Var"""
                    return ensure_jittor_var(x, "data", None)

                # å¼ºåˆ¶è½¬æ¢æ‰€æœ‰æ•°æ®ä¸ºJittoræ ¼å¼
                if 'img' in jt_data:
                    # å¤„ç†å›¾åƒæ•°æ®ï¼šç¡®ä¿æ˜¯å•ä¸ªå¼ é‡è€Œä¸æ˜¯åˆ—è¡¨
                    try:
                        if isinstance(jt_data['img'], (list, tuple)) and len(jt_data['img']) > 0:
                            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç›´æ¥è½¬æ¢æ•´ä¸ªåˆ—è¡¨ï¼ˆMMDetectionçš„é»˜è®¤è¡Œä¸ºï¼‰
                            jt_data['img'] = to_jt_var(jt_data['img'])
                        else:
                            jt_data['img'] = to_jt_var(jt_data['img'])
                        
                        # ä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿å›¾åƒæ•°æ®æ ¼å¼æ­£ç¡®ï¼Œä¸å¼ºåˆ¶æŒ‡å®šå½¢çŠ¶
                        jt_data['img'] = ensure_jittor_var(jt_data['img'], "img")
                        print(f"ğŸ” å›¾åƒæ•°æ®è½¬æ¢å: {jt_data['img'].shape}, ç±»å‹: {type(jt_data['img'])}")
                    except Exception as img_error:
                        print(f"âš ï¸  å›¾åƒæ•°æ®è½¬æ¢å¤±è´¥: {img_error}")
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å€¼
                        jt_data['img'] = jt.zeros((1, 3, 224, 224), dtype='float32')
                        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤å›¾åƒå¼ é‡: {jt_data['img'].shape}")
                
                if 'gt_bboxes' in jt_data:
                    # å¤„ç† DataContainer ç±»å‹
                    try:
                        if hasattr(jt_data['gt_bboxes'], 'data'):
                            # å¦‚æœæ˜¯ DataContainerï¼Œæå–å…¶ data å±æ€§
                            jt_data['gt_bboxes'] = jt_data['gt_bboxes'].data
                    except Exception:
                        pass
                    
                    # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç®€åŒ–è½¬æ¢
                    try:
                        jt_data['gt_bboxes'] = ensure_jittor_var(jt_data['gt_bboxes'], "gt_bboxes")
                        print(f"ğŸ” GT bboxes è½¬æ¢å: {jt_data['gt_bboxes'].shape}, ç±»å‹: {type(jt_data['gt_bboxes'])}")
                    except Exception as bbox_error:
                        print(f"âš ï¸  GT bboxes è½¬æ¢å¤±è´¥: {bbox_error}")
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        jt_data['gt_bboxes'] = jt.zeros((1, 4), dtype='float32')
                        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤ GT bboxes: {jt_data['gt_bboxes'].shape}")
                
                if 'gt_labels' in jt_data:
                    # å¤„ç† DataContainer ç±»å‹
                    try:
                        if hasattr(jt_data['gt_labels'], 'data'):
                            # å¦‚æœæ˜¯ DataContainerï¼Œæå–å…¶ data å±æ€§
                            jt_data['gt_labels'] = jt_data['gt_labels'].data
                    except Exception:
                        pass
                    
                    # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç®€åŒ–è½¬æ¢
                    try:
                        jt_data['gt_labels'] = ensure_jittor_var(jt_data['gt_labels'], "gt_labels")
                        print(f"ğŸ” GT labels è½¬æ¢å: {jt_data['gt_labels'].shape}, ç±»å‹: {type(jt_data['gt_labels'])}")
                    except Exception as label_error:
                        print(f"âš ï¸  GT labels è½¬æ¢å¤±è´¥: {label_error}")
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        jt_data['gt_labels'] = jt.zeros((1,), dtype='int32')
                        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤ GT labels: {jt_data['gt_labels'].shape}")
            
                if 'proposals' in jt_data:
                    # ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°ç®€åŒ–è½¬æ¢
                    jt_data['proposals'] = ensure_jittor_var(jt_data['proposals'], "proposals")
                
                # æ•°æ®æ ¼å¼éªŒè¯å’Œä¿®å¤
                try:
                    # ç¡®ä¿gt_bboxeså’Œgt_labelsçš„æ ¼å¼æ­£ç¡®
                    if 'gt_bboxes' in jt_data and 'gt_labels' in jt_data:
                        bbox_shape = jt_data['gt_bboxes'].shape
                        label_shape = jt_data['gt_labels'].shape
                        
                        # æ£€æŸ¥gt_bboxesæ ¼å¼ï¼šåº”è¯¥æ˜¯ [N, 4] å…¶ä¸­Næ˜¯è¾¹ç•Œæ¡†æ•°é‡
                        if len(bbox_shape) == 2 and bbox_shape[1] == 4:
                            print(f"âœ… gt_bboxesæ ¼å¼æ­£ç¡®: {bbox_shape}")
                        elif len(bbox_shape) == 3 and bbox_shape[2] == 4:
                            # å¦‚æœæ˜¯ [B, N, 4] æ ¼å¼ï¼Œå±•å¹³ä¸º [B*N, 4]
                            jt_data['gt_bboxes'] = jt_data['gt_bboxes'].view(-1, 4)
                            print(f"âœ… gt_bboxeså·²å±•å¹³: {jt_data['gt_bboxes'].shape}")
                        else:
                            print(f"âš ï¸  gt_bboxesæ ¼å¼å¼‚å¸¸: {bbox_shape}")
                        
                        # æ£€æŸ¥gt_labelsæ ¼å¼ï¼šåº”è¯¥æ˜¯ [N] å…¶ä¸­Næ˜¯æ ‡ç­¾æ•°é‡
                        if len(label_shape) == 1:
                            print(f"âœ… gt_labelsæ ¼å¼æ­£ç¡®: {label_shape}")
                        elif len(label_shape) == 2:
                            # å¦‚æœæ˜¯ [B, N] æ ¼å¼ï¼Œå±•å¹³ä¸º [B*N]
                            jt_data['gt_labels'] = jt_data['gt_labels'].view(-1)
                            print(f"âœ… gt_labelså·²å±•å¹³: {jt_data['gt_labels'].shape}")
                        else:
                            print(f"âš ï¸  gt_labelsæ ¼å¼å¼‚å¸¸: {label_shape}")
                        
                        # ç¡®ä¿è¾¹ç•Œæ¡†å’Œæ ‡ç­¾æ•°é‡ä¸€è‡´
                        bbox_count = jt_data['gt_bboxes'].shape[0]
                        label_count = jt_data['gt_labels'].shape[0]
                        if bbox_count != label_count:
                            print(f"âš ï¸  è¾¹ç•Œæ¡†å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…: bboxes={bbox_count}, labels={label_count}")
                            # å–è¾ƒå°çš„æ•°é‡
                            min_count = min(bbox_count, label_count)
                            if bbox_count > min_count:
                                jt_data['gt_bboxes'] = jt_data['gt_bboxes'][:min_count]
                            if label_count > min_count:
                                jt_data['gt_labels'] = jt_data['gt_labels'][:min_count]
                            print(f"âœ… å·²è°ƒæ•´æ•°é‡ä¸º: {min_count}")
                except Exception as e:
                    print(f"âš ï¸  æ•°æ®æ ¼å¼éªŒè¯å¤±è´¥: {e}")
                
                # æ¯å¤„ç†å‡ ä¸ªæ‰¹æ¬¡å°±æ¸…ç†ä¸€æ¬¡å†…å­˜
                if i % 3 == 0:  # æ›´é¢‘ç¹çš„å†…å­˜æ¸…ç†
                    try:
                        clear_jittor_cache()
                        jt.sync_all()
                        # å¼ºåˆ¶åƒåœ¾å›æ”¶
                        import gc
                        gc.collect()
                        
                        # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                        try:
                            import pynvml
                            pynvml.nvmlInit()
                            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                            info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                            used_gb = info.used / 1024**3
                            total_gb = info.total / 1024**3
                            if used_gb > total_gb * 0.8:  # å¦‚æœä½¿ç”¨ç‡è¶…è¿‡80%
                                print(f"âš ï¸  GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {used_gb:.2f}GB/{total_gb:.2f}GB")
                                # æ›´æ¿€è¿›çš„å†…å­˜æ¸…ç†
                                jt.gc()
                                jt.sync_all()
                                gc.collect()
                                print("ğŸš¨ å†…å­˜ä½¿ç”¨ç‡ä»ç„¶è¿‡é«˜ï¼Œè¿›è¡Œæ¿€è¿›æ¸…ç†...")
                        except Exception:
                            pass
                    except:
                        pass
                
                # è°ƒè¯•ä¿¡æ¯ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºï¼Œç®€åŒ–è¾“å‡ºï¼‰
                if i == 0:
                    print(f"ğŸ” æ•°æ®è°ƒè¯•ä¿¡æ¯:")
                    for key, value in jt_data.items():
                        if isinstance(value, jt.Var):
                            print(f"   {key}: {value.shape}, ç±»å‹: {type(value)}")
                        elif isinstance(value, (list, tuple)) and len(value) > 0:
                            print(f"   {key}: list with {len(value)} items")
                            first_item = ensure_jittor_var(value[0], f"{key}[0]")
                            print(f"     first item shape: {first_item.shape}, ç±»å‹: {type(first_item)}")
                        else:
                            print(f"   {key}: ç±»å‹: {type(value)}")
                
                # å‰å‘ä¼ æ’­
                losses = model(**jt_data)
                
                # ç¡®ä¿ total_loss å˜é‡è¢«åˆå§‹åŒ–
                total_loss = None
                
                # ç«‹å³æ£€æŸ¥rcnn_score_lossï¼Œè¿™æ˜¯é—®é¢˜çš„æ ¹æº
                if isinstance(losses, dict) and 'rcnn_score_loss' in losses:
                    score_loss_val = ensure_jittor_var(losses['rcnn_score_loss'], 'rcnn_score_loss').item()
                    if abs(score_loss_val) > 1000:
                        print(f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸çš„rcnn_score_loss: {score_loss_val}")
                        # ä¸è¦ç›´æ¥é‡ç½®ï¼Œè€Œæ˜¯å°è¯•ç¼©æ”¾
                        if score_loss_val > 0:
                            scale_factor = 1000.0 / score_loss_val
                            losses['rcnn_score_loss'] = losses['rcnn_score_loss'] * scale_factor
                            print(f"ğŸ”’ rcnn_score_loss å·²ç¼©æ”¾: {score_loss_val:.2e} -> {ensure_jittor_var(losses['rcnn_score_loss'], 'rcnn_score_loss').item():.4f}")
                        else:
                            # å¦‚æœæ˜¯è´Ÿå€¼ï¼Œå–ç»å¯¹å€¼åç¼©æ”¾
                            scale_factor = 1000.0 / abs(score_loss_val)
                            losses['rcnn_score_loss'] = losses['rcnn_score_loss'] * scale_factor
                            print(f"ğŸ”’ rcnn_score_loss å·²ç¼©æ”¾: {score_loss_val:.2e} -> {ensure_jittor_var(losses['rcnn_score_loss'], 'rcnn_score_loss').item():.4f}")
                
                # è°ƒè¯•ï¼šæ£€æŸ¥æŸå¤±å€¼æ˜¯å¦åŒ…å« NaN æˆ– infï¼Œå¹¶è¿›è¡Œæ›´ä¸¥æ ¼çš„ç¨³å®šåŒ–å¤„ç†
                if isinstance(losses, dict):
                    # æ£€æŸ¥æ¯ä¸ªæŸå¤±å€¼å¹¶è¿›è¡Œç¨³å®šåŒ–å¤„ç†
                    for key, value in losses.items():
                        loss_val = ensure_jittor_var(value, f"losses[{key}]").item()
                        # æ›´ä¸¥æ ¼çš„æŸå¤±å€¼æ£€æŸ¥
                        if not np.isfinite(loss_val) or abs(loss_val) > 1000:
                            print(f"âš ï¸  WARNING: {key} = {loss_val} (å¼‚å¸¸å€¼)")
                            logger.warning(f"Abnormal loss detected: {key} = {loss_val}")
                            
                            # æ ¹æ®æŸå¤±ç±»å‹è¿›è¡Œä¸åŒçš„å¤„ç†
                            if key in ['rcnn_score_loss', 'rcnn_cls_loss', 'rcnn_bbox_loss']:
                                # å¯¹äºåˆ†ç±»å’Œå›å½’æŸå¤±ï¼Œå°è¯•ç¼©æ”¾è€Œä¸æ˜¯é‡ç½®
                                if np.isnan(loss_val) or np.isinf(loss_val):
                                    losses[key] = jt.array(0.1)
                                    print(f"ğŸ”’ {key} é‡ç½®ä¸º: 0.1 (NaN/Inf)")
                                elif abs(loss_val) > 1000:
                                    # ç¼©æ”¾å¼‚å¸¸å¤§çš„æŸå¤±å€¼
                                    scale_factor = 100.0 / abs(loss_val)
                                    losses[key] = losses[key] * scale_factor
                                    print(f"ğŸ”’ {key} å·²ç¼©æ”¾: {loss_val:.2e} -> {ensure_jittor_var(losses[key], f'losses[{key}]').item():.4f}")
                            else:
                                # å¯¹äºå…¶ä»–æŸå¤±ï¼Œå°è¯•ç¼©æ”¾
                                if abs(loss_val) > 1000:
                                    scale_factor = 100.0 / abs(loss_val)
                                    losses[key] = losses[key] * scale_factor
                                    print(f"ğŸ”’ {key} å·²ç¼©æ”¾: {loss_val:.2e} -> {ensure_jittor_var(losses[key], f'losses[{key}]').item():.4f}")
                                elif np.isnan(loss_val) or np.isinf(loss_val):
                                    losses[key] = jt.array(0.0)
                                    print(f"ğŸ”’ {key} é‡ç½®ä¸º: 0.0 (NaN/Inf)")
                    
                    # è®¡ç®—æ€»æŸå¤±å¹¶è¿›è¡Œç¨³å®šåŒ–
                    total_loss = sum(losses.values())
                    
                    # æ£€æŸ¥æ€»æŸå¤±æ˜¯å¦æœ‰æ•ˆ
                    total_loss_val = ensure_jittor_var(total_loss, "total_loss").item()
                    if not np.isfinite(total_loss_val) or abs(total_loss_val) > 1000:
                        print(f"âš ï¸  WARNING: æ€»æŸå¤± = {total_loss_val} (å¼‚å¸¸å€¼)")
                        logger.warning(f"Abnormal total loss: {total_loss_val}")
                        
                        # å¦‚æœæ€»æŸå¤±æ— æ•ˆï¼Œä½¿ç”¨æ‰€æœ‰æœ‰æ•ˆæŸå¤±çš„æ€»å’Œ
                        valid_losses = []
                        for key, value in losses.items():
                            val = ensure_jittor_var(value, f"losses[{key}]").item()
                            if np.isfinite(val) and abs(val) <= 1000:
                                valid_losses.append(value)
                        
                        if valid_losses:
                            total_loss = sum(valid_losses)
                            print(f"âœ… ä½¿ç”¨æœ‰æ•ˆæŸå¤±é‡æ–°è®¡ç®—æ€»æŸå¤±: {ensure_jittor_var(total_loss, 'total_loss').item()}")
                        else:
                            # å¦‚æœæ‰€æœ‰æŸå¤±éƒ½æ— æ•ˆï¼Œå°è¯•ä½¿ç”¨ä¸€ä¸ªåŸºäºæ‰¹æ¬¡å¤§å°çš„åˆç†å€¼
                            total_loss = jt.array(0.1 * batch_size)
                            print(f"âš ï¸  æ‰€æœ‰æŸå¤±éƒ½æ— æ•ˆï¼Œä½¿ç”¨åŸºäºæ‰¹æ¬¡å¤§å°çš„å€¼: {ensure_jittor_var(total_loss, 'total_loss').item()}")
                    
                    # ç´¯ç§¯å„é¡¹æŸå¤±
                    for key, value in losses.items():
                        if key != 'loss':
                            if key not in epoch_components:
                                epoch_components[key] = 0.0
                            try:
                                epoch_components[key] += ensure_jittor_var(value, f"losses[{key}]").item()
                            except Exception as e:
                                print(f"âš ï¸  ç´¯ç§¯æŸå¤±å¤±è´¥ {key}: {e}")
                                epoch_components[key] += 0.0
                else:
                    # å¦‚æœlossesä¸æ˜¯å­—å…¸ï¼Œç¡®ä¿total_lossè¢«æ­£ç¡®å®šä¹‰
                    try:
                        total_loss = ensure_jittor_var(losses, "losses", (1,))
                        # æ£€æŸ¥æ€»æŸå¤±æ˜¯å¦æœ‰æ•ˆ
                        total_loss_val = total_loss.item()
                        if not np.isfinite(total_loss_val) or abs(total_loss_val) > 1000:
                            print(f"âš ï¸  WARNING: æ€»æŸå¤± = {total_loss_val} (å¼‚å¸¸å€¼)")
                            logger.warning(f"Abnormal total loss: {total_loss_val}")
                            # å¦‚æœæ€»æŸå¤±æ— æ•ˆï¼Œä½¿ç”¨ä¸€ä¸ªå°çš„é»˜è®¤å€¼
                            total_loss = jt.array(0.001)
                    except Exception as e:
                        print(f"âš ï¸  æŸå¤±è½¬æ¢å¤±è´¥: {e}")
                        total_loss = jt.array(0.001)
                
                # æ¸©å’Œåœ°é™åˆ¶æŸå¤±å€¼èŒƒå›´ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
                try:
                    # å…ˆæ£€æŸ¥æŸå¤±å€¼æ˜¯å¦å¼‚å¸¸
                    loss_val = ensure_jittor_var(total_loss, "total_loss").item()
                    if not np.isfinite(loss_val):
                        print(f"âš ï¸  æ£€æµ‹åˆ°éæœ‰é™æŸå¤±å€¼: {loss_val}")
                        # å¦‚æœæŸå¤±å€¼éæœ‰é™ï¼Œä½¿ç”¨ä¸€ä¸ªåŸºäºæ‰¹æ¬¡å¤§å°çš„åˆç†å€¼
                        total_loss = jt.array(0.1 * batch_size)
                        print(f"ğŸ”’ ä½¿ç”¨åŸºäºæ‰¹æ¬¡å¤§å°çš„æŸå¤±å€¼: {ensure_jittor_var(total_loss, 'total_loss').item()}")
                    elif abs(loss_val) > 10000:  # æé«˜é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦é™åˆ¶
                        print(f"âš ï¸  æ£€æµ‹åˆ°è¿‡å¤§æŸå¤±å€¼: {loss_val}")
                        # å¦‚æœæŸå¤±å€¼è¿‡å¤§ï¼Œè¿›è¡Œæ¸©å’Œçš„ç¼©æ”¾
                        scale_factor = 1000.0 / abs(loss_val)
                        total_loss = total_loss * scale_factor
                        print(f"ğŸ”’ æŸå¤±å€¼å·²ç¼©æ”¾: {loss_val:.2e} -> {ensure_jittor_var(total_loss, 'total_loss').item():.4f}")
                    else:
                        # åªåœ¨æŸå¤±å€¼æ­£å¸¸æ—¶è¿›è¡Œæ¸©å’Œé™åˆ¶
                        total_loss = total_loss.clamp(-1000.0, 1000.0)
                except Exception as e:
                    print(f"âš ï¸  æŸå¤±å€¼é™åˆ¶å¤±è´¥: {e}")
                    # å¦‚æœé™åˆ¶å¤±è´¥ï¼Œä½¿ç”¨åŸºäºæ‰¹æ¬¡å¤§å°çš„å€¼
                    total_loss = jt.array(0.1 * batch_size)
                    print(f"ğŸ”’ ä½¿ç”¨åŸºäºæ‰¹æ¬¡å¤§å°çš„æŸå¤±å€¼: {ensure_jittor_var(total_loss, 'total_loss').item()}")
                
                # åå‘ä¼ æ’­ & æ¢¯åº¦è£å‰ªï¼ˆè‹¥é…ç½®å¯ç”¨ï¼‰
                # print(f"ğŸ”„ å¼€å§‹åå‘ä¼ æ’­...")
                grad_norm_value = None
                if grad_clip_cfg is not None:
                    # åœ¨Jittorä¸­ï¼Œæ¢¯åº¦è£å‰ªé€šå¸¸é€šè¿‡ä¼˜åŒ–å™¨é…ç½®å®ç°ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                    try:
                        max_norm = float(getattr(grad_clip_cfg, 'max_norm', 20))
                        print(f"âœ‚ï¸  æ¢¯åº¦è£å‰ªé…ç½®: max_norm={max_norm}")
                    except Exception:
                        pass
                
                # ç®€åŒ–çš„æ¢¯åº¦ç›‘æ§ï¼ˆé¿å…ä½¿ç”¨jt.gradï¼‰
                try:
                    # åœ¨Jittorä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦
                    # æ¢¯åº¦ä¼šåœ¨optimizer.step()ä¸­è‡ªåŠ¨è®¡ç®—
                    pass
                except Exception as e:
                    print(f"âš ï¸  æ¢¯åº¦ç›‘æ§å¤±è´¥: {e}")
                    # å¦‚æœæ¢¯åº¦ç›‘æ§å¤±è´¥ï¼Œå°è¯•ç»§ç»­è®­ç»ƒ
                    print(f"ğŸ”„ æ¢¯åº¦ç›‘æ§å¤±è´¥ï¼Œå°è¯•ç»§ç»­è®­ç»ƒ...")
                
                # æœ€ç»ˆæ£€æŸ¥ total_loss æ˜¯å¦è¢«æ­£ç¡®å®šä¹‰
                if total_loss is None:
                    print(f"âš ï¸  total_loss ä»ç„¶ä¸º Noneï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    total_loss = jt.array(0.001)
                
                # æ›´æ–°å‚æ•°
                try:
                    # åœ¨Jittorä¸­ï¼Œä½¿ç”¨optimizer.step(loss)æ¥è‡ªåŠ¨å¤„ç†æ¢¯åº¦è®¡ç®—å’Œæ›´æ–°
                    # ä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿total_lossæ˜¯å•ä¸ªJittorå¼ é‡
                    total_loss = ensure_jittor_var(total_loss, "total_loss", (1,))
                    
                    print(f"ğŸ” ä¼˜åŒ–å™¨æ›´æ–°å‰ï¼Œtotal_lossç±»å‹: {type(total_loss)}, shape: {ensure_jittor_var(total_loss, 'total_loss').shape}")

                    # åœ¨Jittorä¸­ï¼Œæ¨èä½¿ç”¨ optimizer.step(loss) æ¥è‡ªåŠ¨å¤„ç†
                    optimizer.step(total_loss)
                    
                    processed_batches += 1  # æˆåŠŸå¤„ç†çš„æ‰¹æ¬¡
                    # print(f"âœ… å‚æ•°æ›´æ–°æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸  ä¼˜åŒ–å™¨æ›´æ–°å¤±è´¥: {e}")
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•æ¸…ç†å†…å­˜å¹¶ç»§ç»­
                    try:
                        clear_jittor_cache()
                        jt.sync_all()
                    except:
                        pass
                    logger.error(f"Optimizer step failed: {e}")
                    # å¦‚æœä¼˜åŒ–å™¨æ›´æ–°å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ‰¹æ¬¡
                    skipped_batches += 1
                    continue
                
                # å†…å­˜ç®¡ç†ä¼˜åŒ–ï¼šæ¸…ç†ä¸­é—´å˜é‡å’Œæ¢¯åº¦
                try:
                    # åœ¨Jittorä¸­ï¼Œä¸éœ€è¦æ‰‹åŠ¨æ¸…ç†æ¢¯åº¦ï¼Œoptimizer.step()ä¼šè‡ªåŠ¨å¤„ç†
                    # æ¸…ç†Jittorç¼“å­˜
                    clear_jittor_cache()
                    
                    # æ¸…ç†ä¸­é—´å˜é‡å¼•ç”¨
                    del total_loss
                    if 'losses' in locals():
                        del losses
                    if 'jt_data' in locals():
                        del jt_data
                    
                    # å¼ºåˆ¶åƒåœ¾å›æ”¶
                    gc.collect()
                    
                        
                except Exception as e:
                    print(f"âš ï¸  å†…å­˜æ¸…ç†å¤±è´¥: {e}")
                
                # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if scheduler is not None:
                    try:
                        # æ£€æŸ¥å½“å‰å­¦ä¹ ç‡æ˜¯å¦è¿‡ä½
                        current_lr = optimizer.lr
                        if current_lr < 1e-6:  # å¦‚æœå­¦ä¹ ç‡è¿‡ä½ï¼Œé‡ç½®ä¸ºåˆå§‹å€¼
                            print(f"âš ï¸  å­¦ä¹ ç‡è¿‡ä½ ({current_lr:.2e})ï¼Œé‡ç½®ä¸ºåˆå§‹å€¼")
                            optimizer.lr = 0.005  # é‡ç½®ä¸ºåˆå§‹å­¦ä¹ ç‡
                        
                        scheduler.step()
                        
                        # å®‰å…¨åœ°è·å–å½“å‰å­¦ä¹ ç‡
                        if hasattr(optimizer, 'param_groups') and len(optimizer.param_groups) > 0:
                            current_lr = optimizer.param_groups[0].get('lr', 0.0)
                            if i % 200 == 0:  # æ¯200æ­¥æ‰“å°ä¸€æ¬¡å­¦ä¹ ç‡
                                print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")
                    except Exception as e:
                        print(f"âš ï¸  å­¦ä¹ ç‡è°ƒåº¦å™¨æ›´æ–°å¤±è´¥: {e}")
                        # å¦‚æœè°ƒåº¦å™¨æ›´æ–°å¤±è´¥ï¼Œå°è¯•é‡ç½®
                        try:
                            if hasattr(scheduler, 'reset'):
                                scheduler.reset()
                                print("ğŸ”„ å­¦ä¹ ç‡è°ƒåº¦å™¨å·²é‡ç½®")
                        except Exception as e2:
                            print(f"âš ï¸  å­¦ä¹ ç‡è°ƒåº¦å™¨é‡ç½®ä¹Ÿå¤±è´¥: {e2}")
                
                # ç´¯ç§¯æŸå¤±
                try:
                    if 'total_loss' in locals() and total_loss is not None:
                        epoch_loss += ensure_jittor_var(total_loss, "total_loss").item()
                    else:
                        print(f"âš ï¸  total_loss æœªå®šä¹‰ï¼Œè·³è¿‡ç´¯ç§¯")
                        epoch_loss += 0.0
                except Exception as e:
                    print(f"âš ï¸  ç´¯ç§¯æ€»æŸå¤±å¤±è´¥: {e}")
                    epoch_loss += 0.0
                
                num_batches += 1
                total_steps += 1

                # å‘¨æœŸæ€§å›æ”¶æ˜¾å­˜ï¼Œç¼“è§£ OOMï¼ˆJittor æ¨èï¼‰
                if (i + 1) % 50 == 0:  # æ›´é¢‘ç¹çš„å†…å­˜æ¸…ç†
                    try:
                        jt.gc()
                        clear_jittor_cache()
                        gc.collect()
                    except Exception:
                        pass
            
                
                # æ›´æ–°tqdmè¿›åº¦æ¡æ˜¾ç¤ºæŸå¤±ä¿¡æ¯
                if isinstance(losses, dict):
                    # åªæ˜¾ç¤ºä¸»è¦çš„æŸå¤±å€¼ï¼Œé¿å…ä¿¡æ¯è¿‡å¤š
                    main_losses = {}
                    for k, v in losses.items():
                        if k in ['loss', 'rpn_cls_loss', 'rpn_bbox_loss', 'rcnn_cls_loss', 'rcnn_bbox_loss']:
                            try:
                                main_losses[k] = f"{ensure_jittor_var(v, f'losses[{k}]').item():.4f}"
                            except:
                                main_losses[k] = "0.0000"
                    
                    # æ›´æ–°è¿›åº¦æ¡æè¿°
                    pbar.set_postfix({
                        'Loss': f"{ensure_jittor_var(total_loss, 'total_loss').item():.4f}",
                        'RPN': f"{main_losses.get('rpn_cls_loss', '0.0000')}",
                        'RCNN': f"{main_losses.get('rcnn_cls_loss', '0.0000')}"
                    })
                else:
                    pbar.set_postfix({'Loss': f"{ensure_jittor_var(total_loss, 'total_loss').item():.4f}"})
                
                # æ¯100æ­¥è®°å½•åˆ°loggerå’ŒJSONæ—¥å¿—
                if i % 100 == 0:
                    if isinstance(losses, dict):
                        loss_str = ', '.join([f'{k}: {ensure_jittor_var(v, f"losses[{k}]").item():.4f}' for k, v in losses.items()])
                    else:
                        loss_str = f'{ensure_jittor_var(total_loss, "total_loss").item():.4f}'
                    
                    # è®°å½•åˆ°logger
                    logger.info(f"Step {i+1}: {loss_str}")
                    
                    # JSON è¡Œæ—¥å¿—ï¼ˆä¸MMDeté£æ ¼æ¥è¿‘ï¼‰
                    record = {
                        'mode': 'train',
                        'epoch': epoch + 1,
                        'iter': i + 1,
                        'lr': float(optimizer.lr),
                        'total_batches': total_batches,
                        'grad_norm': float(grad_norm) if 'grad_norm' in locals() else 0.0,
                    }
                    if grad_norm_value is not None:
                        record['grad_norm'] = float(grad_norm_value)
                    if isinstance(losses, dict):
                        for k, v in losses.items():
                            try:
                                record[k] = float(ensure_jittor_var(v, f"losses[{k}]").item())
                            except Exception:
                                pass
                        record['loss'] = float(ensure_jittor_var(total_loss, "total_loss").item())
                    else:
                        record['loss'] = float(ensure_jittor_var(total_loss, "total_loss").item())
                    append_json_log(record)
                    
            except Exception as e:
                # åªåœ¨ç¬¬ä¸€ä¸ªé”™è¯¯æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œåç»­é”™è¯¯é™é»˜å¤„ç†
                if num_batches == 0:
                    print(f"âŒ æ‰¹æ¬¡ {i+1} å¤„ç†å¤±è´¥: {e}")
                    import traceback as _tb
                    _tb.print_exc()
                    print(f"   æ•°æ®ç±»å‹: {type(data_batch)}")
                    if isinstance(data_batch, dict):
                        for key, value in data_batch.items():
                            print(f"   {key}: {type(value)}")
                skipped_batches += 1
                continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        try:
            avg_loss = epoch_loss / num_batches if num_batches > 0 else 0.0
            # æ£€æŸ¥å¹³å‡æŸå¤±æ˜¯å¦æœ‰æ•ˆ
            if not np.isfinite(avg_loss):
                print(f"âš ï¸  WARNING: å¹³å‡æŸå¤± = {avg_loss} (éæœ‰é™å€¼)ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                avg_loss = 0.001
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—å¹³å‡æŸå¤±å¤±è´¥: {e}")
            avg_loss = 0.001
        
        try:
            avg_components = {key: value / num_batches if num_batches > 0 else 0.0 
                             for key, value in epoch_components.items()}
            # æ£€æŸ¥ç»„ä»¶æŸå¤±æ˜¯å¦æœ‰æ•ˆ
            for key, value in avg_components.items():
                if not np.isfinite(value):
                    print(f"âš ï¸  WARNING: {key} = {value} (éæœ‰é™å€¼)ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    avg_components[key] = 0.0
        except Exception as e:
            print(f"âš ï¸  è®¡ç®—å¹³å‡ç»„ä»¶æŸå¤±å¤±è´¥: {e}")
            avg_components = {}
        
        epoch_losses.append(avg_loss)
        
        # å…³é—­tqdmè¿›åº¦æ¡
        pbar.close()
        
        print(f"\nğŸ“ˆ è½®æ¬¡ {epoch + 1} ç»Ÿè®¡:")
        print(f"   - å¹³å‡æ€»æŸå¤±: {avg_loss:.4f}")
        if avg_components:
            for key, value in avg_components.items():
                print(f"   - {key}: {value:.4f}")
        print(f"   - æ€»æ­¥æ•°: {total_steps}")
        print(f"   - æˆåŠŸå¤„ç†æ‰¹æ¬¡: {processed_batches}")
        print(f"   - è·³è¿‡æ‰¹æ¬¡: {skipped_batches}")
        print(f"   - å®é™…å¤„ç†æ‰¹æ¬¡: {num_batches}/{total_batches} ({num_batches/total_batches*100:.1f}%)")
        
        # è®°å½•åˆ°logger
        logger.info(
            f"Epoch {epoch+1} avg_loss={avg_loss:.4f}, steps={total_steps}, processed_batches={processed_batches}, skipped_batches={skipped_batches}"
        )
        
        # è®°å½•åˆ°JSONæ—¥å¿—
        epoch_record = {
            'mode': 'epoch_summary',
            'epoch': epoch + 1,
            'avg_loss': float(avg_loss),
            'total_steps': total_steps,
            'processed_batches': processed_batches,
            'skipped_batches': skipped_batches,
            'num_batches': num_batches,
            'total_batches': total_batches,
            'lr': float(optimizer.lr)
        }
        if avg_components:
            for key, value in avg_components.items():
                epoch_record[f'avg_{key}'] = float(value)
        append_json_log(epoch_record)
        
        # ä¿å­˜epochè®°å½•
        epoch_records.append(epoch_record)
        
        # å­¦ä¹ ç‡è¡°å‡
        if step_epochs and (epoch + 1) in step_epochs:
            old_lr = optimizer.lr
            optimizer.lr *= 0.1
            print(f"ğŸ“‰ å­¦ä¹ ç‡è¡°å‡: {old_lr:.6f} -> {optimizer.lr:.6f}")
        
        # éªŒè¯
        if validate and len(datasets) > 1:
            print(f"ğŸ” è¿›è¡ŒéªŒè¯...")
            model.eval()
        
        # æ˜¾ç¤ºå½“å‰epochå®ŒæˆçŠ¶æ€
        print(f"â±ï¸  Epoch {epoch+1} å®Œæˆæ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}")
        
        # æ¯ä¸ªepochç»“æŸæ—¶æ¸…ç†å†…å­˜
        clear_jittor_cache()
        gc.collect()
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if hasattr(cfg, 'checkpoint_config') and cfg.checkpoint_config.interval > 0:
            if (epoch + 1) % cfg.checkpoint_config.interval == 0:
                # ç»Ÿä¸€ä½¿ç”¨ .pth æ‰©å±•åï¼Œä¾¿äºä¸ PyTorch æµç¨‹å¯¹é½
                checkpoint_path = osp.join(cfg.work_dir, f'epoch_{epoch+1}.pth')
                # å®é™…ä¿å­˜æ¨¡å‹å‚æ•°ï¼ˆJittor Var -> numpyï¼‰ï¼Œå¹¶åŒ…å«åŸºæœ¬å…ƒä¿¡æ¯
                try:
                    print(f"ğŸ’¾ å¼€å§‹ä¿å­˜æ£€æŸ¥ç‚¹...")
                    
                    # å¼ºåˆ¶åŒæ­¥æ‰€æœ‰ CUDA æ“ä½œ
                    print(f"ğŸ”„ åŒæ­¥ CUDA æ“ä½œ...")
                    try:
                        jt.sync_all(True)
                        print(f"âœ… CUDA åŒæ­¥å®Œæˆ")
                    except Exception as e:
                        print(f"âš ï¸  CUDA åŒæ­¥è­¦å‘Š: {e}")
                    
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ‰€æœ‰æ“ä½œå®Œæˆ
                    import time
                    time.sleep(1)
                    
                    # è·å–æ¨¡å‹çŠ¶æ€
                    print(f"ğŸ“‹ è·å–æ¨¡å‹çŠ¶æ€...")
                    state = {}
                    try:
                        model_state = model.state_dict()
                        print(f"âœ… æ¨¡å‹çŠ¶æ€è·å–æˆåŠŸï¼ŒåŒ…å« {len(model_state)} ä¸ªå‚æ•°")
                    except Exception as e:
                        print(f"âŒ æ¨¡å‹çŠ¶æ€è·å–å¤±è´¥: {e}")
                        model_state = {}
                    
                    # è½¬æ¢å‚æ•°ä¸º numpy
                    print(f"ğŸ”„ è½¬æ¢å‚æ•°æ ¼å¼...")
                    for key, val in model_state.items():
                        try:
                            if hasattr(val, 'numpy'):
                                state[key] = val.numpy()
                            elif hasattr(val, 'detach') and hasattr(val, 'cpu'):
                                # å¤„ç†å¯èƒ½çš„ torch.Tensor
                                state[key] = val.detach().cpu().numpy()
                            else:
                                state[key] = val
                        except Exception as e:
                            print(f"âš ï¸  å‚æ•° {key} è½¬æ¢å¤±è´¥: {e}")
                            state[key] = val
                    
                    # å‡†å¤‡å…ƒä¿¡æ¯
                    meta = {
                        'epoch': epoch + 1,
                        'classes': getattr(model, 'CLASSES', None),
                        'config': getattr(cfg, 'pretty_text', None),
                        'timestamp': datetime.datetime.now().isoformat(),
                        'avg_loss': float(avg_loss),
                        'num_batches': num_batches
                    }
                    
                    # åˆ›å»ºç›®å½•å¹¶ä¿å­˜
                    print(f"ğŸ“ åˆ›å»ºä¿å­˜ç›®å½•...")
                    mmcv.mkdir_or_exist(osp.dirname(osp.abspath(checkpoint_path)))
                    
                    print(f"ğŸ’¾ å†™å…¥æ£€æŸ¥ç‚¹æ–‡ä»¶...")
                    with open(checkpoint_path, 'wb') as f:
                        pickle.dump({'state_dict': state, 'meta': meta}, f)
                    
                    print(f"âœ… æ£€æŸ¥ç‚¹ä¿å­˜æˆåŠŸ: {checkpoint_path}")
                    logger.info(f"Checkpoint saved to {checkpoint_path}")
                    
                except Exception as e:
                    print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                    logger.error(f"Failed to save checkpoint: {e}")
                    import traceback
                    traceback.print_exc()
                    
                    # å°è¯•ä¿å­˜ä¸€ä¸ªç®€åŒ–çš„æ£€æŸ¥ç‚¹
                    try:
                        print(f"ğŸ”„ å°è¯•ä¿å­˜ç®€åŒ–æ£€æŸ¥ç‚¹...")
                        simple_checkpoint_path = osp.join(cfg.work_dir, f'epoch_{epoch+1}_simple.pth')
                        simple_state = {'epoch': epoch + 1, 'error': str(e)}
                        with open(simple_checkpoint_path, 'wb') as f:
                            pickle.dump(simple_state, f)
                        print(f"âœ… ç®€åŒ–æ£€æŸ¥ç‚¹ä¿å­˜æˆåŠŸ: {simple_checkpoint_path}")
                    except Exception as e2:
                        print(f"âŒ ç®€åŒ–æ£€æŸ¥ç‚¹ä¹Ÿä¿å­˜å¤±è´¥: {e2}")
        
        print(f"âœ… è½®æ¬¡ {epoch + 1} å®Œæˆ")
    
    # è®­ç»ƒå®Œæˆæ€»ç»“
    print(f"\nğŸ‰ Jittorè®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
    print(f"   - æ€»è½®æ¬¡: {max_epochs}")
    print(f"   - æœ€ç»ˆå¹³å‡æŸå¤±: {np.mean(epoch_losses):.4f}")
    print(f"   - æ€»æ­¥æ•°: {total_steps}")
    print(f"   - æ€»æˆåŠŸæ‰¹æ¬¡: {sum([epoch_record.get('processed_batches', 0) for epoch_record in epoch_records if 'processed_batches' in epoch_record])}")
    print(f"   - æ€»è·³è¿‡æ‰¹æ¬¡: {sum([epoch_record.get('skipped_batches', 0) for epoch_record in epoch_records if 'skipped_batches' in epoch_record])}")
    
    # è®°å½•åˆ°logger
    logger.info(f"Training completed: epochs={max_epochs}, final_avg_loss={np.mean(epoch_losses):.4f}, total_steps={total_steps}")
    
    # è®°å½•åˆ°JSONæ—¥å¿—
    final_record = {
        'mode': 'training_complete',
        'total_epochs': max_epochs,
        'final_avg_loss': float(np.mean(epoch_losses)),
        'total_steps': total_steps,
        'timestamp': datetime.datetime.now().isoformat()
    }
    append_json_log(final_record)


def main():
    args = parse_args()

    print("=" * 60)
    print(f"ğŸ”¬ æ··åˆæ¨¡å¼è®­ç»ƒ - Jittor + MMDetection")
    print("=" * 60)

    # åŠ è½½è‡ªå®šä¹‰ç»„ä»¶
    if not load_custom_components():
        print("âŒ è‡ªå®šä¹‰ç»„ä»¶åŠ è½½å¤±è´¥ï¼Œé€€å‡º")
        return

    # è®¾ç½®Jittor
    setup_jittor()

    cfg = Config.fromfile(args.config)
    if args.cfg_options is not None:
        cfg.merge_from_dict(args.cfg_options)
    
    # è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥é˜²æ­¢å†…å­˜æº¢å‡º
    if hasattr(cfg, 'data') and hasattr(cfg.data, 'samples_per_gpu'):
        original_batch_size = cfg.data.samples_per_gpu
        # å¦‚æœæ‰¹æ¬¡å¤§å°å¤§äº1ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º1ï¼ˆè¿›ä¸€æ­¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼‰
        if original_batch_size > 1:
            cfg.data.samples_per_gpu = 1
            print(f"âš ï¸  è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°: {original_batch_size} -> {cfg.data.samples_per_gpu} (é˜²æ­¢å†…å­˜æº¢å‡º)")
    
    # å¦‚æœå‘½ä»¤è¡ŒæŒ‡å®šäº†æ‰¹æ¬¡å¤§å°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    if args.batch_size:
        if hasattr(cfg, 'data'):
            cfg.data.samples_per_gpu = args.batch_size
            print(f"ğŸ“ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    
    # å¯¼å…¥å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æ¨¡å—
    if cfg.get('custom_imports', None):
        from mmcv.utils import import_modules_from_strings
        import_modules_from_strings(**cfg['custom_imports'])

    # work_dirçš„ä¼˜å…ˆçº§ï¼šCLI > æ–‡ä»¶ä¸­çš„æ®µ > æ–‡ä»¶å
    if args.work_dir is not None:
        cfg.work_dir = args.work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = osp.join('./work_dirs', osp.splitext(osp.basename(args.config))[0])
    if args.resume_from is not None:
        cfg.resume_from = args.resume_from
    if args.gpu_ids is not None:
        cfg.gpu_ids = args.gpu_ids
    else:
        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)

    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    if args.launcher == 'none':
        distributed = False
    else:
        distributed = True
        init_dist(args.launcher, **cfg.dist_params)
        _, world_size = get_dist_info()
        cfg.gpu_ids = range(world_size)

    # åˆ›å»ºwork_dirï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„æ··æ·†ï¼‰
    abs_work_dir = osp.abspath(cfg.work_dir)
    mmcv.mkdir_or_exist(abs_work_dir)
    cfg.work_dir = abs_work_dir
    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))
    
    # åˆå§‹åŒ–logger
    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    log_file = osp.join(cfg.work_dir, f'{timestamp}_mixed_mode.log')
    log_level = cfg.get('log_level', 'INFO')
    logger = get_root_logger(log_file=log_file, log_level=log_level)
    # è¿½åŠ ä¸€ä¸ª json è¡Œæ—¥å¿—æ–‡ä»¶ï¼Œå…¼å®¹ mmdet é£æ ¼
    json_log_path = osp.join(cfg.work_dir, f'{timestamp}.log.json')

    # åˆå§‹åŒ–meta dict
    meta = dict()
    env_info_dict = collect_env()
    env_info = '\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])
    dash_line = '-' * 60 + '\n'
    logger.info('ç¯å¢ƒä¿¡æ¯:\n' + dash_line + env_info + '\n' + dash_line)
    meta['env_info'] = env_info
    meta['config'] = cfg.pretty_text
    logger.info(f'åˆ†å¸ƒå¼è®­ç»ƒ: {distributed}')
    logger.info(f'å¼€å§‹è®­ç»ƒ')
    logger.info(f'é…ç½®:\n{cfg.pretty_text}')

    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        logger.info(f'è®¾ç½®éšæœºç§å­ä¸º {args.seed}, ç¡®å®šæ€§: {args.deterministic}')
        set_random_seed(args.seed, deterministic=args.deterministic)
    cfg.seed = args.seed
    meta['seed'] = args.seed
    meta['exp_name'] = osp.basename(args.config)
    meta['stage'] = 'auto_detected'

    # æ„å»ºæ•°æ®é›†
    print("ğŸ“Š æ„å»ºæ•°æ®é›†...")
    datasets = [build_dataset(cfg.data.train)]
    workflow = cfg.get('workflow', [('train', 1)])
    if len(workflow) == 2:
        val_dataset = copy.deepcopy(cfg.data.val)
        val_dataset.pipeline = cfg.data.train.pipeline
        datasets.append(build_dataset(val_dataset))
    # è¾“å‡ºè®­ç»ƒé›†å›¾åƒæ•°é‡ï¼Œä¾¿äºç¡®è®¤æ­¥æ•°
    try:
        train_len = len(datasets[0])
        print(f"ğŸ“¦ è®­ç»ƒé›†å›¾åƒæ•°é‡: {train_len}")
        logger.info(f"Train dataset length (images): {train_len}")
    except Exception:
        pass
    
    model_classes = datasets[0].CLASSES

    # è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ
    stage = detect_training_stage(cfg, args.config)
    
    # åˆ›å»ºJittorå…¼å®¹çš„æ¨¡å‹
    model = create_jittor_compatible_model(cfg, stage)
    model.CLASSES = model_classes

    # ä½¿ç”¨è‡ªå®šä¹‰çš„Jittorè®­ç»ƒå™¨
    try:
        create_jittor_trainer(
            model,
            datasets,
            cfg,
            args,
            distributed=distributed,
            validate=(not args.no_validate),
            timestamp=timestamp,
            meta=meta,
            logger=logger,
            json_log_path=json_log_path)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
