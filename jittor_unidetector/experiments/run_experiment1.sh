#!/bin/bash

# å®éªŒ1ï¼šCOCO + Objects365 â†’ LVISv1 è·¨æ•°æ®é›†æ£€æµ‹
# ä¸€é”®æ‰§è¡Œè„šæœ¬

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ1ï¼šCOCO + Objects365 â†’ LVISv1"

# æ£€æŸ¥ç¯å¢ƒ
echo "ğŸ“‹ æ£€æŸ¥ç¯å¢ƒ..."
python -c "import jittor; print('âœ“ Jittor version:', jittor.__version__)"
python -c "import clip; print('âœ“ CLIP installed successfully')"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
echo "ğŸ“ åˆ›å»ºç›®å½•..."
mkdir -p work_dirs/coco_objects365_cln
mkdir -p work_dirs/coco_objects365_roi
mkdir -p results
mkdir -p data/proposals

# æ•°æ®å‡†å¤‡ï¼ˆå¦‚æœæ•°æ®ä¸å­˜åœ¨ï¼Œæç¤ºç”¨æˆ·ï¼‰
echo "ğŸ“Š æ£€æŸ¥æ•°æ®..."
if [ ! -f "data/coco/annotations/instances_train2017.json" ]; then
    echo "âš ï¸  è¯·å…ˆå‡†å¤‡COCOæ•°æ®é›†"
    echo "   è¿è¡Œ: python tools/prepare_data.py --data-root /path/to/coco --output-dir ./data/coco --dataset coco"
    exit 1
fi

if [ ! -f "data/objects365/annotations/instances_train.json" ]; then
    echo "âš ï¸  è¯·å…ˆå‡†å¤‡Objects365æ•°æ®é›†"
    echo "   è¿è¡Œ: python tools/prepare_data.py --data-root /path/to/objects365 --output-dir ./data/objects365 --dataset objects365"
    exit 1
fi

if [ ! -f "data/lvis/annotations/lvis_v1_val.json" ]; then
    echo "âš ï¸  è¯·å…ˆå‡†å¤‡LVISv1æ•°æ®é›†"
    echo "   è¿è¡Œ: python tools/prepare_data.py --data-root /path/to/lvis --output-dir ./data/lvis --dataset lvis"
    exit 1
fi

# ç”ŸæˆCLIPåµŒå…¥ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
echo "ğŸ”¤ ç”ŸæˆCLIPåµŒå…¥..."
if [ ! -f "clip_embeddings/coco_clip_embeddings.npy" ]; then
    echo "ç”ŸæˆCOCO CLIPåµŒå…¥..."
    python tools/generate_clip_embeddings.py \
        --dataset coco \
        --output-path ./clip_embeddings/coco_clip_embeddings.npy
fi

if [ ! -f "clip_embeddings/objects365_clip_embeddings.npy" ]; then
    echo "ç”ŸæˆObjects365 CLIPåµŒå…¥..."
    python tools/generate_clip_embeddings.py \
        --dataset objects365 \
        --output-path ./clip_embeddings/objects365_clip_embeddings.npy
fi

if [ ! -f "clip_embeddings/lvis_clip_embeddings.npy" ]; then
    echo "ç”ŸæˆLVIS CLIPåµŒå…¥..."
    python tools/generate_clip_embeddings.py \
        --dataset lvis \
        --output-path ./clip_embeddings/lvis_clip_embeddings.npy
fi

# ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒCLNç½‘ç»œ
echo "ğŸ¯ ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒCLNç½‘ç»œ..."
python tools/jittor_train.py \
    --config configs/coco_objects365_cln_training.py \
    --work-dir work_dirs/coco_objects365_cln \
    --epochs 12 \
    --batch-size 2 \
    --datasets coco objects365

# ç”Ÿæˆproposalæ–‡ä»¶
echo "ğŸ“‹ ç”Ÿæˆproposalæ–‡ä»¶..."
python tools/generate_proposals.py \
    --config configs/coco_objects365_cln_training.py \
    --checkpoint work_dirs/coco_objects365_cln/epoch_12.pkl \
    --output-dir data/proposals

# ç¬¬äºŒé˜¶æ®µï¼šè®­ç»ƒRoIåˆ†ç±»å¤´
echo "ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šè®­ç»ƒRoIåˆ†ç±»å¤´..."
python tools/jittor_train.py \
    --config configs/coco_objects365_roi_training.py \
    --work-dir work_dirs/coco_objects365_roi \
    --epochs 8 \
    --batch-size 2

# åœ¨LVISv1ä¸Šæµ‹è¯•
echo "ğŸ§ª åœ¨LVISv1ä¸Šæµ‹è¯•..."
python tools/test.py \
    --config configs/lvis_inference.py \
    --checkpoint work_dirs/coco_objects365_roi/epoch_8.pkl \
    --out results/coco_objects365_to_lvis.json \
    --eval bbox \
    --dataset lvis

# æ¦‚ç‡æ ¡å‡†
echo "âš–ï¸  æ¦‚ç‡æ ¡å‡†..."
python tools/calibrate_results.py \
    --input results/coco_objects365_to_lvis.json \
    --output results/coco_objects365_to_lvis_calibrated.json \
    --calibration-method prior_probability

echo "âœ… å®éªŒ1å®Œæˆï¼"
echo "ğŸ“Š ç»“æœæ–‡ä»¶ï¼š"
echo "   - åŸå§‹ç»“æœ: results/coco_objects365_to_lvis.json"
echo "   - æ ¡å‡†ç»“æœ: results/coco_objects365_to_lvis_calibrated.json"
echo "   - æ¨¡å‹æ–‡ä»¶: work_dirs/coco_objects365_roi/epoch_8.pkl" 